/*
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/dataplex/v1/catalog.proto

// Protobuf Java Version: 3.25.5
package com.google.cloud.dataplex.v1;

/**
 *
 *
 * <pre>
 * A metadata job resource.
 * </pre>
 *
 * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob}
 */
public final class MetadataJob extends com.google.protobuf.GeneratedMessageV3
    implements
    // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.MetadataJob)
    MetadataJobOrBuilder {
  private static final long serialVersionUID = 0L;
  // Use MetadataJob.newBuilder() to construct.
  private MetadataJob(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }

  private MetadataJob() {
    name_ = "";
    uid_ = "";
    type_ = 0;
  }

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
    return new MetadataJob();
  }

  public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
    return com.google.cloud.dataplex.v1.CatalogProto
        .internal_static_google_cloud_dataplex_v1_MetadataJob_descriptor;
  }

  @SuppressWarnings({"rawtypes"})
  @java.lang.Override
  protected com.google.protobuf.MapFieldReflectionAccessor internalGetMapFieldReflection(
      int number) {
    switch (number) {
      case 5:
        return internalGetLabels();
      default:
        throw new RuntimeException("Invalid map field number: " + number);
    }
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.google.cloud.dataplex.v1.CatalogProto
        .internal_static_google_cloud_dataplex_v1_MetadataJob_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.google.cloud.dataplex.v1.MetadataJob.class,
            com.google.cloud.dataplex.v1.MetadataJob.Builder.class);
  }

  /**
   *
   *
   * <pre>
   * Metadata job type.
   * </pre>
   *
   * Protobuf enum {@code google.cloud.dataplex.v1.MetadataJob.Type}
   */
  public enum Type implements com.google.protobuf.ProtocolMessageEnum {
    /**
     *
     *
     * <pre>
     * Unspecified.
     * </pre>
     *
     * <code>TYPE_UNSPECIFIED = 0;</code>
     */
    TYPE_UNSPECIFIED(0),
    /**
     *
     *
     * <pre>
     * Import job.
     * </pre>
     *
     * <code>IMPORT = 1;</code>
     */
    IMPORT(1),
    UNRECOGNIZED(-1),
    ;

    /**
     *
     *
     * <pre>
     * Unspecified.
     * </pre>
     *
     * <code>TYPE_UNSPECIFIED = 0;</code>
     */
    public static final int TYPE_UNSPECIFIED_VALUE = 0;
    /**
     *
     *
     * <pre>
     * Import job.
     * </pre>
     *
     * <code>IMPORT = 1;</code>
     */
    public static final int IMPORT_VALUE = 1;

    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static Type valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static Type forNumber(int value) {
      switch (value) {
        case 0:
          return TYPE_UNSPECIFIED;
        case 1:
          return IMPORT;
        default:
          return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<Type> internalGetValueMap() {
      return internalValueMap;
    }

    private static final com.google.protobuf.Internal.EnumLiteMap<Type> internalValueMap =
        new com.google.protobuf.Internal.EnumLiteMap<Type>() {
          public Type findValueByNumber(int number) {
            return Type.forNumber(number);
          }
        };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }

    public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType() {
      return getDescriptor();
    }

    public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.MetadataJob.getDescriptor().getEnumTypes().get(0);
    }

    private static final Type[] VALUES = values();

    public static Type valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private Type(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:google.cloud.dataplex.v1.MetadataJob.Type)
  }

  public interface ImportJobResultOrBuilder
      extends
      // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.MetadataJob.ImportJobResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were deleted.
     * </pre>
     *
     * <code>int64 deleted_entries = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The deletedEntries.
     */
    long getDeletedEntries();

    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were updated.
     * </pre>
     *
     * <code>int64 updated_entries = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The updatedEntries.
     */
    long getUpdatedEntries();

    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were created.
     * </pre>
     *
     * <code>int64 created_entries = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The createdEntries.
     */
    long getCreatedEntries();

    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were unchanged.
     * </pre>
     *
     * <code>int64 unchanged_entries = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The unchangedEntries.
     */
    long getUnchangedEntries();

    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were recreated.
     * </pre>
     *
     * <code>int64 recreated_entries = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The recreatedEntries.
     */
    long getRecreatedEntries();

    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the updateTime field is set.
     */
    boolean hasUpdateTime();
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The updateTime.
     */
    com.google.protobuf.Timestamp getUpdateTime();
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder();
  }
  /**
   *
   *
   * <pre>
   * Results from a metadata import job.
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.ImportJobResult}
   */
  public static final class ImportJobResult extends com.google.protobuf.GeneratedMessageV3
      implements
      // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.MetadataJob.ImportJobResult)
      ImportJobResultOrBuilder {
    private static final long serialVersionUID = 0L;
    // Use ImportJobResult.newBuilder() to construct.
    private ImportJobResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }

    private ImportJobResult() {}

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
      return new ImportJobResult();
    }

    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobResult_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.class,
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.Builder.class);
    }

    private int bitField0_;
    public static final int DELETED_ENTRIES_FIELD_NUMBER = 1;
    private long deletedEntries_ = 0L;
    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were deleted.
     * </pre>
     *
     * <code>int64 deleted_entries = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The deletedEntries.
     */
    @java.lang.Override
    public long getDeletedEntries() {
      return deletedEntries_;
    }

    public static final int UPDATED_ENTRIES_FIELD_NUMBER = 2;
    private long updatedEntries_ = 0L;
    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were updated.
     * </pre>
     *
     * <code>int64 updated_entries = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The updatedEntries.
     */
    @java.lang.Override
    public long getUpdatedEntries() {
      return updatedEntries_;
    }

    public static final int CREATED_ENTRIES_FIELD_NUMBER = 3;
    private long createdEntries_ = 0L;
    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were created.
     * </pre>
     *
     * <code>int64 created_entries = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The createdEntries.
     */
    @java.lang.Override
    public long getCreatedEntries() {
      return createdEntries_;
    }

    public static final int UNCHANGED_ENTRIES_FIELD_NUMBER = 4;
    private long unchangedEntries_ = 0L;
    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were unchanged.
     * </pre>
     *
     * <code>int64 unchanged_entries = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The unchangedEntries.
     */
    @java.lang.Override
    public long getUnchangedEntries() {
      return unchangedEntries_;
    }

    public static final int RECREATED_ENTRIES_FIELD_NUMBER = 6;
    private long recreatedEntries_ = 0L;
    /**
     *
     *
     * <pre>
     * Output only. The total number of entries that were recreated.
     * </pre>
     *
     * <code>int64 recreated_entries = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The recreatedEntries.
     */
    @java.lang.Override
    public long getRecreatedEntries() {
      return recreatedEntries_;
    }

    public static final int UPDATE_TIME_FIELD_NUMBER = 5;
    private com.google.protobuf.Timestamp updateTime_;
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the updateTime field is set.
     */
    @java.lang.Override
    public boolean hasUpdateTime() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The updateTime.
     */
    @java.lang.Override
    public com.google.protobuf.Timestamp getUpdateTime() {
      return updateTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : updateTime_;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    @java.lang.Override
    public com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder() {
      return updateTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : updateTime_;
    }

    private byte memoizedIsInitialized = -1;

    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
      if (deletedEntries_ != 0L) {
        output.writeInt64(1, deletedEntries_);
      }
      if (updatedEntries_ != 0L) {
        output.writeInt64(2, updatedEntries_);
      }
      if (createdEntries_ != 0L) {
        output.writeInt64(3, createdEntries_);
      }
      if (unchangedEntries_ != 0L) {
        output.writeInt64(4, unchangedEntries_);
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(5, getUpdateTime());
      }
      if (recreatedEntries_ != 0L) {
        output.writeInt64(6, recreatedEntries_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (deletedEntries_ != 0L) {
        size += com.google.protobuf.CodedOutputStream.computeInt64Size(1, deletedEntries_);
      }
      if (updatedEntries_ != 0L) {
        size += com.google.protobuf.CodedOutputStream.computeInt64Size(2, updatedEntries_);
      }
      if (createdEntries_ != 0L) {
        size += com.google.protobuf.CodedOutputStream.computeInt64Size(3, createdEntries_);
      }
      if (unchangedEntries_ != 0L) {
        size += com.google.protobuf.CodedOutputStream.computeInt64Size(4, unchangedEntries_);
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream.computeMessageSize(5, getUpdateTime());
      }
      if (recreatedEntries_ != 0L) {
        size += com.google.protobuf.CodedOutputStream.computeInt64Size(6, recreatedEntries_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
        return true;
      }
      if (!(obj instanceof com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult)) {
        return super.equals(obj);
      }
      com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult other =
          (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) obj;

      if (getDeletedEntries() != other.getDeletedEntries()) return false;
      if (getUpdatedEntries() != other.getUpdatedEntries()) return false;
      if (getCreatedEntries() != other.getCreatedEntries()) return false;
      if (getUnchangedEntries() != other.getUnchangedEntries()) return false;
      if (getRecreatedEntries() != other.getRecreatedEntries()) return false;
      if (hasUpdateTime() != other.hasUpdateTime()) return false;
      if (hasUpdateTime()) {
        if (!getUpdateTime().equals(other.getUpdateTime())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + DELETED_ENTRIES_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getDeletedEntries());
      hash = (37 * hash) + UPDATED_ENTRIES_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getUpdatedEntries());
      hash = (37 * hash) + CREATED_ENTRIES_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getCreatedEntries());
      hash = (37 * hash) + UNCHANGED_ENTRIES_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getUnchangedEntries());
      hash = (37 * hash) + RECREATED_ENTRIES_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(getRecreatedEntries());
      if (hasUpdateTime()) {
        hash = (37 * hash) + UPDATE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + getUpdateTime().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseDelimitedFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseDelimitedFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        com.google.protobuf.CodedInputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() {
      return newBuilder();
    }

    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }

    public static Builder newBuilder(
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }

    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     *
     *
     * <pre>
     * Results from a metadata import job.
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.ImportJobResult}
     */
    public static final class Builder
        extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
        implements
        // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.MetadataJob.ImportJobResult)
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobResult_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.class,
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.Builder.class);
      }

      // Construct using com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }

      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {
          getUpdateTimeFieldBuilder();
        }
      }

      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        deletedEntries_ = 0L;
        updatedEntries_ = 0L;
        createdEntries_ = 0L;
        unchangedEntries_ = 0L;
        recreatedEntries_ = 0L;
        updateTime_ = null;
        if (updateTimeBuilder_ != null) {
          updateTimeBuilder_.dispose();
          updateTimeBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobResult_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult getDefaultInstanceForType() {
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult build() {
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult buildPartial() {
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult result =
            new com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult(this);
        if (bitField0_ != 0) {
          buildPartial0(result);
        }
        onBuilt();
        return result;
      }

      private void buildPartial0(com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.deletedEntries_ = deletedEntries_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.updatedEntries_ = updatedEntries_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.createdEntries_ = createdEntries_;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.unchangedEntries_ = unchangedEntries_;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.recreatedEntries_ = recreatedEntries_;
        }
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.updateTime_ =
              updateTimeBuilder_ == null ? updateTime_ : updateTimeBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }

      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.setField(field, value);
      }

      @java.lang.Override
      public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }

      @java.lang.Override
      public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }

      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index,
          java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }

      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }

      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) {
          return mergeFrom((com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult other) {
        if (other == com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance())
          return this;
        if (other.getDeletedEntries() != 0L) {
          setDeletedEntries(other.getDeletedEntries());
        }
        if (other.getUpdatedEntries() != 0L) {
          setUpdatedEntries(other.getUpdatedEntries());
        }
        if (other.getCreatedEntries() != 0L) {
          setCreatedEntries(other.getCreatedEntries());
        }
        if (other.getUnchangedEntries() != 0L) {
          setUnchangedEntries(other.getUnchangedEntries());
        }
        if (other.getRecreatedEntries() != 0L) {
          setRecreatedEntries(other.getRecreatedEntries());
        }
        if (other.hasUpdateTime()) {
          mergeUpdateTime(other.getUpdateTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8:
                {
                  deletedEntries_ = input.readInt64();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 8
              case 16:
                {
                  updatedEntries_ = input.readInt64();
                  bitField0_ |= 0x00000002;
                  break;
                } // case 16
              case 24:
                {
                  createdEntries_ = input.readInt64();
                  bitField0_ |= 0x00000004;
                  break;
                } // case 24
              case 32:
                {
                  unchangedEntries_ = input.readInt64();
                  bitField0_ |= 0x00000008;
                  break;
                } // case 32
              case 42:
                {
                  input.readMessage(getUpdateTimeFieldBuilder().getBuilder(), extensionRegistry);
                  bitField0_ |= 0x00000020;
                  break;
                } // case 42
              case 48:
                {
                  recreatedEntries_ = input.readInt64();
                  bitField0_ |= 0x00000010;
                  break;
                } // case 48
              default:
                {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private int bitField0_;

      private long deletedEntries_;
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were deleted.
       * </pre>
       *
       * <code>int64 deleted_entries = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The deletedEntries.
       */
      @java.lang.Override
      public long getDeletedEntries() {
        return deletedEntries_;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were deleted.
       * </pre>
       *
       * <code>int64 deleted_entries = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The deletedEntries to set.
       * @return This builder for chaining.
       */
      public Builder setDeletedEntries(long value) {

        deletedEntries_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were deleted.
       * </pre>
       *
       * <code>int64 deleted_entries = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearDeletedEntries() {
        bitField0_ = (bitField0_ & ~0x00000001);
        deletedEntries_ = 0L;
        onChanged();
        return this;
      }

      private long updatedEntries_;
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were updated.
       * </pre>
       *
       * <code>int64 updated_entries = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The updatedEntries.
       */
      @java.lang.Override
      public long getUpdatedEntries() {
        return updatedEntries_;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were updated.
       * </pre>
       *
       * <code>int64 updated_entries = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The updatedEntries to set.
       * @return This builder for chaining.
       */
      public Builder setUpdatedEntries(long value) {

        updatedEntries_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were updated.
       * </pre>
       *
       * <code>int64 updated_entries = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearUpdatedEntries() {
        bitField0_ = (bitField0_ & ~0x00000002);
        updatedEntries_ = 0L;
        onChanged();
        return this;
      }

      private long createdEntries_;
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were created.
       * </pre>
       *
       * <code>int64 created_entries = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The createdEntries.
       */
      @java.lang.Override
      public long getCreatedEntries() {
        return createdEntries_;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were created.
       * </pre>
       *
       * <code>int64 created_entries = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The createdEntries to set.
       * @return This builder for chaining.
       */
      public Builder setCreatedEntries(long value) {

        createdEntries_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were created.
       * </pre>
       *
       * <code>int64 created_entries = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearCreatedEntries() {
        bitField0_ = (bitField0_ & ~0x00000004);
        createdEntries_ = 0L;
        onChanged();
        return this;
      }

      private long unchangedEntries_;
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were unchanged.
       * </pre>
       *
       * <code>int64 unchanged_entries = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The unchangedEntries.
       */
      @java.lang.Override
      public long getUnchangedEntries() {
        return unchangedEntries_;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were unchanged.
       * </pre>
       *
       * <code>int64 unchanged_entries = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The unchangedEntries to set.
       * @return This builder for chaining.
       */
      public Builder setUnchangedEntries(long value) {

        unchangedEntries_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were unchanged.
       * </pre>
       *
       * <code>int64 unchanged_entries = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearUnchangedEntries() {
        bitField0_ = (bitField0_ & ~0x00000008);
        unchangedEntries_ = 0L;
        onChanged();
        return this;
      }

      private long recreatedEntries_;
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were recreated.
       * </pre>
       *
       * <code>int64 recreated_entries = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The recreatedEntries.
       */
      @java.lang.Override
      public long getRecreatedEntries() {
        return recreatedEntries_;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were recreated.
       * </pre>
       *
       * <code>int64 recreated_entries = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The recreatedEntries to set.
       * @return This builder for chaining.
       */
      public Builder setRecreatedEntries(long value) {

        recreatedEntries_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The total number of entries that were recreated.
       * </pre>
       *
       * <code>int64 recreated_entries = 6 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearRecreatedEntries() {
        bitField0_ = (bitField0_ & ~0x00000010);
        recreatedEntries_ = 0L;
        onChanged();
        return this;
      }

      private com.google.protobuf.Timestamp updateTime_;
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp,
              com.google.protobuf.Timestamp.Builder,
              com.google.protobuf.TimestampOrBuilder>
          updateTimeBuilder_;
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @return Whether the updateTime field is set.
       */
      public boolean hasUpdateTime() {
        return ((bitField0_ & 0x00000020) != 0);
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @return The updateTime.
       */
      public com.google.protobuf.Timestamp getUpdateTime() {
        if (updateTimeBuilder_ == null) {
          return updateTime_ == null
              ? com.google.protobuf.Timestamp.getDefaultInstance()
              : updateTime_;
        } else {
          return updateTimeBuilder_.getMessage();
        }
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder setUpdateTime(com.google.protobuf.Timestamp value) {
        if (updateTimeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          updateTime_ = value;
        } else {
          updateTimeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder setUpdateTime(com.google.protobuf.Timestamp.Builder builderForValue) {
        if (updateTimeBuilder_ == null) {
          updateTime_ = builderForValue.build();
        } else {
          updateTimeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder mergeUpdateTime(com.google.protobuf.Timestamp value) {
        if (updateTimeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0)
              && updateTime_ != null
              && updateTime_ != com.google.protobuf.Timestamp.getDefaultInstance()) {
            getUpdateTimeBuilder().mergeFrom(value);
          } else {
            updateTime_ = value;
          }
        } else {
          updateTimeBuilder_.mergeFrom(value);
        }
        if (updateTime_ != null) {
          bitField0_ |= 0x00000020;
          onChanged();
        }
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder clearUpdateTime() {
        bitField0_ = (bitField0_ & ~0x00000020);
        updateTime_ = null;
        if (updateTimeBuilder_ != null) {
          updateTimeBuilder_.dispose();
          updateTimeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public com.google.protobuf.Timestamp.Builder getUpdateTimeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getUpdateTimeFieldBuilder().getBuilder();
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder() {
        if (updateTimeBuilder_ != null) {
          return updateTimeBuilder_.getMessageOrBuilder();
        } else {
          return updateTime_ == null
              ? com.google.protobuf.Timestamp.getDefaultInstance()
              : updateTime_;
        }
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 5 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp,
              com.google.protobuf.Timestamp.Builder,
              com.google.protobuf.TimestampOrBuilder>
          getUpdateTimeFieldBuilder() {
        if (updateTimeBuilder_ == null) {
          updateTimeBuilder_ =
              new com.google.protobuf.SingleFieldBuilderV3<
                  com.google.protobuf.Timestamp,
                  com.google.protobuf.Timestamp.Builder,
                  com.google.protobuf.TimestampOrBuilder>(
                  getUpdateTime(), getParentForChildren(), isClean());
          updateTime_ = null;
        }
        return updateTimeBuilder_;
      }

      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }

      // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobResult)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobResult)
    private static final com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult DEFAULT_INSTANCE;

    static {
      DEFAULT_INSTANCE = new com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult();
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ImportJobResult> PARSER =
        new com.google.protobuf.AbstractParser<ImportJobResult>() {
          @java.lang.Override
          public ImportJobResult parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
            Builder builder = newBuilder();
            try {
              builder.mergeFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              throw e.setUnfinishedMessage(builder.buildPartial());
            } catch (com.google.protobuf.UninitializedMessageException e) {
              throw e.asInvalidProtocolBufferException()
                  .setUnfinishedMessage(builder.buildPartial());
            } catch (java.io.IOException e) {
              throw new com.google.protobuf.InvalidProtocolBufferException(e)
                  .setUnfinishedMessage(builder.buildPartial());
            }
            return builder.buildPartial();
          }
        };

    public static com.google.protobuf.Parser<ImportJobResult> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ImportJobResult> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }
  }

  public interface ImportJobSpecOrBuilder
      extends
      // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec)
      com.google.protobuf.MessageOrBuilder {

    /**
     *
     *
     * <pre>
     * Optional. The URI of a Cloud Storage bucket or folder (beginning with
     * `gs://` and ending with `/`) that contains the metadata import files for
     * this job.
     *
     * A metadata import file defines the values to set for each of the entries
     * and aspects in a metadata job. For more information about how to create a
     * metadata import file and the file requirements, see [Metadata import
     * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
     *
     * You can provide multiple metadata import files in the same metadata job.
     * The bucket or folder must contain at least one metadata import file, in
     * JSON Lines format (either `.json` or `.jsonl` file extension).
     *
     * In `FULL` entry sync mode, don't save the metadata import file in a
     * folder named `SOURCE_STORAGE_URI/deletions/`.
     *
     * **Caution**: If the metadata import file contains no data, all entries
     * and aspects that belong to the job's scope are deleted.
     * </pre>
     *
     * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The sourceStorageUri.
     */
    java.lang.String getSourceStorageUri();
    /**
     *
     *
     * <pre>
     * Optional. The URI of a Cloud Storage bucket or folder (beginning with
     * `gs://` and ending with `/`) that contains the metadata import files for
     * this job.
     *
     * A metadata import file defines the values to set for each of the entries
     * and aspects in a metadata job. For more information about how to create a
     * metadata import file and the file requirements, see [Metadata import
     * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
     *
     * You can provide multiple metadata import files in the same metadata job.
     * The bucket or folder must contain at least one metadata import file, in
     * JSON Lines format (either `.json` or `.jsonl` file extension).
     *
     * In `FULL` entry sync mode, don't save the metadata import file in a
     * folder named `SOURCE_STORAGE_URI/deletions/`.
     *
     * **Caution**: If the metadata import file contains no data, all entries
     * and aspects that belong to the job's scope are deleted.
     * </pre>
     *
     * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The bytes for sourceStorageUri.
     */
    com.google.protobuf.ByteString getSourceStorageUriBytes();

    /**
     *
     *
     * <pre>
     * Optional. The time when the process that created the metadata import
     * files began.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return Whether the sourceCreateTime field is set.
     */
    boolean hasSourceCreateTime();
    /**
     *
     *
     * <pre>
     * Optional. The time when the process that created the metadata import
     * files began.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The sourceCreateTime.
     */
    com.google.protobuf.Timestamp getSourceCreateTime();
    /**
     *
     *
     * <pre>
     * Optional. The time when the process that created the metadata import
     * files began.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    com.google.protobuf.TimestampOrBuilder getSourceCreateTimeOrBuilder();

    /**
     *
     *
     * <pre>
     * Required. A boundary on the scope of impact that the metadata import job
     * can have.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return Whether the scope field is set.
     */
    boolean hasScope();
    /**
     *
     *
     * <pre>
     * Required. A boundary on the scope of impact that the metadata import job
     * can have.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The scope.
     */
    com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope getScope();
    /**
     *
     *
     * <pre>
     * Required. A boundary on the scope of impact that the metadata import job
     * can have.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     */
    com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScopeOrBuilder
        getScopeOrBuilder();

    /**
     *
     *
     * <pre>
     * Required. The sync mode for entries.
     * Only `FULL` mode is supported for entries. All entries in the job's scope
     * are modified. If an entry exists in Dataplex but isn't included in the
     * metadata import file, the entry is deleted when you run the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The enum numeric value on the wire for entrySyncMode.
     */
    int getEntrySyncModeValue();
    /**
     *
     *
     * <pre>
     * Required. The sync mode for entries.
     * Only `FULL` mode is supported for entries. All entries in the job's scope
     * are modified. If an entry exists in Dataplex but isn't included in the
     * metadata import file, the entry is deleted when you run the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The entrySyncMode.
     */
    com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode getEntrySyncMode();

    /**
     *
     *
     * <pre>
     * Required. The sync mode for aspects.
     * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
     * only if the metadata import file includes a reference to the aspect in
     * the `update_mask` field and the `aspect_keys` field.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The enum numeric value on the wire for aspectSyncMode.
     */
    int getAspectSyncModeValue();
    /**
     *
     *
     * <pre>
     * Required. The sync mode for aspects.
     * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
     * only if the metadata import file includes a reference to the aspect in
     * the `update_mask` field and the `aspect_keys` field.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The aspectSyncMode.
     */
    com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode getAspectSyncMode();

    /**
     *
     *
     * <pre>
     * Optional. The level of logs to write to Cloud Logging for this job.
     *
     * Debug-level logs provide highly-detailed information for
     * troubleshooting, but their increased verbosity could incur [additional
     * costs](https://cloud.google.com/stackdriver/pricing) that might not be
     * merited for all jobs.
     *
     * If unspecified, defaults to `INFO`.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The enum numeric value on the wire for logLevel.
     */
    int getLogLevelValue();
    /**
     *
     *
     * <pre>
     * Optional. The level of logs to write to Cloud Logging for this job.
     *
     * Debug-level logs provide highly-detailed information for
     * troubleshooting, but their increased verbosity could incur [additional
     * costs](https://cloud.google.com/stackdriver/pricing) that might not be
     * merited for all jobs.
     *
     * If unspecified, defaults to `INFO`.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The logLevel.
     */
    com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel getLogLevel();
  }
  /**
   *
   *
   * <pre>
   * Job specification for a metadata import job
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.ImportJobSpec}
   */
  public static final class ImportJobSpec extends com.google.protobuf.GeneratedMessageV3
      implements
      // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec)
      ImportJobSpecOrBuilder {
    private static final long serialVersionUID = 0L;
    // Use ImportJobSpec.newBuilder() to construct.
    private ImportJobSpec(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }

    private ImportJobSpec() {
      sourceStorageUri_ = "";
      entrySyncMode_ = 0;
      aspectSyncMode_ = 0;
      logLevel_ = 0;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
      return new ImportJobSpec();
    }

    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.class,
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.Builder.class);
    }

    /**
     *
     *
     * <pre>
     * Specifies how the entries and aspects in a metadata job are updated.
     * </pre>
     *
     * Protobuf enum {@code google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode}
     */
    public enum SyncMode implements com.google.protobuf.ProtocolMessageEnum {
      /**
       *
       *
       * <pre>
       * Sync mode unspecified.
       * </pre>
       *
       * <code>SYNC_MODE_UNSPECIFIED = 0;</code>
       */
      SYNC_MODE_UNSPECIFIED(0),
      /**
       *
       *
       * <pre>
       * All resources in the job's scope are modified. If a resource exists in
       * Dataplex but isn't included in the metadata import file, the resource
       * is deleted when you run the metadata job. Use this mode to perform a
       * full sync of the set of entries in the job scope.
       * </pre>
       *
       * <code>FULL = 1;</code>
       */
      FULL(1),
      /**
       *
       *
       * <pre>
       * Only the entries and aspects that are explicitly included in the
       * metadata import file are modified. Use this mode to modify a subset of
       * resources while leaving unreferenced resources unchanged.
       * </pre>
       *
       * <code>INCREMENTAL = 2;</code>
       */
      INCREMENTAL(2),
      UNRECOGNIZED(-1),
      ;

      /**
       *
       *
       * <pre>
       * Sync mode unspecified.
       * </pre>
       *
       * <code>SYNC_MODE_UNSPECIFIED = 0;</code>
       */
      public static final int SYNC_MODE_UNSPECIFIED_VALUE = 0;
      /**
       *
       *
       * <pre>
       * All resources in the job's scope are modified. If a resource exists in
       * Dataplex but isn't included in the metadata import file, the resource
       * is deleted when you run the metadata job. Use this mode to perform a
       * full sync of the set of entries in the job scope.
       * </pre>
       *
       * <code>FULL = 1;</code>
       */
      public static final int FULL_VALUE = 1;
      /**
       *
       *
       * <pre>
       * Only the entries and aspects that are explicitly included in the
       * metadata import file are modified. Use this mode to modify a subset of
       * resources while leaving unreferenced resources unchanged.
       * </pre>
       *
       * <code>INCREMENTAL = 2;</code>
       */
      public static final int INCREMENTAL_VALUE = 2;

      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static SyncMode valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static SyncMode forNumber(int value) {
        switch (value) {
          case 0:
            return SYNC_MODE_UNSPECIFIED;
          case 1:
            return FULL;
          case 2:
            return INCREMENTAL;
          default:
            return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<SyncMode> internalGetValueMap() {
        return internalValueMap;
      }

      private static final com.google.protobuf.Internal.EnumLiteMap<SyncMode> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<SyncMode>() {
            public SyncMode findValueByNumber(int number) {
              return SyncMode.forNumber(number);
            }
          };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }

      public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType() {
        return getDescriptor();
      }

      public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDescriptor()
            .getEnumTypes()
            .get(0);
      }

      private static final SyncMode[] VALUES = values();

      public static SyncMode valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private SyncMode(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode)
    }

    /**
     *
     *
     * <pre>
     * The level of logs to write to Cloud Logging for this job.
     * </pre>
     *
     * Protobuf enum {@code google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel}
     */
    public enum LogLevel implements com.google.protobuf.ProtocolMessageEnum {
      /**
       *
       *
       * <pre>
       * Log level unspecified.
       * </pre>
       *
       * <code>LOG_LEVEL_UNSPECIFIED = 0;</code>
       */
      LOG_LEVEL_UNSPECIFIED(0),
      /**
       *
       *
       * <pre>
       * Debug-level logging. Captures detailed logs for each import item. Use
       * debug-level logging to troubleshoot issues with specific import items.
       * For example, use debug-level logging to identify resources that are
       * missing from the job scope, entries or aspects that don't conform to
       * the associated entry type or aspect type, or other misconfigurations
       * with the metadata import file.
       *
       * Depending on the size of your metadata job and the number of logs that
       * are generated, debug-level logging might incur
       * [additional costs](https://cloud.google.com/stackdriver/pricing).
       * </pre>
       *
       * <code>DEBUG = 1;</code>
       */
      DEBUG(1),
      /**
       *
       *
       * <pre>
       * Info-level logging. Captures logs at the overall job level. Includes
       * aggregate logs about import items, but doesn't specify which import
       * item has an error.
       * </pre>
       *
       * <code>INFO = 2;</code>
       */
      INFO(2),
      UNRECOGNIZED(-1),
      ;

      /**
       *
       *
       * <pre>
       * Log level unspecified.
       * </pre>
       *
       * <code>LOG_LEVEL_UNSPECIFIED = 0;</code>
       */
      public static final int LOG_LEVEL_UNSPECIFIED_VALUE = 0;
      /**
       *
       *
       * <pre>
       * Debug-level logging. Captures detailed logs for each import item. Use
       * debug-level logging to troubleshoot issues with specific import items.
       * For example, use debug-level logging to identify resources that are
       * missing from the job scope, entries or aspects that don't conform to
       * the associated entry type or aspect type, or other misconfigurations
       * with the metadata import file.
       *
       * Depending on the size of your metadata job and the number of logs that
       * are generated, debug-level logging might incur
       * [additional costs](https://cloud.google.com/stackdriver/pricing).
       * </pre>
       *
       * <code>DEBUG = 1;</code>
       */
      public static final int DEBUG_VALUE = 1;
      /**
       *
       *
       * <pre>
       * Info-level logging. Captures logs at the overall job level. Includes
       * aggregate logs about import items, but doesn't specify which import
       * item has an error.
       * </pre>
       *
       * <code>INFO = 2;</code>
       */
      public static final int INFO_VALUE = 2;

      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static LogLevel valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static LogLevel forNumber(int value) {
        switch (value) {
          case 0:
            return LOG_LEVEL_UNSPECIFIED;
          case 1:
            return DEBUG;
          case 2:
            return INFO;
          default:
            return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<LogLevel> internalGetValueMap() {
        return internalValueMap;
      }

      private static final com.google.protobuf.Internal.EnumLiteMap<LogLevel> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LogLevel>() {
            public LogLevel findValueByNumber(int number) {
              return LogLevel.forNumber(number);
            }
          };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }

      public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType() {
        return getDescriptor();
      }

      public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDescriptor()
            .getEnumTypes()
            .get(1);
      }

      private static final LogLevel[] VALUES = values();

      public static LogLevel valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private LogLevel(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel)
    }

    public interface ImportJobScopeOrBuilder
        extends
        // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope)
        com.google.protobuf.MessageOrBuilder {

      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return A list containing the entryGroups.
       */
      java.util.List<java.lang.String> getEntryGroupsList();
      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The count of entryGroups.
       */
      int getEntryGroupsCount();
      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the element to return.
       * @return The entryGroups at the given index.
       */
      java.lang.String getEntryGroups(int index);
      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the entryGroups at the given index.
       */
      com.google.protobuf.ByteString getEntryGroupsBytes(int index);

      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return A list containing the entryTypes.
       */
      java.util.List<java.lang.String> getEntryTypesList();
      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The count of entryTypes.
       */
      int getEntryTypesCount();
      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the element to return.
       * @return The entryTypes at the given index.
       */
      java.lang.String getEntryTypes(int index);
      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the entryTypes at the given index.
       */
      com.google.protobuf.ByteString getEntryTypesBytes(int index);

      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return A list containing the aspectTypes.
       */
      java.util.List<java.lang.String> getAspectTypesList();
      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The count of aspectTypes.
       */
      int getAspectTypesCount();
      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the element to return.
       * @return The aspectTypes at the given index.
       */
      java.lang.String getAspectTypes(int index);
      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the aspectTypes at the given index.
       */
      com.google.protobuf.ByteString getAspectTypesBytes(int index);
    }
    /**
     *
     *
     * <pre>
     * A boundary on the scope of impact that the metadata import job can have.
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope}
     */
    public static final class ImportJobScope extends com.google.protobuf.GeneratedMessageV3
        implements
        // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope)
        ImportJobScopeOrBuilder {
      private static final long serialVersionUID = 0L;
      // Use ImportJobScope.newBuilder() to construct.
      private ImportJobScope(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }

      private ImportJobScope() {
        entryGroups_ = com.google.protobuf.LazyStringArrayList.emptyList();
        entryTypes_ = com.google.protobuf.LazyStringArrayList.emptyList();
        aspectTypes_ = com.google.protobuf.LazyStringArrayList.emptyList();
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
        return new ImportJobScope();
      }

      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_ImportJobScope_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_ImportJobScope_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.class,
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.Builder
                    .class);
      }

      public static final int ENTRY_GROUPS_FIELD_NUMBER = 1;

      @SuppressWarnings("serial")
      private com.google.protobuf.LazyStringArrayList entryGroups_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return A list containing the entryGroups.
       */
      public com.google.protobuf.ProtocolStringList getEntryGroupsList() {
        return entryGroups_;
      }
      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The count of entryGroups.
       */
      public int getEntryGroupsCount() {
        return entryGroups_.size();
      }
      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the element to return.
       * @return The entryGroups at the given index.
       */
      public java.lang.String getEntryGroups(int index) {
        return entryGroups_.get(index);
      }
      /**
       *
       *
       * <pre>
       * Required. The entry group that is in scope for the import job,
       * specified as a relative resource name in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
       * Only entries that belong to the specified entry group are affected by
       * the job.
       *
       * Must contain exactly one element. The entry group and the job
       * must be in the same location.
       * </pre>
       *
       * <code>
       * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the entryGroups at the given index.
       */
      public com.google.protobuf.ByteString getEntryGroupsBytes(int index) {
        return entryGroups_.getByteString(index);
      }

      public static final int ENTRY_TYPES_FIELD_NUMBER = 2;

      @SuppressWarnings("serial")
      private com.google.protobuf.LazyStringArrayList entryTypes_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return A list containing the entryTypes.
       */
      public com.google.protobuf.ProtocolStringList getEntryTypesList() {
        return entryTypes_;
      }
      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The count of entryTypes.
       */
      public int getEntryTypesCount() {
        return entryTypes_.size();
      }
      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the element to return.
       * @return The entryTypes at the given index.
       */
      public java.lang.String getEntryTypes(int index) {
        return entryTypes_.get(index);
      }
      /**
       *
       *
       * <pre>
       * Required. The entry types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
       * The job modifies only the entries that belong to these entry types.
       *
       * If the metadata import file attempts to modify an entry whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an entry type must either match the location of the
       * job, or the entry type must be global.
       * </pre>
       *
       * <code>
       * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the entryTypes at the given index.
       */
      public com.google.protobuf.ByteString getEntryTypesBytes(int index) {
        return entryTypes_.getByteString(index);
      }

      public static final int ASPECT_TYPES_FIELD_NUMBER = 3;

      @SuppressWarnings("serial")
      private com.google.protobuf.LazyStringArrayList aspectTypes_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return A list containing the aspectTypes.
       */
      public com.google.protobuf.ProtocolStringList getAspectTypesList() {
        return aspectTypes_;
      }
      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The count of aspectTypes.
       */
      public int getAspectTypesCount() {
        return aspectTypes_.size();
      }
      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the element to return.
       * @return The aspectTypes at the given index.
       */
      public java.lang.String getAspectTypes(int index) {
        return aspectTypes_.get(index);
      }
      /**
       *
       *
       * <pre>
       * Optional. The aspect types that are in scope for the import job,
       * specified as relative resource names in the format
       * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
       * The job modifies only the aspects that belong to these aspect types.
       *
       * If the metadata import file attempts to modify an aspect whose type
       * isn't included in this list, the import job is halted before modifying
       * any entries or aspects.
       *
       * The location of an aspect type must either match the location of the
       * job, or the aspect type must be global.
       * </pre>
       *
       * <code>
       * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the aspectTypes at the given index.
       */
      public com.google.protobuf.ByteString getAspectTypesBytes(int index) {
        return aspectTypes_.getByteString(index);
      }

      private byte memoizedIsInitialized = -1;

      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
        for (int i = 0; i < entryGroups_.size(); i++) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, entryGroups_.getRaw(i));
        }
        for (int i = 0; i < entryTypes_.size(); i++) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 2, entryTypes_.getRaw(i));
        }
        for (int i = 0; i < aspectTypes_.size(); i++) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 3, aspectTypes_.getRaw(i));
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        {
          int dataSize = 0;
          for (int i = 0; i < entryGroups_.size(); i++) {
            dataSize += computeStringSizeNoTag(entryGroups_.getRaw(i));
          }
          size += dataSize;
          size += 1 * getEntryGroupsList().size();
        }
        {
          int dataSize = 0;
          for (int i = 0; i < entryTypes_.size(); i++) {
            dataSize += computeStringSizeNoTag(entryTypes_.getRaw(i));
          }
          size += dataSize;
          size += 1 * getEntryTypesList().size();
        }
        {
          int dataSize = 0;
          for (int i = 0; i < aspectTypes_.size(); i++) {
            dataSize += computeStringSizeNoTag(aspectTypes_.getRaw(i));
          }
          size += dataSize;
          size += 1 * getAspectTypesList().size();
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
          return true;
        }
        if (!(obj
            instanceof com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope)) {
          return super.equals(obj);
        }
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope other =
            (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope) obj;

        if (!getEntryGroupsList().equals(other.getEntryGroupsList())) return false;
        if (!getEntryTypesList().equals(other.getEntryTypesList())) return false;
        if (!getAspectTypesList().equals(other.getAspectTypesList())) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (getEntryGroupsCount() > 0) {
          hash = (37 * hash) + ENTRY_GROUPS_FIELD_NUMBER;
          hash = (53 * hash) + getEntryGroupsList().hashCode();
        }
        if (getEntryTypesCount() > 0) {
          hash = (37 * hash) + ENTRY_TYPES_FIELD_NUMBER;
          hash = (53 * hash) + getEntryTypesList().hashCode();
        }
        if (getAspectTypesCount() > 0) {
          hash = (37 * hash) + ASPECT_TYPES_FIELD_NUMBER;
          hash = (53 * hash) + getAspectTypesList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          byte[] data) throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          java.io.InputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
            PARSER, input, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
          parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
          parseDelimitedFrom(
              java.io.InputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
            PARSER, input, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          com.google.protobuf.CodedInputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
            PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() {
        return newBuilder();
      }

      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }

      public static Builder newBuilder(
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }

      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       *
       *
       * <pre>
       * A boundary on the scope of impact that the metadata import job can have.
       * </pre>
       *
       * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope}
       */
      public static final class Builder
          extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
          implements
          // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope)
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScopeOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
          return com.google.cloud.dataplex.v1.CatalogProto
              .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_ImportJobScope_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return com.google.cloud.dataplex.v1.CatalogProto
              .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_ImportJobScope_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.class,
                  com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.Builder
                      .class);
        }

        // Construct using
        // com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.newBuilder()
        private Builder() {}

        private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
        }

        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          entryGroups_ = com.google.protobuf.LazyStringArrayList.emptyList();
          entryTypes_ = com.google.protobuf.LazyStringArrayList.emptyList();
          aspectTypes_ = com.google.protobuf.LazyStringArrayList.emptyList();
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
          return com.google.cloud.dataplex.v1.CatalogProto
              .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_ImportJobScope_descriptor;
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
            getDefaultInstanceForType() {
          return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
              .getDefaultInstance();
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope build() {
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope result =
              buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
            buildPartial() {
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope result =
              new com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope(this);
          if (bitField0_ != 0) {
            buildPartial0(result);
          }
          onBuilt();
          return result;
        }

        private void buildPartial0(
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope result) {
          int from_bitField0_ = bitField0_;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            entryGroups_.makeImmutable();
            result.entryGroups_ = entryGroups_;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            entryTypes_.makeImmutable();
            result.entryTypes_ = entryTypes_;
          }
          if (((from_bitField0_ & 0x00000004) != 0)) {
            aspectTypes_.makeImmutable();
            result.aspectTypes_ = aspectTypes_;
          }
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }

        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
          return super.setField(field, value);
        }

        @java.lang.Override
        public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }

        @java.lang.Override
        public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }

        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index,
            java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }

        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }

        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other
              instanceof com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope) {
            return mergeFrom(
                (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope) other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope other) {
          if (other
              == com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
                  .getDefaultInstance()) return this;
          if (!other.entryGroups_.isEmpty()) {
            if (entryGroups_.isEmpty()) {
              entryGroups_ = other.entryGroups_;
              bitField0_ |= 0x00000001;
            } else {
              ensureEntryGroupsIsMutable();
              entryGroups_.addAll(other.entryGroups_);
            }
            onChanged();
          }
          if (!other.entryTypes_.isEmpty()) {
            if (entryTypes_.isEmpty()) {
              entryTypes_ = other.entryTypes_;
              bitField0_ |= 0x00000002;
            } else {
              ensureEntryTypesIsMutable();
              entryTypes_.addAll(other.entryTypes_);
            }
            onChanged();
          }
          if (!other.aspectTypes_.isEmpty()) {
            if (aspectTypes_.isEmpty()) {
              aspectTypes_ = other.aspectTypes_;
              bitField0_ |= 0x00000004;
            } else {
              ensureAspectTypesIsMutable();
              aspectTypes_.addAll(other.aspectTypes_);
            }
            onChanged();
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10:
                  {
                    java.lang.String s = input.readStringRequireUtf8();
                    ensureEntryGroupsIsMutable();
                    entryGroups_.add(s);
                    break;
                  } // case 10
                case 18:
                  {
                    java.lang.String s = input.readStringRequireUtf8();
                    ensureEntryTypesIsMutable();
                    entryTypes_.add(s);
                    break;
                  } // case 18
                case 26:
                  {
                    java.lang.String s = input.readStringRequireUtf8();
                    ensureAspectTypesIsMutable();
                    aspectTypes_.add(s);
                    break;
                  } // case 26
                default:
                  {
                    if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                      done = true; // was an endgroup tag
                    }
                    break;
                  } // default:
              } // switch (tag)
            } // while (!done)
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }

        private int bitField0_;

        private com.google.protobuf.LazyStringArrayList entryGroups_ =
            com.google.protobuf.LazyStringArrayList.emptyList();

        private void ensureEntryGroupsIsMutable() {
          if (!entryGroups_.isModifiable()) {
            entryGroups_ = new com.google.protobuf.LazyStringArrayList(entryGroups_);
          }
          bitField0_ |= 0x00000001;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return A list containing the entryGroups.
         */
        public com.google.protobuf.ProtocolStringList getEntryGroupsList() {
          entryGroups_.makeImmutable();
          return entryGroups_;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return The count of entryGroups.
         */
        public int getEntryGroupsCount() {
          return entryGroups_.size();
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index of the element to return.
         * @return The entryGroups at the given index.
         */
        public java.lang.String getEntryGroups(int index) {
          return entryGroups_.get(index);
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index of the value to return.
         * @return The bytes of the entryGroups at the given index.
         */
        public com.google.protobuf.ByteString getEntryGroupsBytes(int index) {
          return entryGroups_.getByteString(index);
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index to set the value at.
         * @param value The entryGroups to set.
         * @return This builder for chaining.
         */
        public Builder setEntryGroups(int index, java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryGroupsIsMutable();
          entryGroups_.set(index, value);
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param value The entryGroups to add.
         * @return This builder for chaining.
         */
        public Builder addEntryGroups(java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryGroupsIsMutable();
          entryGroups_.add(value);
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param values The entryGroups to add.
         * @return This builder for chaining.
         */
        public Builder addAllEntryGroups(java.lang.Iterable<java.lang.String> values) {
          ensureEntryGroupsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(values, entryGroups_);
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return This builder for chaining.
         */
        public Builder clearEntryGroups() {
          entryGroups_ = com.google.protobuf.LazyStringArrayList.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          ;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry group that is in scope for the import job,
         * specified as a relative resource name in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryGroups/{entry_group_id}`.
         * Only entries that belong to the specified entry group are affected by
         * the job.
         *
         * Must contain exactly one element. The entry group and the job
         * must be in the same location.
         * </pre>
         *
         * <code>
         * repeated string entry_groups = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param value The bytes of the entryGroups to add.
         * @return This builder for chaining.
         */
        public Builder addEntryGroupsBytes(com.google.protobuf.ByteString value) {
          if (value == null) {
            throw new NullPointerException();
          }
          checkByteStringIsUtf8(value);
          ensureEntryGroupsIsMutable();
          entryGroups_.add(value);
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }

        private com.google.protobuf.LazyStringArrayList entryTypes_ =
            com.google.protobuf.LazyStringArrayList.emptyList();

        private void ensureEntryTypesIsMutable() {
          if (!entryTypes_.isModifiable()) {
            entryTypes_ = new com.google.protobuf.LazyStringArrayList(entryTypes_);
          }
          bitField0_ |= 0x00000002;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return A list containing the entryTypes.
         */
        public com.google.protobuf.ProtocolStringList getEntryTypesList() {
          entryTypes_.makeImmutable();
          return entryTypes_;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return The count of entryTypes.
         */
        public int getEntryTypesCount() {
          return entryTypes_.size();
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index of the element to return.
         * @return The entryTypes at the given index.
         */
        public java.lang.String getEntryTypes(int index) {
          return entryTypes_.get(index);
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index of the value to return.
         * @return The bytes of the entryTypes at the given index.
         */
        public com.google.protobuf.ByteString getEntryTypesBytes(int index) {
          return entryTypes_.getByteString(index);
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index to set the value at.
         * @param value The entryTypes to set.
         * @return This builder for chaining.
         */
        public Builder setEntryTypes(int index, java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryTypesIsMutable();
          entryTypes_.set(index, value);
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param value The entryTypes to add.
         * @return This builder for chaining.
         */
        public Builder addEntryTypes(java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEntryTypesIsMutable();
          entryTypes_.add(value);
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param values The entryTypes to add.
         * @return This builder for chaining.
         */
        public Builder addAllEntryTypes(java.lang.Iterable<java.lang.String> values) {
          ensureEntryTypesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(values, entryTypes_);
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return This builder for chaining.
         */
        public Builder clearEntryTypes() {
          entryTypes_ = com.google.protobuf.LazyStringArrayList.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          ;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Required. The entry types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/entryTypes/{entry_type_id}`.
         * The job modifies only the entries that belong to these entry types.
         *
         * If the metadata import file attempts to modify an entry whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an entry type must either match the location of the
         * job, or the entry type must be global.
         * </pre>
         *
         * <code>
         * repeated string entry_types = 2 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param value The bytes of the entryTypes to add.
         * @return This builder for chaining.
         */
        public Builder addEntryTypesBytes(com.google.protobuf.ByteString value) {
          if (value == null) {
            throw new NullPointerException();
          }
          checkByteStringIsUtf8(value);
          ensureEntryTypesIsMutable();
          entryTypes_.add(value);
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }

        private com.google.protobuf.LazyStringArrayList aspectTypes_ =
            com.google.protobuf.LazyStringArrayList.emptyList();

        private void ensureAspectTypesIsMutable() {
          if (!aspectTypes_.isModifiable()) {
            aspectTypes_ = new com.google.protobuf.LazyStringArrayList(aspectTypes_);
          }
          bitField0_ |= 0x00000004;
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return A list containing the aspectTypes.
         */
        public com.google.protobuf.ProtocolStringList getAspectTypesList() {
          aspectTypes_.makeImmutable();
          return aspectTypes_;
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return The count of aspectTypes.
         */
        public int getAspectTypesCount() {
          return aspectTypes_.size();
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index of the element to return.
         * @return The aspectTypes at the given index.
         */
        public java.lang.String getAspectTypes(int index) {
          return aspectTypes_.get(index);
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index of the value to return.
         * @return The bytes of the aspectTypes at the given index.
         */
        public com.google.protobuf.ByteString getAspectTypesBytes(int index) {
          return aspectTypes_.getByteString(index);
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param index The index to set the value at.
         * @param value The aspectTypes to set.
         * @return This builder for chaining.
         */
        public Builder setAspectTypes(int index, java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAspectTypesIsMutable();
          aspectTypes_.set(index, value);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param value The aspectTypes to add.
         * @return This builder for chaining.
         */
        public Builder addAspectTypes(java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAspectTypesIsMutable();
          aspectTypes_.add(value);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param values The aspectTypes to add.
         * @return This builder for chaining.
         */
        public Builder addAllAspectTypes(java.lang.Iterable<java.lang.String> values) {
          ensureAspectTypesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(values, aspectTypes_);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @return This builder for chaining.
         */
        public Builder clearAspectTypes() {
          aspectTypes_ = com.google.protobuf.LazyStringArrayList.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          ;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The aspect types that are in scope for the import job,
         * specified as relative resource names in the format
         * `projects/{project_number_or_id}/locations/{location_id}/aspectTypes/{aspect_type_id}`.
         * The job modifies only the aspects that belong to these aspect types.
         *
         * If the metadata import file attempts to modify an aspect whose type
         * isn't included in this list, the import job is halted before modifying
         * any entries or aspects.
         *
         * The location of an aspect type must either match the location of the
         * job, or the aspect type must be global.
         * </pre>
         *
         * <code>
         * repeated string aspect_types = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
         * </code>
         *
         * @param value The bytes of the aspectTypes to add.
         * @return This builder for chaining.
         */
        public Builder addAspectTypesBytes(com.google.protobuf.ByteString value) {
          if (value == null) {
            throw new NullPointerException();
          }
          checkByteStringIsUtf8(value);
          ensureAspectTypesIsMutable();
          aspectTypes_.add(value);
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }

        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }

        // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope)
      }

      // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope)
      private static final com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
          DEFAULT_INSTANCE;

      static {
        DEFAULT_INSTANCE =
            new com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope();
      }

      public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
          getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<ImportJobScope> PARSER =
          new com.google.protobuf.AbstractParser<ImportJobScope>() {
            @java.lang.Override
            public ImportJobScope parsePartialFrom(
                com.google.protobuf.CodedInputStream input,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws com.google.protobuf.InvalidProtocolBufferException {
              Builder builder = newBuilder();
              try {
                builder.mergeFrom(input, extensionRegistry);
              } catch (com.google.protobuf.InvalidProtocolBufferException e) {
                throw e.setUnfinishedMessage(builder.buildPartial());
              } catch (com.google.protobuf.UninitializedMessageException e) {
                throw e.asInvalidProtocolBufferException()
                    .setUnfinishedMessage(builder.buildPartial());
              } catch (java.io.IOException e) {
                throw new com.google.protobuf.InvalidProtocolBufferException(e)
                    .setUnfinishedMessage(builder.buildPartial());
              }
              return builder.buildPartial();
            }
          };

      public static com.google.protobuf.Parser<ImportJobScope> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<ImportJobScope> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
          getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }
    }

    private int bitField0_;
    public static final int SOURCE_STORAGE_URI_FIELD_NUMBER = 1;

    @SuppressWarnings("serial")
    private volatile java.lang.Object sourceStorageUri_ = "";
    /**
     *
     *
     * <pre>
     * Optional. The URI of a Cloud Storage bucket or folder (beginning with
     * `gs://` and ending with `/`) that contains the metadata import files for
     * this job.
     *
     * A metadata import file defines the values to set for each of the entries
     * and aspects in a metadata job. For more information about how to create a
     * metadata import file and the file requirements, see [Metadata import
     * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
     *
     * You can provide multiple metadata import files in the same metadata job.
     * The bucket or folder must contain at least one metadata import file, in
     * JSON Lines format (either `.json` or `.jsonl` file extension).
     *
     * In `FULL` entry sync mode, don't save the metadata import file in a
     * folder named `SOURCE_STORAGE_URI/deletions/`.
     *
     * **Caution**: If the metadata import file contains no data, all entries
     * and aspects that belong to the job's scope are deleted.
     * </pre>
     *
     * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The sourceStorageUri.
     */
    @java.lang.Override
    public java.lang.String getSourceStorageUri() {
      java.lang.Object ref = sourceStorageUri_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        sourceStorageUri_ = s;
        return s;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. The URI of a Cloud Storage bucket or folder (beginning with
     * `gs://` and ending with `/`) that contains the metadata import files for
     * this job.
     *
     * A metadata import file defines the values to set for each of the entries
     * and aspects in a metadata job. For more information about how to create a
     * metadata import file and the file requirements, see [Metadata import
     * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
     *
     * You can provide multiple metadata import files in the same metadata job.
     * The bucket or folder must contain at least one metadata import file, in
     * JSON Lines format (either `.json` or `.jsonl` file extension).
     *
     * In `FULL` entry sync mode, don't save the metadata import file in a
     * folder named `SOURCE_STORAGE_URI/deletions/`.
     *
     * **Caution**: If the metadata import file contains no data, all entries
     * and aspects that belong to the job's scope are deleted.
     * </pre>
     *
     * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The bytes for sourceStorageUri.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getSourceStorageUriBytes() {
      java.lang.Object ref = sourceStorageUri_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
        sourceStorageUri_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SOURCE_CREATE_TIME_FIELD_NUMBER = 5;
    private com.google.protobuf.Timestamp sourceCreateTime_;
    /**
     *
     *
     * <pre>
     * Optional. The time when the process that created the metadata import
     * files began.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return Whether the sourceCreateTime field is set.
     */
    @java.lang.Override
    public boolean hasSourceCreateTime() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     *
     *
     * <pre>
     * Optional. The time when the process that created the metadata import
     * files began.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The sourceCreateTime.
     */
    @java.lang.Override
    public com.google.protobuf.Timestamp getSourceCreateTime() {
      return sourceCreateTime_ == null
          ? com.google.protobuf.Timestamp.getDefaultInstance()
          : sourceCreateTime_;
    }
    /**
     *
     *
     * <pre>
     * Optional. The time when the process that created the metadata import
     * files began.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    @java.lang.Override
    public com.google.protobuf.TimestampOrBuilder getSourceCreateTimeOrBuilder() {
      return sourceCreateTime_ == null
          ? com.google.protobuf.Timestamp.getDefaultInstance()
          : sourceCreateTime_;
    }

    public static final int SCOPE_FIELD_NUMBER = 2;
    private com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope_;
    /**
     *
     *
     * <pre>
     * Required. A boundary on the scope of impact that the metadata import job
     * can have.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return Whether the scope field is set.
     */
    @java.lang.Override
    public boolean hasScope() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     *
     *
     * <pre>
     * Required. A boundary on the scope of impact that the metadata import job
     * can have.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The scope.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope getScope() {
      return scope_ == null
          ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
              .getDefaultInstance()
          : scope_;
    }
    /**
     *
     *
     * <pre>
     * Required. A boundary on the scope of impact that the metadata import job
     * can have.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScopeOrBuilder
        getScopeOrBuilder() {
      return scope_ == null
          ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
              .getDefaultInstance()
          : scope_;
    }

    public static final int ENTRY_SYNC_MODE_FIELD_NUMBER = 3;
    private int entrySyncMode_ = 0;
    /**
     *
     *
     * <pre>
     * Required. The sync mode for entries.
     * Only `FULL` mode is supported for entries. All entries in the job's scope
     * are modified. If an entry exists in Dataplex but isn't included in the
     * metadata import file, the entry is deleted when you run the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The enum numeric value on the wire for entrySyncMode.
     */
    @java.lang.Override
    public int getEntrySyncModeValue() {
      return entrySyncMode_;
    }
    /**
     *
     *
     * <pre>
     * Required. The sync mode for entries.
     * Only `FULL` mode is supported for entries. All entries in the job's scope
     * are modified. If an entry exists in Dataplex but isn't included in the
     * metadata import file, the entry is deleted when you run the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The entrySyncMode.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode getEntrySyncMode() {
      com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode result =
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.forNumber(entrySyncMode_);
      return result == null
          ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.UNRECOGNIZED
          : result;
    }

    public static final int ASPECT_SYNC_MODE_FIELD_NUMBER = 4;
    private int aspectSyncMode_ = 0;
    /**
     *
     *
     * <pre>
     * Required. The sync mode for aspects.
     * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
     * only if the metadata import file includes a reference to the aspect in
     * the `update_mask` field and the `aspect_keys` field.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The enum numeric value on the wire for aspectSyncMode.
     */
    @java.lang.Override
    public int getAspectSyncModeValue() {
      return aspectSyncMode_;
    }
    /**
     *
     *
     * <pre>
     * Required. The sync mode for aspects.
     * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
     * only if the metadata import file includes a reference to the aspect in
     * the `update_mask` field and the `aspect_keys` field.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The aspectSyncMode.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode getAspectSyncMode() {
      com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode result =
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.forNumber(
              aspectSyncMode_);
      return result == null
          ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.UNRECOGNIZED
          : result;
    }

    public static final int LOG_LEVEL_FIELD_NUMBER = 6;
    private int logLevel_ = 0;
    /**
     *
     *
     * <pre>
     * Optional. The level of logs to write to Cloud Logging for this job.
     *
     * Debug-level logs provide highly-detailed information for
     * troubleshooting, but their increased verbosity could incur [additional
     * costs](https://cloud.google.com/stackdriver/pricing) that might not be
     * merited for all jobs.
     *
     * If unspecified, defaults to `INFO`.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The enum numeric value on the wire for logLevel.
     */
    @java.lang.Override
    public int getLogLevelValue() {
      return logLevel_;
    }
    /**
     *
     *
     * <pre>
     * Optional. The level of logs to write to Cloud Logging for this job.
     *
     * Debug-level logs provide highly-detailed information for
     * troubleshooting, but their increased verbosity could incur [additional
     * costs](https://cloud.google.com/stackdriver/pricing) that might not be
     * merited for all jobs.
     *
     * If unspecified, defaults to `INFO`.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The logLevel.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel getLogLevel() {
      com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel result =
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel.forNumber(logLevel_);
      return result == null
          ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel.UNRECOGNIZED
          : result;
    }

    private byte memoizedIsInitialized = -1;

    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sourceStorageUri_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, sourceStorageUri_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(2, getScope());
      }
      if (entrySyncMode_
          != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.SYNC_MODE_UNSPECIFIED
              .getNumber()) {
        output.writeEnum(3, entrySyncMode_);
      }
      if (aspectSyncMode_
          != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.SYNC_MODE_UNSPECIFIED
              .getNumber()) {
        output.writeEnum(4, aspectSyncMode_);
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(5, getSourceCreateTime());
      }
      if (logLevel_
          != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel.LOG_LEVEL_UNSPECIFIED
              .getNumber()) {
        output.writeEnum(6, logLevel_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(sourceStorageUri_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, sourceStorageUri_);
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream.computeMessageSize(2, getScope());
      }
      if (entrySyncMode_
          != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.SYNC_MODE_UNSPECIFIED
              .getNumber()) {
        size += com.google.protobuf.CodedOutputStream.computeEnumSize(3, entrySyncMode_);
      }
      if (aspectSyncMode_
          != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.SYNC_MODE_UNSPECIFIED
              .getNumber()) {
        size += com.google.protobuf.CodedOutputStream.computeEnumSize(4, aspectSyncMode_);
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream.computeMessageSize(5, getSourceCreateTime());
      }
      if (logLevel_
          != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel.LOG_LEVEL_UNSPECIFIED
              .getNumber()) {
        size += com.google.protobuf.CodedOutputStream.computeEnumSize(6, logLevel_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
        return true;
      }
      if (!(obj instanceof com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec)) {
        return super.equals(obj);
      }
      com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec other =
          (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) obj;

      if (!getSourceStorageUri().equals(other.getSourceStorageUri())) return false;
      if (hasSourceCreateTime() != other.hasSourceCreateTime()) return false;
      if (hasSourceCreateTime()) {
        if (!getSourceCreateTime().equals(other.getSourceCreateTime())) return false;
      }
      if (hasScope() != other.hasScope()) return false;
      if (hasScope()) {
        if (!getScope().equals(other.getScope())) return false;
      }
      if (entrySyncMode_ != other.entrySyncMode_) return false;
      if (aspectSyncMode_ != other.aspectSyncMode_) return false;
      if (logLevel_ != other.logLevel_) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + SOURCE_STORAGE_URI_FIELD_NUMBER;
      hash = (53 * hash) + getSourceStorageUri().hashCode();
      if (hasSourceCreateTime()) {
        hash = (37 * hash) + SOURCE_CREATE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + getSourceCreateTime().hashCode();
      }
      if (hasScope()) {
        hash = (37 * hash) + SCOPE_FIELD_NUMBER;
        hash = (53 * hash) + getScope().hashCode();
      }
      hash = (37 * hash) + ENTRY_SYNC_MODE_FIELD_NUMBER;
      hash = (53 * hash) + entrySyncMode_;
      hash = (37 * hash) + ASPECT_SYNC_MODE_FIELD_NUMBER;
      hash = (53 * hash) + aspectSyncMode_;
      hash = (37 * hash) + LOG_LEVEL_FIELD_NUMBER;
      hash = (53 * hash) + logLevel_;
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseDelimitedFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseDelimitedFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        com.google.protobuf.CodedInputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() {
      return newBuilder();
    }

    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }

    public static Builder newBuilder(
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }

    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     *
     *
     * <pre>
     * Job specification for a metadata import job
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.ImportJobSpec}
     */
    public static final class Builder
        extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
        implements
        // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec)
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpecOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.class,
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.Builder.class);
      }

      // Construct using com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }

      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {
          getSourceCreateTimeFieldBuilder();
          getScopeFieldBuilder();
        }
      }

      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        sourceStorageUri_ = "";
        sourceCreateTime_ = null;
        if (sourceCreateTimeBuilder_ != null) {
          sourceCreateTimeBuilder_.dispose();
          sourceCreateTimeBuilder_ = null;
        }
        scope_ = null;
        if (scopeBuilder_ != null) {
          scopeBuilder_.dispose();
          scopeBuilder_ = null;
        }
        entrySyncMode_ = 0;
        aspectSyncMode_ = 0;
        logLevel_ = 0;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_ImportJobSpec_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec getDefaultInstanceForType() {
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec build() {
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec buildPartial() {
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec result =
            new com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec(this);
        if (bitField0_ != 0) {
          buildPartial0(result);
        }
        onBuilt();
        return result;
      }

      private void buildPartial0(com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.sourceStorageUri_ = sourceStorageUri_;
        }
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.sourceCreateTime_ =
              sourceCreateTimeBuilder_ == null
                  ? sourceCreateTime_
                  : sourceCreateTimeBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.scope_ = scopeBuilder_ == null ? scope_ : scopeBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.entrySyncMode_ = entrySyncMode_;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.aspectSyncMode_ = aspectSyncMode_;
        }
        if (((from_bitField0_ & 0x00000020) != 0)) {
          result.logLevel_ = logLevel_;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }

      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.setField(field, value);
      }

      @java.lang.Override
      public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }

      @java.lang.Override
      public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }

      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index,
          java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }

      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }

      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) {
          return mergeFrom((com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec other) {
        if (other == com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance())
          return this;
        if (!other.getSourceStorageUri().isEmpty()) {
          sourceStorageUri_ = other.sourceStorageUri_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.hasSourceCreateTime()) {
          mergeSourceCreateTime(other.getSourceCreateTime());
        }
        if (other.hasScope()) {
          mergeScope(other.getScope());
        }
        if (other.entrySyncMode_ != 0) {
          setEntrySyncModeValue(other.getEntrySyncModeValue());
        }
        if (other.aspectSyncMode_ != 0) {
          setAspectSyncModeValue(other.getAspectSyncModeValue());
        }
        if (other.logLevel_ != 0) {
          setLogLevelValue(other.getLogLevelValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10:
                {
                  sourceStorageUri_ = input.readStringRequireUtf8();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 10
              case 18:
                {
                  input.readMessage(getScopeFieldBuilder().getBuilder(), extensionRegistry);
                  bitField0_ |= 0x00000004;
                  break;
                } // case 18
              case 24:
                {
                  entrySyncMode_ = input.readEnum();
                  bitField0_ |= 0x00000008;
                  break;
                } // case 24
              case 32:
                {
                  aspectSyncMode_ = input.readEnum();
                  bitField0_ |= 0x00000010;
                  break;
                } // case 32
              case 42:
                {
                  input.readMessage(
                      getSourceCreateTimeFieldBuilder().getBuilder(), extensionRegistry);
                  bitField0_ |= 0x00000002;
                  break;
                } // case 42
              case 48:
                {
                  logLevel_ = input.readEnum();
                  bitField0_ |= 0x00000020;
                  break;
                } // case 48
              default:
                {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private int bitField0_;

      private java.lang.Object sourceStorageUri_ = "";
      /**
       *
       *
       * <pre>
       * Optional. The URI of a Cloud Storage bucket or folder (beginning with
       * `gs://` and ending with `/`) that contains the metadata import files for
       * this job.
       *
       * A metadata import file defines the values to set for each of the entries
       * and aspects in a metadata job. For more information about how to create a
       * metadata import file and the file requirements, see [Metadata import
       * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
       *
       * You can provide multiple metadata import files in the same metadata job.
       * The bucket or folder must contain at least one metadata import file, in
       * JSON Lines format (either `.json` or `.jsonl` file extension).
       *
       * In `FULL` entry sync mode, don't save the metadata import file in a
       * folder named `SOURCE_STORAGE_URI/deletions/`.
       *
       * **Caution**: If the metadata import file contains no data, all entries
       * and aspects that belong to the job's scope are deleted.
       * </pre>
       *
       * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The sourceStorageUri.
       */
      public java.lang.String getSourceStorageUri() {
        java.lang.Object ref = sourceStorageUri_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          sourceStorageUri_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The URI of a Cloud Storage bucket or folder (beginning with
       * `gs://` and ending with `/`) that contains the metadata import files for
       * this job.
       *
       * A metadata import file defines the values to set for each of the entries
       * and aspects in a metadata job. For more information about how to create a
       * metadata import file and the file requirements, see [Metadata import
       * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
       *
       * You can provide multiple metadata import files in the same metadata job.
       * The bucket or folder must contain at least one metadata import file, in
       * JSON Lines format (either `.json` or `.jsonl` file extension).
       *
       * In `FULL` entry sync mode, don't save the metadata import file in a
       * folder named `SOURCE_STORAGE_URI/deletions/`.
       *
       * **Caution**: If the metadata import file contains no data, all entries
       * and aspects that belong to the job's scope are deleted.
       * </pre>
       *
       * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for sourceStorageUri.
       */
      public com.google.protobuf.ByteString getSourceStorageUriBytes() {
        java.lang.Object ref = sourceStorageUri_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          sourceStorageUri_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The URI of a Cloud Storage bucket or folder (beginning with
       * `gs://` and ending with `/`) that contains the metadata import files for
       * this job.
       *
       * A metadata import file defines the values to set for each of the entries
       * and aspects in a metadata job. For more information about how to create a
       * metadata import file and the file requirements, see [Metadata import
       * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
       *
       * You can provide multiple metadata import files in the same metadata job.
       * The bucket or folder must contain at least one metadata import file, in
       * JSON Lines format (either `.json` or `.jsonl` file extension).
       *
       * In `FULL` entry sync mode, don't save the metadata import file in a
       * folder named `SOURCE_STORAGE_URI/deletions/`.
       *
       * **Caution**: If the metadata import file contains no data, all entries
       * and aspects that belong to the job's scope are deleted.
       * </pre>
       *
       * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @param value The sourceStorageUri to set.
       * @return This builder for chaining.
       */
      public Builder setSourceStorageUri(java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        sourceStorageUri_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The URI of a Cloud Storage bucket or folder (beginning with
       * `gs://` and ending with `/`) that contains the metadata import files for
       * this job.
       *
       * A metadata import file defines the values to set for each of the entries
       * and aspects in a metadata job. For more information about how to create a
       * metadata import file and the file requirements, see [Metadata import
       * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
       *
       * You can provide multiple metadata import files in the same metadata job.
       * The bucket or folder must contain at least one metadata import file, in
       * JSON Lines format (either `.json` or `.jsonl` file extension).
       *
       * In `FULL` entry sync mode, don't save the metadata import file in a
       * folder named `SOURCE_STORAGE_URI/deletions/`.
       *
       * **Caution**: If the metadata import file contains no data, all entries
       * and aspects that belong to the job's scope are deleted.
       * </pre>
       *
       * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearSourceStorageUri() {
        sourceStorageUri_ = getDefaultInstance().getSourceStorageUri();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The URI of a Cloud Storage bucket or folder (beginning with
       * `gs://` and ending with `/`) that contains the metadata import files for
       * this job.
       *
       * A metadata import file defines the values to set for each of the entries
       * and aspects in a metadata job. For more information about how to create a
       * metadata import file and the file requirements, see [Metadata import
       * file](https://cloud.google.com/dataplex/docs/import-metadata#metadata-import-file).
       *
       * You can provide multiple metadata import files in the same metadata job.
       * The bucket or folder must contain at least one metadata import file, in
       * JSON Lines format (either `.json` or `.jsonl` file extension).
       *
       * In `FULL` entry sync mode, don't save the metadata import file in a
       * folder named `SOURCE_STORAGE_URI/deletions/`.
       *
       * **Caution**: If the metadata import file contains no data, all entries
       * and aspects that belong to the job's scope are deleted.
       * </pre>
       *
       * <code>string source_storage_uri = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @param value The bytes for sourceStorageUri to set.
       * @return This builder for chaining.
       */
      public Builder setSourceStorageUriBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
          throw new NullPointerException();
        }
        checkByteStringIsUtf8(value);
        sourceStorageUri_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private com.google.protobuf.Timestamp sourceCreateTime_;
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp,
              com.google.protobuf.Timestamp.Builder,
              com.google.protobuf.TimestampOrBuilder>
          sourceCreateTimeBuilder_;
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return Whether the sourceCreateTime field is set.
       */
      public boolean hasSourceCreateTime() {
        return ((bitField0_ & 0x00000002) != 0);
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The sourceCreateTime.
       */
      public com.google.protobuf.Timestamp getSourceCreateTime() {
        if (sourceCreateTimeBuilder_ == null) {
          return sourceCreateTime_ == null
              ? com.google.protobuf.Timestamp.getDefaultInstance()
              : sourceCreateTime_;
        } else {
          return sourceCreateTimeBuilder_.getMessage();
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder setSourceCreateTime(com.google.protobuf.Timestamp value) {
        if (sourceCreateTimeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          sourceCreateTime_ = value;
        } else {
          sourceCreateTimeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder setSourceCreateTime(com.google.protobuf.Timestamp.Builder builderForValue) {
        if (sourceCreateTimeBuilder_ == null) {
          sourceCreateTime_ = builderForValue.build();
        } else {
          sourceCreateTimeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder mergeSourceCreateTime(com.google.protobuf.Timestamp value) {
        if (sourceCreateTimeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)
              && sourceCreateTime_ != null
              && sourceCreateTime_ != com.google.protobuf.Timestamp.getDefaultInstance()) {
            getSourceCreateTimeBuilder().mergeFrom(value);
          } else {
            sourceCreateTime_ = value;
          }
        } else {
          sourceCreateTimeBuilder_.mergeFrom(value);
        }
        if (sourceCreateTime_ != null) {
          bitField0_ |= 0x00000002;
          onChanged();
        }
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder clearSourceCreateTime() {
        bitField0_ = (bitField0_ & ~0x00000002);
        sourceCreateTime_ = null;
        if (sourceCreateTimeBuilder_ != null) {
          sourceCreateTimeBuilder_.dispose();
          sourceCreateTimeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public com.google.protobuf.Timestamp.Builder getSourceCreateTimeBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getSourceCreateTimeFieldBuilder().getBuilder();
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public com.google.protobuf.TimestampOrBuilder getSourceCreateTimeOrBuilder() {
        if (sourceCreateTimeBuilder_ != null) {
          return sourceCreateTimeBuilder_.getMessageOrBuilder();
        } else {
          return sourceCreateTime_ == null
              ? com.google.protobuf.Timestamp.getDefaultInstance()
              : sourceCreateTime_;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The time when the process that created the metadata import
       * files began.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp source_create_time = 5 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp,
              com.google.protobuf.Timestamp.Builder,
              com.google.protobuf.TimestampOrBuilder>
          getSourceCreateTimeFieldBuilder() {
        if (sourceCreateTimeBuilder_ == null) {
          sourceCreateTimeBuilder_ =
              new com.google.protobuf.SingleFieldBuilderV3<
                  com.google.protobuf.Timestamp,
                  com.google.protobuf.Timestamp.Builder,
                  com.google.protobuf.TimestampOrBuilder>(
                  getSourceCreateTime(), getParentForChildren(), isClean());
          sourceCreateTime_ = null;
        }
        return sourceCreateTimeBuilder_;
      }

      private com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope_;
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope,
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.Builder,
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScopeOrBuilder>
          scopeBuilder_;
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return Whether the scope field is set.
       */
      public boolean hasScope() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return The scope.
       */
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope getScope() {
        if (scopeBuilder_ == null) {
          return scope_ == null
              ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
                  .getDefaultInstance()
              : scope_;
        } else {
          return scopeBuilder_.getMessage();
        }
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       */
      public Builder setScope(
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope value) {
        if (scopeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          scope_ = value;
        } else {
          scopeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       */
      public Builder setScope(
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.Builder
              builderForValue) {
        if (scopeBuilder_ == null) {
          scope_ = builderForValue.build();
        } else {
          scopeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       */
      public Builder mergeScope(
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope value) {
        if (scopeBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)
              && scope_ != null
              && scope_
                  != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
                      .getDefaultInstance()) {
            getScopeBuilder().mergeFrom(value);
          } else {
            scope_ = value;
          }
        } else {
          scopeBuilder_.mergeFrom(value);
        }
        if (scope_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       */
      public Builder clearScope() {
        bitField0_ = (bitField0_ & ~0x00000004);
        scope_ = null;
        if (scopeBuilder_ != null) {
          scopeBuilder_.dispose();
          scopeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       */
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.Builder
          getScopeBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getScopeFieldBuilder().getBuilder();
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       */
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScopeOrBuilder
          getScopeOrBuilder() {
        if (scopeBuilder_ != null) {
          return scopeBuilder_.getMessageOrBuilder();
        } else {
          return scope_ == null
              ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope
                  .getDefaultInstance()
              : scope_;
        }
      }
      /**
       *
       *
       * <pre>
       * Required. A boundary on the scope of impact that the metadata import job
       * can have.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope scope = 2 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope,
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.Builder,
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScopeOrBuilder>
          getScopeFieldBuilder() {
        if (scopeBuilder_ == null) {
          scopeBuilder_ =
              new com.google.protobuf.SingleFieldBuilderV3<
                  com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope,
                  com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScope.Builder,
                  com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.ImportJobScopeOrBuilder>(
                  getScope(), getParentForChildren(), isClean());
          scope_ = null;
        }
        return scopeBuilder_;
      }

      private int entrySyncMode_ = 0;
      /**
       *
       *
       * <pre>
       * Required. The sync mode for entries.
       * Only `FULL` mode is supported for entries. All entries in the job's scope
       * are modified. If an entry exists in Dataplex but isn't included in the
       * metadata import file, the entry is deleted when you run the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return The enum numeric value on the wire for entrySyncMode.
       */
      @java.lang.Override
      public int getEntrySyncModeValue() {
        return entrySyncMode_;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for entries.
       * Only `FULL` mode is supported for entries. All entries in the job's scope
       * are modified. If an entry exists in Dataplex but isn't included in the
       * metadata import file, the entry is deleted when you run the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @param value The enum numeric value on the wire for entrySyncMode to set.
       * @return This builder for chaining.
       */
      public Builder setEntrySyncModeValue(int value) {
        entrySyncMode_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for entries.
       * Only `FULL` mode is supported for entries. All entries in the job's scope
       * are modified. If an entry exists in Dataplex but isn't included in the
       * metadata import file, the entry is deleted when you run the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return The entrySyncMode.
       */
      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode getEntrySyncMode() {
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode result =
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.forNumber(
                entrySyncMode_);
        return result == null
            ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.UNRECOGNIZED
            : result;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for entries.
       * Only `FULL` mode is supported for entries. All entries in the job's scope
       * are modified. If an entry exists in Dataplex but isn't included in the
       * metadata import file, the entry is deleted when you run the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @param value The entrySyncMode to set.
       * @return This builder for chaining.
       */
      public Builder setEntrySyncMode(
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        entrySyncMode_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for entries.
       * Only `FULL` mode is supported for entries. All entries in the job's scope
       * are modified. If an entry exists in Dataplex but isn't included in the
       * metadata import file, the entry is deleted when you run the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode entry_sync_mode = 3 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearEntrySyncMode() {
        bitField0_ = (bitField0_ & ~0x00000008);
        entrySyncMode_ = 0;
        onChanged();
        return this;
      }

      private int aspectSyncMode_ = 0;
      /**
       *
       *
       * <pre>
       * Required. The sync mode for aspects.
       * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
       * only if the metadata import file includes a reference to the aspect in
       * the `update_mask` field and the `aspect_keys` field.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return The enum numeric value on the wire for aspectSyncMode.
       */
      @java.lang.Override
      public int getAspectSyncModeValue() {
        return aspectSyncMode_;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for aspects.
       * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
       * only if the metadata import file includes a reference to the aspect in
       * the `update_mask` field and the `aspect_keys` field.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @param value The enum numeric value on the wire for aspectSyncMode to set.
       * @return This builder for chaining.
       */
      public Builder setAspectSyncModeValue(int value) {
        aspectSyncMode_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for aspects.
       * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
       * only if the metadata import file includes a reference to the aspect in
       * the `update_mask` field and the `aspect_keys` field.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return The aspectSyncMode.
       */
      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode getAspectSyncMode() {
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode result =
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.forNumber(
                aspectSyncMode_);
        return result == null
            ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode.UNRECOGNIZED
            : result;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for aspects.
       * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
       * only if the metadata import file includes a reference to the aspect in
       * the `update_mask` field and the `aspect_keys` field.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @param value The aspectSyncMode to set.
       * @return This builder for chaining.
       */
      public Builder setAspectSyncMode(
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        aspectSyncMode_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Required. The sync mode for aspects.
       * Only `INCREMENTAL` mode is supported for aspects. An aspect is modified
       * only if the metadata import file includes a reference to the aspect in
       * the `update_mask` field and the `aspect_keys` field.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.SyncMode aspect_sync_mode = 4 [(.google.api.field_behavior) = REQUIRED];
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearAspectSyncMode() {
        bitField0_ = (bitField0_ & ~0x00000010);
        aspectSyncMode_ = 0;
        onChanged();
        return this;
      }

      private int logLevel_ = 0;
      /**
       *
       *
       * <pre>
       * Optional. The level of logs to write to Cloud Logging for this job.
       *
       * Debug-level logs provide highly-detailed information for
       * troubleshooting, but their increased verbosity could incur [additional
       * costs](https://cloud.google.com/stackdriver/pricing) that might not be
       * merited for all jobs.
       *
       * If unspecified, defaults to `INFO`.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The enum numeric value on the wire for logLevel.
       */
      @java.lang.Override
      public int getLogLevelValue() {
        return logLevel_;
      }
      /**
       *
       *
       * <pre>
       * Optional. The level of logs to write to Cloud Logging for this job.
       *
       * Debug-level logs provide highly-detailed information for
       * troubleshooting, but their increased verbosity could incur [additional
       * costs](https://cloud.google.com/stackdriver/pricing) that might not be
       * merited for all jobs.
       *
       * If unspecified, defaults to `INFO`.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The enum numeric value on the wire for logLevel to set.
       * @return This builder for chaining.
       */
      public Builder setLogLevelValue(int value) {
        logLevel_ = value;
        bitField0_ |= 0x00000020;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The level of logs to write to Cloud Logging for this job.
       *
       * Debug-level logs provide highly-detailed information for
       * troubleshooting, but their increased verbosity could incur [additional
       * costs](https://cloud.google.com/stackdriver/pricing) that might not be
       * merited for all jobs.
       *
       * If unspecified, defaults to `INFO`.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The logLevel.
       */
      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel getLogLevel() {
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel result =
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel.forNumber(logLevel_);
        return result == null
            ? com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel.UNRECOGNIZED
            : result;
      }
      /**
       *
       *
       * <pre>
       * Optional. The level of logs to write to Cloud Logging for this job.
       *
       * Debug-level logs provide highly-detailed information for
       * troubleshooting, but their increased verbosity could incur [additional
       * costs](https://cloud.google.com/stackdriver/pricing) that might not be
       * merited for all jobs.
       *
       * If unspecified, defaults to `INFO`.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The logLevel to set.
       * @return This builder for chaining.
       */
      public Builder setLogLevel(
          com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000020;
        logLevel_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The level of logs to write to Cloud Logging for this job.
       *
       * Debug-level logs provide highly-detailed information for
       * troubleshooting, but their increased verbosity could incur [additional
       * costs](https://cloud.google.com/stackdriver/pricing) that might not be
       * merited for all jobs.
       *
       * If unspecified, defaults to `INFO`.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.LogLevel log_level = 6 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearLogLevel() {
        bitField0_ = (bitField0_ & ~0x00000020);
        logLevel_ = 0;
        onChanged();
        return this;
      }

      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }

      // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.MetadataJob.ImportJobSpec)
    private static final com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec DEFAULT_INSTANCE;

    static {
      DEFAULT_INSTANCE = new com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec();
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ImportJobSpec> PARSER =
        new com.google.protobuf.AbstractParser<ImportJobSpec>() {
          @java.lang.Override
          public ImportJobSpec parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
            Builder builder = newBuilder();
            try {
              builder.mergeFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              throw e.setUnfinishedMessage(builder.buildPartial());
            } catch (com.google.protobuf.UninitializedMessageException e) {
              throw e.asInvalidProtocolBufferException()
                  .setUnfinishedMessage(builder.buildPartial());
            } catch (java.io.IOException e) {
              throw new com.google.protobuf.InvalidProtocolBufferException(e)
                  .setUnfinishedMessage(builder.buildPartial());
            }
            return builder.buildPartial();
          }
        };

    public static com.google.protobuf.Parser<ImportJobSpec> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ImportJobSpec> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }
  }

  public interface StatusOrBuilder
      extends
      // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.MetadataJob.Status)
      com.google.protobuf.MessageOrBuilder {

    /**
     *
     *
     * <pre>
     * Output only. State of the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The enum numeric value on the wire for state.
     */
    int getStateValue();
    /**
     *
     *
     * <pre>
     * Output only. State of the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The state.
     */
    com.google.cloud.dataplex.v1.MetadataJob.Status.State getState();

    /**
     *
     *
     * <pre>
     * Output only. Message relating to the progression of a metadata job.
     * </pre>
     *
     * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The message.
     */
    java.lang.String getMessage();
    /**
     *
     *
     * <pre>
     * Output only. Message relating to the progression of a metadata job.
     * </pre>
     *
     * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The bytes for message.
     */
    com.google.protobuf.ByteString getMessageBytes();

    /**
     *
     *
     * <pre>
     * Output only. Progress tracking.
     * </pre>
     *
     * <code>int32 completion_percent = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The completionPercent.
     */
    int getCompletionPercent();

    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the updateTime field is set.
     */
    boolean hasUpdateTime();
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The updateTime.
     */
    com.google.protobuf.Timestamp getUpdateTime();
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder();
  }
  /**
   *
   *
   * <pre>
   * Metadata job status.
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.Status}
   */
  public static final class Status extends com.google.protobuf.GeneratedMessageV3
      implements
      // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.MetadataJob.Status)
      StatusOrBuilder {
    private static final long serialVersionUID = 0L;
    // Use Status.newBuilder() to construct.
    private Status(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }

    private Status() {
      state_ = 0;
      message_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
      return new Status();
    }

    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_Status_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_Status_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataplex.v1.MetadataJob.Status.class,
              com.google.cloud.dataplex.v1.MetadataJob.Status.Builder.class);
    }

    /**
     *
     *
     * <pre>
     * State of a metadata job.
     * </pre>
     *
     * Protobuf enum {@code google.cloud.dataplex.v1.MetadataJob.Status.State}
     */
    public enum State implements com.google.protobuf.ProtocolMessageEnum {
      /**
       *
       *
       * <pre>
       * State unspecified.
       * </pre>
       *
       * <code>STATE_UNSPECIFIED = 0;</code>
       */
      STATE_UNSPECIFIED(0),
      /**
       *
       *
       * <pre>
       * The job is queued.
       * </pre>
       *
       * <code>QUEUED = 1;</code>
       */
      QUEUED(1),
      /**
       *
       *
       * <pre>
       * The job is running.
       * </pre>
       *
       * <code>RUNNING = 2;</code>
       */
      RUNNING(2),
      /**
       *
       *
       * <pre>
       * The job is being canceled.
       * </pre>
       *
       * <code>CANCELING = 3;</code>
       */
      CANCELING(3),
      /**
       *
       *
       * <pre>
       * The job is canceled.
       * </pre>
       *
       * <code>CANCELED = 4;</code>
       */
      CANCELED(4),
      /**
       *
       *
       * <pre>
       * The job succeeded.
       * </pre>
       *
       * <code>SUCCEEDED = 5;</code>
       */
      SUCCEEDED(5),
      /**
       *
       *
       * <pre>
       * The job failed.
       * </pre>
       *
       * <code>FAILED = 6;</code>
       */
      FAILED(6),
      /**
       *
       *
       * <pre>
       * The job completed with some errors.
       * </pre>
       *
       * <code>SUCCEEDED_WITH_ERRORS = 7;</code>
       */
      SUCCEEDED_WITH_ERRORS(7),
      UNRECOGNIZED(-1),
      ;

      /**
       *
       *
       * <pre>
       * State unspecified.
       * </pre>
       *
       * <code>STATE_UNSPECIFIED = 0;</code>
       */
      public static final int STATE_UNSPECIFIED_VALUE = 0;
      /**
       *
       *
       * <pre>
       * The job is queued.
       * </pre>
       *
       * <code>QUEUED = 1;</code>
       */
      public static final int QUEUED_VALUE = 1;
      /**
       *
       *
       * <pre>
       * The job is running.
       * </pre>
       *
       * <code>RUNNING = 2;</code>
       */
      public static final int RUNNING_VALUE = 2;
      /**
       *
       *
       * <pre>
       * The job is being canceled.
       * </pre>
       *
       * <code>CANCELING = 3;</code>
       */
      public static final int CANCELING_VALUE = 3;
      /**
       *
       *
       * <pre>
       * The job is canceled.
       * </pre>
       *
       * <code>CANCELED = 4;</code>
       */
      public static final int CANCELED_VALUE = 4;
      /**
       *
       *
       * <pre>
       * The job succeeded.
       * </pre>
       *
       * <code>SUCCEEDED = 5;</code>
       */
      public static final int SUCCEEDED_VALUE = 5;
      /**
       *
       *
       * <pre>
       * The job failed.
       * </pre>
       *
       * <code>FAILED = 6;</code>
       */
      public static final int FAILED_VALUE = 6;
      /**
       *
       *
       * <pre>
       * The job completed with some errors.
       * </pre>
       *
       * <code>SUCCEEDED_WITH_ERRORS = 7;</code>
       */
      public static final int SUCCEEDED_WITH_ERRORS_VALUE = 7;

      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static State valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static State forNumber(int value) {
        switch (value) {
          case 0:
            return STATE_UNSPECIFIED;
          case 1:
            return QUEUED;
          case 2:
            return RUNNING;
          case 3:
            return CANCELING;
          case 4:
            return CANCELED;
          case 5:
            return SUCCEEDED;
          case 6:
            return FAILED;
          case 7:
            return SUCCEEDED_WITH_ERRORS;
          default:
            return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<State> internalGetValueMap() {
        return internalValueMap;
      }

      private static final com.google.protobuf.Internal.EnumLiteMap<State> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<State>() {
            public State findValueByNumber(int number) {
              return State.forNumber(number);
            }
          };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }

      public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType() {
        return getDescriptor();
      }

      public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.MetadataJob.Status.getDescriptor()
            .getEnumTypes()
            .get(0);
      }

      private static final State[] VALUES = values();

      public static State valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private State(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:google.cloud.dataplex.v1.MetadataJob.Status.State)
    }

    private int bitField0_;
    public static final int STATE_FIELD_NUMBER = 1;
    private int state_ = 0;
    /**
     *
     *
     * <pre>
     * Output only. State of the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The enum numeric value on the wire for state.
     */
    @java.lang.Override
    public int getStateValue() {
      return state_;
    }
    /**
     *
     *
     * <pre>
     * Output only. State of the metadata job.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The state.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.Status.State getState() {
      com.google.cloud.dataplex.v1.MetadataJob.Status.State result =
          com.google.cloud.dataplex.v1.MetadataJob.Status.State.forNumber(state_);
      return result == null
          ? com.google.cloud.dataplex.v1.MetadataJob.Status.State.UNRECOGNIZED
          : result;
    }

    public static final int MESSAGE_FIELD_NUMBER = 2;

    @SuppressWarnings("serial")
    private volatile java.lang.Object message_ = "";
    /**
     *
     *
     * <pre>
     * Output only. Message relating to the progression of a metadata job.
     * </pre>
     *
     * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The message.
     */
    @java.lang.Override
    public java.lang.String getMessage() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        message_ = s;
        return s;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. Message relating to the progression of a metadata job.
     * </pre>
     *
     * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The bytes for message.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getMessageBytes() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
        message_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int COMPLETION_PERCENT_FIELD_NUMBER = 3;
    private int completionPercent_ = 0;
    /**
     *
     *
     * <pre>
     * Output only. Progress tracking.
     * </pre>
     *
     * <code>int32 completion_percent = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
     *
     * @return The completionPercent.
     */
    @java.lang.Override
    public int getCompletionPercent() {
      return completionPercent_;
    }

    public static final int UPDATE_TIME_FIELD_NUMBER = 4;
    private com.google.protobuf.Timestamp updateTime_;
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the updateTime field is set.
     */
    @java.lang.Override
    public boolean hasUpdateTime() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The updateTime.
     */
    @java.lang.Override
    public com.google.protobuf.Timestamp getUpdateTime() {
      return updateTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : updateTime_;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the status was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    @java.lang.Override
    public com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder() {
      return updateTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : updateTime_;
    }

    private byte memoizedIsInitialized = -1;

    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
      if (state_
          != com.google.cloud.dataplex.v1.MetadataJob.Status.State.STATE_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, state_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(message_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, message_);
      }
      if (completionPercent_ != 0) {
        output.writeInt32(3, completionPercent_);
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(4, getUpdateTime());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (state_
          != com.google.cloud.dataplex.v1.MetadataJob.Status.State.STATE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream.computeEnumSize(1, state_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(message_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, message_);
      }
      if (completionPercent_ != 0) {
        size += com.google.protobuf.CodedOutputStream.computeInt32Size(3, completionPercent_);
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream.computeMessageSize(4, getUpdateTime());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
        return true;
      }
      if (!(obj instanceof com.google.cloud.dataplex.v1.MetadataJob.Status)) {
        return super.equals(obj);
      }
      com.google.cloud.dataplex.v1.MetadataJob.Status other =
          (com.google.cloud.dataplex.v1.MetadataJob.Status) obj;

      if (state_ != other.state_) return false;
      if (!getMessage().equals(other.getMessage())) return false;
      if (getCompletionPercent() != other.getCompletionPercent()) return false;
      if (hasUpdateTime() != other.hasUpdateTime()) return false;
      if (hasUpdateTime()) {
        if (!getUpdateTime().equals(other.getUpdateTime())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + STATE_FIELD_NUMBER;
      hash = (53 * hash) + state_;
      hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
      hash = (53 * hash) + getMessage().hashCode();
      hash = (37 * hash) + COMPLETION_PERCENT_FIELD_NUMBER;
      hash = (53 * hash) + getCompletionPercent();
      if (hasUpdateTime()) {
        hash = (37 * hash) + UPDATE_TIME_FIELD_NUMBER;
        hash = (53 * hash) + getUpdateTime().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseDelimitedFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseDelimitedFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        com.google.protobuf.CodedInputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() {
      return newBuilder();
    }

    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }

    public static Builder newBuilder(com.google.cloud.dataplex.v1.MetadataJob.Status prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }

    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     *
     *
     * <pre>
     * Metadata job status.
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob.Status}
     */
    public static final class Builder
        extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
        implements
        // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.MetadataJob.Status)
        com.google.cloud.dataplex.v1.MetadataJob.StatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_Status_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_Status_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.MetadataJob.Status.class,
                com.google.cloud.dataplex.v1.MetadataJob.Status.Builder.class);
      }

      // Construct using com.google.cloud.dataplex.v1.MetadataJob.Status.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }

      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {
          getUpdateTimeFieldBuilder();
        }
      }

      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        state_ = 0;
        message_ = "";
        completionPercent_ = 0;
        updateTime_ = null;
        if (updateTimeBuilder_ != null) {
          updateTimeBuilder_.dispose();
          updateTimeBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
        return com.google.cloud.dataplex.v1.CatalogProto
            .internal_static_google_cloud_dataplex_v1_MetadataJob_Status_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.Status getDefaultInstanceForType() {
        return com.google.cloud.dataplex.v1.MetadataJob.Status.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.Status build() {
        com.google.cloud.dataplex.v1.MetadataJob.Status result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.Status buildPartial() {
        com.google.cloud.dataplex.v1.MetadataJob.Status result =
            new com.google.cloud.dataplex.v1.MetadataJob.Status(this);
        if (bitField0_ != 0) {
          buildPartial0(result);
        }
        onBuilt();
        return result;
      }

      private void buildPartial0(com.google.cloud.dataplex.v1.MetadataJob.Status result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.state_ = state_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.message_ = message_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.completionPercent_ = completionPercent_;
        }
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.updateTime_ =
              updateTimeBuilder_ == null ? updateTime_ : updateTimeBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }

      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.setField(field, value);
      }

      @java.lang.Override
      public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }

      @java.lang.Override
      public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }

      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index,
          java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }

      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }

      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.dataplex.v1.MetadataJob.Status) {
          return mergeFrom((com.google.cloud.dataplex.v1.MetadataJob.Status) other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.dataplex.v1.MetadataJob.Status other) {
        if (other == com.google.cloud.dataplex.v1.MetadataJob.Status.getDefaultInstance())
          return this;
        if (other.state_ != 0) {
          setStateValue(other.getStateValue());
        }
        if (!other.getMessage().isEmpty()) {
          message_ = other.message_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (other.getCompletionPercent() != 0) {
          setCompletionPercent(other.getCompletionPercent());
        }
        if (other.hasUpdateTime()) {
          mergeUpdateTime(other.getUpdateTime());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8:
                {
                  state_ = input.readEnum();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 8
              case 18:
                {
                  message_ = input.readStringRequireUtf8();
                  bitField0_ |= 0x00000002;
                  break;
                } // case 18
              case 24:
                {
                  completionPercent_ = input.readInt32();
                  bitField0_ |= 0x00000004;
                  break;
                } // case 24
              case 34:
                {
                  input.readMessage(getUpdateTimeFieldBuilder().getBuilder(), extensionRegistry);
                  bitField0_ |= 0x00000008;
                  break;
                } // case 34
              default:
                {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private int bitField0_;

      private int state_ = 0;
      /**
       *
       *
       * <pre>
       * Output only. State of the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @return The enum numeric value on the wire for state.
       */
      @java.lang.Override
      public int getStateValue() {
        return state_;
      }
      /**
       *
       *
       * <pre>
       * Output only. State of the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @param value The enum numeric value on the wire for state to set.
       * @return This builder for chaining.
       */
      public Builder setStateValue(int value) {
        state_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. State of the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @return The state.
       */
      @java.lang.Override
      public com.google.cloud.dataplex.v1.MetadataJob.Status.State getState() {
        com.google.cloud.dataplex.v1.MetadataJob.Status.State result =
            com.google.cloud.dataplex.v1.MetadataJob.Status.State.forNumber(state_);
        return result == null
            ? com.google.cloud.dataplex.v1.MetadataJob.Status.State.UNRECOGNIZED
            : result;
      }
      /**
       *
       *
       * <pre>
       * Output only. State of the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @param value The state to set.
       * @return This builder for chaining.
       */
      public Builder setState(com.google.cloud.dataplex.v1.MetadataJob.Status.State value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. State of the metadata job.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.MetadataJob.Status.State state = 1 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000001);
        state_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object message_ = "";
      /**
       *
       *
       * <pre>
       * Output only. Message relating to the progression of a metadata job.
       * </pre>
       *
       * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The message.
       */
      public java.lang.String getMessage() {
        java.lang.Object ref = message_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          message_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Output only. Message relating to the progression of a metadata job.
       * </pre>
       *
       * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The bytes for message.
       */
      public com.google.protobuf.ByteString getMessageBytes() {
        java.lang.Object ref = message_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          message_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Output only. Message relating to the progression of a metadata job.
       * </pre>
       *
       * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The message to set.
       * @return This builder for chaining.
       */
      public Builder setMessage(java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        message_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. Message relating to the progression of a metadata job.
       * </pre>
       *
       * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearMessage() {
        message_ = getDefaultInstance().getMessage();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. Message relating to the progression of a metadata job.
       * </pre>
       *
       * <code>string message = 2 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The bytes for message to set.
       * @return This builder for chaining.
       */
      public Builder setMessageBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
          throw new NullPointerException();
        }
        checkByteStringIsUtf8(value);
        message_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private int completionPercent_;
      /**
       *
       *
       * <pre>
       * Output only. Progress tracking.
       * </pre>
       *
       * <code>int32 completion_percent = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return The completionPercent.
       */
      @java.lang.Override
      public int getCompletionPercent() {
        return completionPercent_;
      }
      /**
       *
       *
       * <pre>
       * Output only. Progress tracking.
       * </pre>
       *
       * <code>int32 completion_percent = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @param value The completionPercent to set.
       * @return This builder for chaining.
       */
      public Builder setCompletionPercent(int value) {

        completionPercent_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. Progress tracking.
       * </pre>
       *
       * <code>int32 completion_percent = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearCompletionPercent() {
        bitField0_ = (bitField0_ & ~0x00000004);
        completionPercent_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Timestamp updateTime_;
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp,
              com.google.protobuf.Timestamp.Builder,
              com.google.protobuf.TimestampOrBuilder>
          updateTimeBuilder_;
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @return Whether the updateTime field is set.
       */
      public boolean hasUpdateTime() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       *
       * @return The updateTime.
       */
      public com.google.protobuf.Timestamp getUpdateTime() {
        if (updateTimeBuilder_ == null) {
          return updateTime_ == null
              ? com.google.protobuf.Timestamp.getDefaultInstance()
              : updateTime_;
        } else {
          return updateTimeBuilder_.getMessage();
        }
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder setUpdateTime(com.google.protobuf.Timestamp value) {
        if (updateTimeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          updateTime_ = value;
        } else {
          updateTimeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder setUpdateTime(com.google.protobuf.Timestamp.Builder builderForValue) {
        if (updateTimeBuilder_ == null) {
          updateTime_ = builderForValue.build();
        } else {
          updateTimeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder mergeUpdateTime(com.google.protobuf.Timestamp value) {
        if (updateTimeBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0)
              && updateTime_ != null
              && updateTime_ != com.google.protobuf.Timestamp.getDefaultInstance()) {
            getUpdateTimeBuilder().mergeFrom(value);
          } else {
            updateTime_ = value;
          }
        } else {
          updateTimeBuilder_.mergeFrom(value);
        }
        if (updateTime_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public Builder clearUpdateTime() {
        bitField0_ = (bitField0_ & ~0x00000008);
        updateTime_ = null;
        if (updateTimeBuilder_ != null) {
          updateTimeBuilder_.dispose();
          updateTimeBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public com.google.protobuf.Timestamp.Builder getUpdateTimeBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUpdateTimeFieldBuilder().getBuilder();
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      public com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder() {
        if (updateTimeBuilder_ != null) {
          return updateTimeBuilder_.getMessageOrBuilder();
        } else {
          return updateTime_ == null
              ? com.google.protobuf.Timestamp.getDefaultInstance()
              : updateTime_;
        }
      }
      /**
       *
       *
       * <pre>
       * Output only. The time when the status was updated.
       * </pre>
       *
       * <code>
       * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
       * </code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp,
              com.google.protobuf.Timestamp.Builder,
              com.google.protobuf.TimestampOrBuilder>
          getUpdateTimeFieldBuilder() {
        if (updateTimeBuilder_ == null) {
          updateTimeBuilder_ =
              new com.google.protobuf.SingleFieldBuilderV3<
                  com.google.protobuf.Timestamp,
                  com.google.protobuf.Timestamp.Builder,
                  com.google.protobuf.TimestampOrBuilder>(
                  getUpdateTime(), getParentForChildren(), isClean());
          updateTime_ = null;
        }
        return updateTimeBuilder_;
      }

      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }

      // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.MetadataJob.Status)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.MetadataJob.Status)
    private static final com.google.cloud.dataplex.v1.MetadataJob.Status DEFAULT_INSTANCE;

    static {
      DEFAULT_INSTANCE = new com.google.cloud.dataplex.v1.MetadataJob.Status();
    }

    public static com.google.cloud.dataplex.v1.MetadataJob.Status getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Status> PARSER =
        new com.google.protobuf.AbstractParser<Status>() {
          @java.lang.Override
          public Status parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
            Builder builder = newBuilder();
            try {
              builder.mergeFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              throw e.setUnfinishedMessage(builder.buildPartial());
            } catch (com.google.protobuf.UninitializedMessageException e) {
              throw e.asInvalidProtocolBufferException()
                  .setUnfinishedMessage(builder.buildPartial());
            } catch (java.io.IOException e) {
              throw new com.google.protobuf.InvalidProtocolBufferException(e)
                  .setUnfinishedMessage(builder.buildPartial());
            }
            return builder.buildPartial();
          }
        };

    public static com.google.protobuf.Parser<Status> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Status> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.Status getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }
  }

  private int bitField0_;
  private int specCase_ = 0;

  @SuppressWarnings("serial")
  private java.lang.Object spec_;

  public enum SpecCase
      implements
          com.google.protobuf.Internal.EnumLite,
          com.google.protobuf.AbstractMessage.InternalOneOfEnum {
    IMPORT_SPEC(100),
    SPEC_NOT_SET(0);
    private final int value;

    private SpecCase(int value) {
      this.value = value;
    }
    /**
     * @param value The number of the enum to look for.
     * @return The enum associated with the given number.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static SpecCase valueOf(int value) {
      return forNumber(value);
    }

    public static SpecCase forNumber(int value) {
      switch (value) {
        case 100:
          return IMPORT_SPEC;
        case 0:
          return SPEC_NOT_SET;
        default:
          return null;
      }
    }

    public int getNumber() {
      return this.value;
    }
  };

  public SpecCase getSpecCase() {
    return SpecCase.forNumber(specCase_);
  }

  private int resultCase_ = 0;

  @SuppressWarnings("serial")
  private java.lang.Object result_;

  public enum ResultCase
      implements
          com.google.protobuf.Internal.EnumLite,
          com.google.protobuf.AbstractMessage.InternalOneOfEnum {
    IMPORT_RESULT(200),
    RESULT_NOT_SET(0);
    private final int value;

    private ResultCase(int value) {
      this.value = value;
    }
    /**
     * @param value The number of the enum to look for.
     * @return The enum associated with the given number.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ResultCase valueOf(int value) {
      return forNumber(value);
    }

    public static ResultCase forNumber(int value) {
      switch (value) {
        case 200:
          return IMPORT_RESULT;
        case 0:
          return RESULT_NOT_SET;
        default:
          return null;
      }
    }

    public int getNumber() {
      return this.value;
    }
  };

  public ResultCase getResultCase() {
    return ResultCase.forNumber(resultCase_);
  }

  public static final int NAME_FIELD_NUMBER = 1;

  @SuppressWarnings("serial")
  private volatile java.lang.Object name_ = "";
  /**
   *
   *
   * <pre>
   * Output only. Identifier. The name of the resource that the configuration is
   * applied to, in the format
   * `projects/{project_number}/locations/{location_id}/metadataJobs/{metadata_job_id}`.
   * </pre>
   *
   * <code>
   * string name = 1 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_behavior) = IDENTIFIER];
   * </code>
   *
   * @return The name.
   */
  @java.lang.Override
  public java.lang.String getName() {
    java.lang.Object ref = name_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      name_ = s;
      return s;
    }
  }
  /**
   *
   *
   * <pre>
   * Output only. Identifier. The name of the resource that the configuration is
   * applied to, in the format
   * `projects/{project_number}/locations/{location_id}/metadataJobs/{metadata_job_id}`.
   * </pre>
   *
   * <code>
   * string name = 1 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_behavior) = IDENTIFIER];
   * </code>
   *
   * @return The bytes for name.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString getNameBytes() {
    java.lang.Object ref = name_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b =
          com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
      name_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int UID_FIELD_NUMBER = 2;

  @SuppressWarnings("serial")
  private volatile java.lang.Object uid_ = "";
  /**
   *
   *
   * <pre>
   * Output only. A system-generated, globally unique ID for the metadata job.
   * If the metadata job is deleted and then re-created with the same name, this
   * ID is different.
   * </pre>
   *
   * <code>
   * string uid = 2 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_info) = { ... }
   * </code>
   *
   * @return The uid.
   */
  @java.lang.Override
  public java.lang.String getUid() {
    java.lang.Object ref = uid_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      uid_ = s;
      return s;
    }
  }
  /**
   *
   *
   * <pre>
   * Output only. A system-generated, globally unique ID for the metadata job.
   * If the metadata job is deleted and then re-created with the same name, this
   * ID is different.
   * </pre>
   *
   * <code>
   * string uid = 2 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_info) = { ... }
   * </code>
   *
   * @return The bytes for uid.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString getUidBytes() {
    java.lang.Object ref = uid_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b =
          com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
      uid_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int CREATE_TIME_FIELD_NUMBER = 3;
  private com.google.protobuf.Timestamp createTime_;
  /**
   *
   *
   * <pre>
   * Output only. The time when the metadata job was created.
   * </pre>
   *
   * <code>.google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return Whether the createTime field is set.
   */
  @java.lang.Override
  public boolean hasCreateTime() {
    return ((bitField0_ & 0x00000001) != 0);
  }
  /**
   *
   *
   * <pre>
   * Output only. The time when the metadata job was created.
   * </pre>
   *
   * <code>.google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return The createTime.
   */
  @java.lang.Override
  public com.google.protobuf.Timestamp getCreateTime() {
    return createTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createTime_;
  }
  /**
   *
   *
   * <pre>
   * Output only. The time when the metadata job was created.
   * </pre>
   *
   * <code>.google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   */
  @java.lang.Override
  public com.google.protobuf.TimestampOrBuilder getCreateTimeOrBuilder() {
    return createTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createTime_;
  }

  public static final int UPDATE_TIME_FIELD_NUMBER = 4;
  private com.google.protobuf.Timestamp updateTime_;
  /**
   *
   *
   * <pre>
   * Output only. The time when the metadata job was updated.
   * </pre>
   *
   * <code>.google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return Whether the updateTime field is set.
   */
  @java.lang.Override
  public boolean hasUpdateTime() {
    return ((bitField0_ & 0x00000002) != 0);
  }
  /**
   *
   *
   * <pre>
   * Output only. The time when the metadata job was updated.
   * </pre>
   *
   * <code>.google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return The updateTime.
   */
  @java.lang.Override
  public com.google.protobuf.Timestamp getUpdateTime() {
    return updateTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : updateTime_;
  }
  /**
   *
   *
   * <pre>
   * Output only. The time when the metadata job was updated.
   * </pre>
   *
   * <code>.google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   */
  @java.lang.Override
  public com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder() {
    return updateTime_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : updateTime_;
  }

  public static final int LABELS_FIELD_NUMBER = 5;

  private static final class LabelsDefaultEntryHolder {
    static final com.google.protobuf.MapEntry<java.lang.String, java.lang.String> defaultEntry =
        com.google.protobuf.MapEntry.<java.lang.String, java.lang.String>newDefaultInstance(
            com.google.cloud.dataplex.v1.CatalogProto
                .internal_static_google_cloud_dataplex_v1_MetadataJob_LabelsEntry_descriptor,
            com.google.protobuf.WireFormat.FieldType.STRING,
            "",
            com.google.protobuf.WireFormat.FieldType.STRING,
            "");
  }

  @SuppressWarnings("serial")
  private com.google.protobuf.MapField<java.lang.String, java.lang.String> labels_;

  private com.google.protobuf.MapField<java.lang.String, java.lang.String> internalGetLabels() {
    if (labels_ == null) {
      return com.google.protobuf.MapField.emptyMapField(LabelsDefaultEntryHolder.defaultEntry);
    }
    return labels_;
  }

  public int getLabelsCount() {
    return internalGetLabels().getMap().size();
  }
  /**
   *
   *
   * <pre>
   * Optional. User-defined labels.
   * </pre>
   *
   * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
   */
  @java.lang.Override
  public boolean containsLabels(java.lang.String key) {
    if (key == null) {
      throw new NullPointerException("map key");
    }
    return internalGetLabels().getMap().containsKey(key);
  }
  /** Use {@link #getLabelsMap()} instead. */
  @java.lang.Override
  @java.lang.Deprecated
  public java.util.Map<java.lang.String, java.lang.String> getLabels() {
    return getLabelsMap();
  }
  /**
   *
   *
   * <pre>
   * Optional. User-defined labels.
   * </pre>
   *
   * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
   */
  @java.lang.Override
  public java.util.Map<java.lang.String, java.lang.String> getLabelsMap() {
    return internalGetLabels().getMap();
  }
  /**
   *
   *
   * <pre>
   * Optional. User-defined labels.
   * </pre>
   *
   * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
   */
  @java.lang.Override
  public /* nullable */ java.lang.String getLabelsOrDefault(
      java.lang.String key,
      /* nullable */
      java.lang.String defaultValue) {
    if (key == null) {
      throw new NullPointerException("map key");
    }
    java.util.Map<java.lang.String, java.lang.String> map = internalGetLabels().getMap();
    return map.containsKey(key) ? map.get(key) : defaultValue;
  }
  /**
   *
   *
   * <pre>
   * Optional. User-defined labels.
   * </pre>
   *
   * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
   */
  @java.lang.Override
  public java.lang.String getLabelsOrThrow(java.lang.String key) {
    if (key == null) {
      throw new NullPointerException("map key");
    }
    java.util.Map<java.lang.String, java.lang.String> map = internalGetLabels().getMap();
    if (!map.containsKey(key)) {
      throw new java.lang.IllegalArgumentException();
    }
    return map.get(key);
  }

  public static final int TYPE_FIELD_NUMBER = 6;
  private int type_ = 0;
  /**
   *
   *
   * <pre>
   * Required. Metadata job type.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.Type type = 6 [(.google.api.field_behavior) = REQUIRED];
   * </code>
   *
   * @return The enum numeric value on the wire for type.
   */
  @java.lang.Override
  public int getTypeValue() {
    return type_;
  }
  /**
   *
   *
   * <pre>
   * Required. Metadata job type.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.Type type = 6 [(.google.api.field_behavior) = REQUIRED];
   * </code>
   *
   * @return The type.
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob.Type getType() {
    com.google.cloud.dataplex.v1.MetadataJob.Type result =
        com.google.cloud.dataplex.v1.MetadataJob.Type.forNumber(type_);
    return result == null ? com.google.cloud.dataplex.v1.MetadataJob.Type.UNRECOGNIZED : result;
  }

  public static final int IMPORT_SPEC_FIELD_NUMBER = 100;
  /**
   *
   *
   * <pre>
   * Import job specification.
   * </pre>
   *
   * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
   *
   * @return Whether the importSpec field is set.
   */
  @java.lang.Override
  public boolean hasImportSpec() {
    return specCase_ == 100;
  }
  /**
   *
   *
   * <pre>
   * Import job specification.
   * </pre>
   *
   * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
   *
   * @return The importSpec.
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec getImportSpec() {
    if (specCase_ == 100) {
      return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_;
    }
    return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance();
  }
  /**
   *
   *
   * <pre>
   * Import job specification.
   * </pre>
   *
   * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpecOrBuilder getImportSpecOrBuilder() {
    if (specCase_ == 100) {
      return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_;
    }
    return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance();
  }

  public static final int IMPORT_RESULT_FIELD_NUMBER = 200;
  /**
   *
   *
   * <pre>
   * Output only. Import job result.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return Whether the importResult field is set.
   */
  @java.lang.Override
  public boolean hasImportResult() {
    return resultCase_ == 200;
  }
  /**
   *
   *
   * <pre>
   * Output only. Import job result.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return The importResult.
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult getImportResult() {
    if (resultCase_ == 200) {
      return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_;
    }
    return com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance();
  }
  /**
   *
   *
   * <pre>
   * Output only. Import job result.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResultOrBuilder
      getImportResultOrBuilder() {
    if (resultCase_ == 200) {
      return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_;
    }
    return com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance();
  }

  public static final int STATUS_FIELD_NUMBER = 7;
  private com.google.cloud.dataplex.v1.MetadataJob.Status status_;
  /**
   *
   *
   * <pre>
   * Output only. Metadata job status.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return Whether the status field is set.
   */
  @java.lang.Override
  public boolean hasStatus() {
    return ((bitField0_ & 0x00000004) != 0);
  }
  /**
   *
   *
   * <pre>
   * Output only. Metadata job status.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   *
   * @return The status.
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob.Status getStatus() {
    return status_ == null
        ? com.google.cloud.dataplex.v1.MetadataJob.Status.getDefaultInstance()
        : status_;
  }
  /**
   *
   *
   * <pre>
   * Output only. Metadata job status.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
   * </code>
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob.StatusOrBuilder getStatusOrBuilder() {
    return status_ == null
        ? com.google.cloud.dataplex.v1.MetadataJob.Status.getDefaultInstance()
        : status_;
  }

  private byte memoizedIsInitialized = -1;

  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(uid_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 2, uid_);
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      output.writeMessage(3, getCreateTime());
    }
    if (((bitField0_ & 0x00000002) != 0)) {
      output.writeMessage(4, getUpdateTime());
    }
    com.google.protobuf.GeneratedMessageV3.serializeStringMapTo(
        output, internalGetLabels(), LabelsDefaultEntryHolder.defaultEntry, 5);
    if (type_ != com.google.cloud.dataplex.v1.MetadataJob.Type.TYPE_UNSPECIFIED.getNumber()) {
      output.writeEnum(6, type_);
    }
    if (((bitField0_ & 0x00000004) != 0)) {
      output.writeMessage(7, getStatus());
    }
    if (specCase_ == 100) {
      output.writeMessage(100, (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_);
    }
    if (resultCase_ == 200) {
      output.writeMessage(200, (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_);
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(uid_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, uid_);
    }
    if (((bitField0_ & 0x00000001) != 0)) {
      size += com.google.protobuf.CodedOutputStream.computeMessageSize(3, getCreateTime());
    }
    if (((bitField0_ & 0x00000002) != 0)) {
      size += com.google.protobuf.CodedOutputStream.computeMessageSize(4, getUpdateTime());
    }
    for (java.util.Map.Entry<java.lang.String, java.lang.String> entry :
        internalGetLabels().getMap().entrySet()) {
      com.google.protobuf.MapEntry<java.lang.String, java.lang.String> labels__ =
          LabelsDefaultEntryHolder.defaultEntry
              .newBuilderForType()
              .setKey(entry.getKey())
              .setValue(entry.getValue())
              .build();
      size += com.google.protobuf.CodedOutputStream.computeMessageSize(5, labels__);
    }
    if (type_ != com.google.cloud.dataplex.v1.MetadataJob.Type.TYPE_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream.computeEnumSize(6, type_);
    }
    if (((bitField0_ & 0x00000004) != 0)) {
      size += com.google.protobuf.CodedOutputStream.computeMessageSize(7, getStatus());
    }
    if (specCase_ == 100) {
      size +=
          com.google.protobuf.CodedOutputStream.computeMessageSize(
              100, (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_);
    }
    if (resultCase_ == 200) {
      size +=
          com.google.protobuf.CodedOutputStream.computeMessageSize(
              200, (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
      return true;
    }
    if (!(obj instanceof com.google.cloud.dataplex.v1.MetadataJob)) {
      return super.equals(obj);
    }
    com.google.cloud.dataplex.v1.MetadataJob other = (com.google.cloud.dataplex.v1.MetadataJob) obj;

    if (!getName().equals(other.getName())) return false;
    if (!getUid().equals(other.getUid())) return false;
    if (hasCreateTime() != other.hasCreateTime()) return false;
    if (hasCreateTime()) {
      if (!getCreateTime().equals(other.getCreateTime())) return false;
    }
    if (hasUpdateTime() != other.hasUpdateTime()) return false;
    if (hasUpdateTime()) {
      if (!getUpdateTime().equals(other.getUpdateTime())) return false;
    }
    if (!internalGetLabels().equals(other.internalGetLabels())) return false;
    if (type_ != other.type_) return false;
    if (hasStatus() != other.hasStatus()) return false;
    if (hasStatus()) {
      if (!getStatus().equals(other.getStatus())) return false;
    }
    if (!getSpecCase().equals(other.getSpecCase())) return false;
    switch (specCase_) {
      case 100:
        if (!getImportSpec().equals(other.getImportSpec())) return false;
        break;
      case 0:
      default:
    }
    if (!getResultCase().equals(other.getResultCase())) return false;
    switch (resultCase_) {
      case 200:
        if (!getImportResult().equals(other.getImportResult())) return false;
        break;
      case 0:
      default:
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + NAME_FIELD_NUMBER;
    hash = (53 * hash) + getName().hashCode();
    hash = (37 * hash) + UID_FIELD_NUMBER;
    hash = (53 * hash) + getUid().hashCode();
    if (hasCreateTime()) {
      hash = (37 * hash) + CREATE_TIME_FIELD_NUMBER;
      hash = (53 * hash) + getCreateTime().hashCode();
    }
    if (hasUpdateTime()) {
      hash = (37 * hash) + UPDATE_TIME_FIELD_NUMBER;
      hash = (53 * hash) + getUpdateTime().hashCode();
    }
    if (!internalGetLabels().getMap().isEmpty()) {
      hash = (37 * hash) + LABELS_FIELD_NUMBER;
      hash = (53 * hash) + internalGetLabels().hashCode();
    }
    hash = (37 * hash) + TYPE_FIELD_NUMBER;
    hash = (53 * hash) + type_;
    if (hasStatus()) {
      hash = (37 * hash) + STATUS_FIELD_NUMBER;
      hash = (53 * hash) + getStatus().hashCode();
    }
    switch (specCase_) {
      case 100:
        hash = (37 * hash) + IMPORT_SPEC_FIELD_NUMBER;
        hash = (53 * hash) + getImportSpec().hashCode();
        break;
      case 0:
      default:
    }
    switch (resultCase_) {
      case 200:
        hash = (37 * hash) + IMPORT_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getImportResult().hashCode();
        break;
      case 0:
      default:
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(
      java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(
      byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(
      java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
        PARSER, input, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseDelimitedFrom(
      java.io.InputStream input) throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseDelimitedFrom(
      java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
        PARSER, input, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(
      com.google.protobuf.CodedInputStream input) throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataplex.v1.MetadataJob parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
        PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() {
    return newBuilder();
  }

  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }

  public static Builder newBuilder(com.google.cloud.dataplex.v1.MetadataJob prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }

  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   *
   *
   * <pre>
   * A metadata job resource.
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataplex.v1.MetadataJob}
   */
  public static final class Builder extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
      implements
      // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.MetadataJob)
      com.google.cloud.dataplex.v1.MetadataJobOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapFieldReflectionAccessor internalGetMapFieldReflection(
        int number) {
      switch (number) {
        case 5:
          return internalGetLabels();
        default:
          throw new RuntimeException("Invalid map field number: " + number);
      }
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapFieldReflectionAccessor internalGetMutableMapFieldReflection(
        int number) {
      switch (number) {
        case 5:
          return internalGetMutableLabels();
        default:
          throw new RuntimeException("Invalid map field number: " + number);
      }
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataplex.v1.MetadataJob.class,
              com.google.cloud.dataplex.v1.MetadataJob.Builder.class);
    }

    // Construct using com.google.cloud.dataplex.v1.MetadataJob.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }

    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {
        getCreateTimeFieldBuilder();
        getUpdateTimeFieldBuilder();
        getStatusFieldBuilder();
      }
    }

    @java.lang.Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      name_ = "";
      uid_ = "";
      createTime_ = null;
      if (createTimeBuilder_ != null) {
        createTimeBuilder_.dispose();
        createTimeBuilder_ = null;
      }
      updateTime_ = null;
      if (updateTimeBuilder_ != null) {
        updateTimeBuilder_.dispose();
        updateTimeBuilder_ = null;
      }
      internalGetMutableLabels().clear();
      type_ = 0;
      if (importSpecBuilder_ != null) {
        importSpecBuilder_.clear();
      }
      if (importResultBuilder_ != null) {
        importResultBuilder_.clear();
      }
      status_ = null;
      if (statusBuilder_ != null) {
        statusBuilder_.dispose();
        statusBuilder_ = null;
      }
      specCase_ = 0;
      spec_ = null;
      resultCase_ = 0;
      result_ = null;
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
      return com.google.cloud.dataplex.v1.CatalogProto
          .internal_static_google_cloud_dataplex_v1_MetadataJob_descriptor;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob getDefaultInstanceForType() {
      return com.google.cloud.dataplex.v1.MetadataJob.getDefaultInstance();
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob build() {
      com.google.cloud.dataplex.v1.MetadataJob result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob buildPartial() {
      com.google.cloud.dataplex.v1.MetadataJob result =
          new com.google.cloud.dataplex.v1.MetadataJob(this);
      if (bitField0_ != 0) {
        buildPartial0(result);
      }
      buildPartialOneofs(result);
      onBuilt();
      return result;
    }

    private void buildPartial0(com.google.cloud.dataplex.v1.MetadataJob result) {
      int from_bitField0_ = bitField0_;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        result.name_ = name_;
      }
      if (((from_bitField0_ & 0x00000002) != 0)) {
        result.uid_ = uid_;
      }
      int to_bitField0_ = 0;
      if (((from_bitField0_ & 0x00000004) != 0)) {
        result.createTime_ = createTimeBuilder_ == null ? createTime_ : createTimeBuilder_.build();
        to_bitField0_ |= 0x00000001;
      }
      if (((from_bitField0_ & 0x00000008) != 0)) {
        result.updateTime_ = updateTimeBuilder_ == null ? updateTime_ : updateTimeBuilder_.build();
        to_bitField0_ |= 0x00000002;
      }
      if (((from_bitField0_ & 0x00000010) != 0)) {
        result.labels_ = internalGetLabels();
        result.labels_.makeImmutable();
      }
      if (((from_bitField0_ & 0x00000020) != 0)) {
        result.type_ = type_;
      }
      if (((from_bitField0_ & 0x00000100) != 0)) {
        result.status_ = statusBuilder_ == null ? status_ : statusBuilder_.build();
        to_bitField0_ |= 0x00000004;
      }
      result.bitField0_ |= to_bitField0_;
    }

    private void buildPartialOneofs(com.google.cloud.dataplex.v1.MetadataJob result) {
      result.specCase_ = specCase_;
      result.spec_ = this.spec_;
      if (specCase_ == 100 && importSpecBuilder_ != null) {
        result.spec_ = importSpecBuilder_.build();
      }
      result.resultCase_ = resultCase_;
      result.result_ = this.result_;
      if (resultCase_ == 200 && importResultBuilder_ != null) {
        result.result_ = importResultBuilder_.build();
      }
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }

    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
      return super.setField(field, value);
    }

    @java.lang.Override
    public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }

    @java.lang.Override
    public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }

    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field, int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }

    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }

    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.google.cloud.dataplex.v1.MetadataJob) {
        return mergeFrom((com.google.cloud.dataplex.v1.MetadataJob) other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.google.cloud.dataplex.v1.MetadataJob other) {
      if (other == com.google.cloud.dataplex.v1.MetadataJob.getDefaultInstance()) return this;
      if (!other.getName().isEmpty()) {
        name_ = other.name_;
        bitField0_ |= 0x00000001;
        onChanged();
      }
      if (!other.getUid().isEmpty()) {
        uid_ = other.uid_;
        bitField0_ |= 0x00000002;
        onChanged();
      }
      if (other.hasCreateTime()) {
        mergeCreateTime(other.getCreateTime());
      }
      if (other.hasUpdateTime()) {
        mergeUpdateTime(other.getUpdateTime());
      }
      internalGetMutableLabels().mergeFrom(other.internalGetLabels());
      bitField0_ |= 0x00000010;
      if (other.type_ != 0) {
        setTypeValue(other.getTypeValue());
      }
      if (other.hasStatus()) {
        mergeStatus(other.getStatus());
      }
      switch (other.getSpecCase()) {
        case IMPORT_SPEC:
          {
            mergeImportSpec(other.getImportSpec());
            break;
          }
        case SPEC_NOT_SET:
          {
            break;
          }
      }
      switch (other.getResultCase()) {
        case IMPORT_RESULT:
          {
            mergeImportResult(other.getImportResult());
            break;
          }
        case RESULT_NOT_SET:
          {
            break;
          }
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10:
              {
                name_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
            case 18:
              {
                uid_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
            case 26:
              {
                input.readMessage(getCreateTimeFieldBuilder().getBuilder(), extensionRegistry);
                bitField0_ |= 0x00000004;
                break;
              } // case 26
            case 34:
              {
                input.readMessage(getUpdateTimeFieldBuilder().getBuilder(), extensionRegistry);
                bitField0_ |= 0x00000008;
                break;
              } // case 34
            case 42:
              {
                com.google.protobuf.MapEntry<java.lang.String, java.lang.String> labels__ =
                    input.readMessage(
                        LabelsDefaultEntryHolder.defaultEntry.getParserForType(),
                        extensionRegistry);
                internalGetMutableLabels()
                    .getMutableMap()
                    .put(labels__.getKey(), labels__.getValue());
                bitField0_ |= 0x00000010;
                break;
              } // case 42
            case 48:
              {
                type_ = input.readEnum();
                bitField0_ |= 0x00000020;
                break;
              } // case 48
            case 58:
              {
                input.readMessage(getStatusFieldBuilder().getBuilder(), extensionRegistry);
                bitField0_ |= 0x00000100;
                break;
              } // case 58
            case 802:
              {
                input.readMessage(getImportSpecFieldBuilder().getBuilder(), extensionRegistry);
                specCase_ = 100;
                break;
              } // case 802
            case 1602:
              {
                input.readMessage(getImportResultFieldBuilder().getBuilder(), extensionRegistry);
                resultCase_ = 200;
                break;
              } // case 1602
            default:
              {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }

    private int specCase_ = 0;
    private java.lang.Object spec_;

    public SpecCase getSpecCase() {
      return SpecCase.forNumber(specCase_);
    }

    public Builder clearSpec() {
      specCase_ = 0;
      spec_ = null;
      onChanged();
      return this;
    }

    private int resultCase_ = 0;
    private java.lang.Object result_;

    public ResultCase getResultCase() {
      return ResultCase.forNumber(resultCase_);
    }

    public Builder clearResult() {
      resultCase_ = 0;
      result_ = null;
      onChanged();
      return this;
    }

    private int bitField0_;

    private java.lang.Object name_ = "";
    /**
     *
     *
     * <pre>
     * Output only. Identifier. The name of the resource that the configuration is
     * applied to, in the format
     * `projects/{project_number}/locations/{location_id}/metadataJobs/{metadata_job_id}`.
     * </pre>
     *
     * <code>
     * string name = 1 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_behavior) = IDENTIFIER];
     * </code>
     *
     * @return The name.
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. Identifier. The name of the resource that the configuration is
     * applied to, in the format
     * `projects/{project_number}/locations/{location_id}/metadataJobs/{metadata_job_id}`.
     * </pre>
     *
     * <code>
     * string name = 1 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_behavior) = IDENTIFIER];
     * </code>
     *
     * @return The bytes for name.
     */
    public com.google.protobuf.ByteString getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. Identifier. The name of the resource that the configuration is
     * applied to, in the format
     * `projects/{project_number}/locations/{location_id}/metadataJobs/{metadata_job_id}`.
     * </pre>
     *
     * <code>
     * string name = 1 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_behavior) = IDENTIFIER];
     * </code>
     *
     * @param value The name to set.
     * @return This builder for chaining.
     */
    public Builder setName(java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      name_ = value;
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Identifier. The name of the resource that the configuration is
     * applied to, in the format
     * `projects/{project_number}/locations/{location_id}/metadataJobs/{metadata_job_id}`.
     * </pre>
     *
     * <code>
     * string name = 1 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_behavior) = IDENTIFIER];
     * </code>
     *
     * @return This builder for chaining.
     */
    public Builder clearName() {
      name_ = getDefaultInstance().getName();
      bitField0_ = (bitField0_ & ~0x00000001);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Identifier. The name of the resource that the configuration is
     * applied to, in the format
     * `projects/{project_number}/locations/{location_id}/metadataJobs/{metadata_job_id}`.
     * </pre>
     *
     * <code>
     * string name = 1 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_behavior) = IDENTIFIER];
     * </code>
     *
     * @param value The bytes for name to set.
     * @return This builder for chaining.
     */
    public Builder setNameBytes(com.google.protobuf.ByteString value) {
      if (value == null) {
        throw new NullPointerException();
      }
      checkByteStringIsUtf8(value);
      name_ = value;
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }

    private java.lang.Object uid_ = "";
    /**
     *
     *
     * <pre>
     * Output only. A system-generated, globally unique ID for the metadata job.
     * If the metadata job is deleted and then re-created with the same name, this
     * ID is different.
     * </pre>
     *
     * <code>
     * string uid = 2 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_info) = { ... }
     * </code>
     *
     * @return The uid.
     */
    public java.lang.String getUid() {
      java.lang.Object ref = uid_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        uid_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. A system-generated, globally unique ID for the metadata job.
     * If the metadata job is deleted and then re-created with the same name, this
     * ID is different.
     * </pre>
     *
     * <code>
     * string uid = 2 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_info) = { ... }
     * </code>
     *
     * @return The bytes for uid.
     */
    public com.google.protobuf.ByteString getUidBytes() {
      java.lang.Object ref = uid_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
        uid_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. A system-generated, globally unique ID for the metadata job.
     * If the metadata job is deleted and then re-created with the same name, this
     * ID is different.
     * </pre>
     *
     * <code>
     * string uid = 2 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_info) = { ... }
     * </code>
     *
     * @param value The uid to set.
     * @return This builder for chaining.
     */
    public Builder setUid(java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      uid_ = value;
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. A system-generated, globally unique ID for the metadata job.
     * If the metadata job is deleted and then re-created with the same name, this
     * ID is different.
     * </pre>
     *
     * <code>
     * string uid = 2 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_info) = { ... }
     * </code>
     *
     * @return This builder for chaining.
     */
    public Builder clearUid() {
      uid_ = getDefaultInstance().getUid();
      bitField0_ = (bitField0_ & ~0x00000002);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. A system-generated, globally unique ID for the metadata job.
     * If the metadata job is deleted and then re-created with the same name, this
     * ID is different.
     * </pre>
     *
     * <code>
     * string uid = 2 [(.google.api.field_behavior) = OUTPUT_ONLY, (.google.api.field_info) = { ... }
     * </code>
     *
     * @param value The bytes for uid to set.
     * @return This builder for chaining.
     */
    public Builder setUidBytes(com.google.protobuf.ByteString value) {
      if (value == null) {
        throw new NullPointerException();
      }
      checkByteStringIsUtf8(value);
      uid_ = value;
      bitField0_ |= 0x00000002;
      onChanged();
      return this;
    }

    private com.google.protobuf.Timestamp createTime_;
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.protobuf.Timestamp,
            com.google.protobuf.Timestamp.Builder,
            com.google.protobuf.TimestampOrBuilder>
        createTimeBuilder_;
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the createTime field is set.
     */
    public boolean hasCreateTime() {
      return ((bitField0_ & 0x00000004) != 0);
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The createTime.
     */
    public com.google.protobuf.Timestamp getCreateTime() {
      if (createTimeBuilder_ == null) {
        return createTime_ == null
            ? com.google.protobuf.Timestamp.getDefaultInstance()
            : createTime_;
      } else {
        return createTimeBuilder_.getMessage();
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setCreateTime(com.google.protobuf.Timestamp value) {
      if (createTimeBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        createTime_ = value;
      } else {
        createTimeBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setCreateTime(com.google.protobuf.Timestamp.Builder builderForValue) {
      if (createTimeBuilder_ == null) {
        createTime_ = builderForValue.build();
      } else {
        createTimeBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000004;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder mergeCreateTime(com.google.protobuf.Timestamp value) {
      if (createTimeBuilder_ == null) {
        if (((bitField0_ & 0x00000004) != 0)
            && createTime_ != null
            && createTime_ != com.google.protobuf.Timestamp.getDefaultInstance()) {
          getCreateTimeBuilder().mergeFrom(value);
        } else {
          createTime_ = value;
        }
      } else {
        createTimeBuilder_.mergeFrom(value);
      }
      if (createTime_ != null) {
        bitField0_ |= 0x00000004;
        onChanged();
      }
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder clearCreateTime() {
      bitField0_ = (bitField0_ & ~0x00000004);
      createTime_ = null;
      if (createTimeBuilder_ != null) {
        createTimeBuilder_.dispose();
        createTimeBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public com.google.protobuf.Timestamp.Builder getCreateTimeBuilder() {
      bitField0_ |= 0x00000004;
      onChanged();
      return getCreateTimeFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public com.google.protobuf.TimestampOrBuilder getCreateTimeOrBuilder() {
      if (createTimeBuilder_ != null) {
        return createTimeBuilder_.getMessageOrBuilder();
      } else {
        return createTime_ == null
            ? com.google.protobuf.Timestamp.getDefaultInstance()
            : createTime_;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was created.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp create_time = 3 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.protobuf.Timestamp,
            com.google.protobuf.Timestamp.Builder,
            com.google.protobuf.TimestampOrBuilder>
        getCreateTimeFieldBuilder() {
      if (createTimeBuilder_ == null) {
        createTimeBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.protobuf.Timestamp,
                com.google.protobuf.Timestamp.Builder,
                com.google.protobuf.TimestampOrBuilder>(
                getCreateTime(), getParentForChildren(), isClean());
        createTime_ = null;
      }
      return createTimeBuilder_;
    }

    private com.google.protobuf.Timestamp updateTime_;
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.protobuf.Timestamp,
            com.google.protobuf.Timestamp.Builder,
            com.google.protobuf.TimestampOrBuilder>
        updateTimeBuilder_;
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the updateTime field is set.
     */
    public boolean hasUpdateTime() {
      return ((bitField0_ & 0x00000008) != 0);
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The updateTime.
     */
    public com.google.protobuf.Timestamp getUpdateTime() {
      if (updateTimeBuilder_ == null) {
        return updateTime_ == null
            ? com.google.protobuf.Timestamp.getDefaultInstance()
            : updateTime_;
      } else {
        return updateTimeBuilder_.getMessage();
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setUpdateTime(com.google.protobuf.Timestamp value) {
      if (updateTimeBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        updateTime_ = value;
      } else {
        updateTimeBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setUpdateTime(com.google.protobuf.Timestamp.Builder builderForValue) {
      if (updateTimeBuilder_ == null) {
        updateTime_ = builderForValue.build();
      } else {
        updateTimeBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000008;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder mergeUpdateTime(com.google.protobuf.Timestamp value) {
      if (updateTimeBuilder_ == null) {
        if (((bitField0_ & 0x00000008) != 0)
            && updateTime_ != null
            && updateTime_ != com.google.protobuf.Timestamp.getDefaultInstance()) {
          getUpdateTimeBuilder().mergeFrom(value);
        } else {
          updateTime_ = value;
        }
      } else {
        updateTimeBuilder_.mergeFrom(value);
      }
      if (updateTime_ != null) {
        bitField0_ |= 0x00000008;
        onChanged();
      }
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder clearUpdateTime() {
      bitField0_ = (bitField0_ & ~0x00000008);
      updateTime_ = null;
      if (updateTimeBuilder_ != null) {
        updateTimeBuilder_.dispose();
        updateTimeBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public com.google.protobuf.Timestamp.Builder getUpdateTimeBuilder() {
      bitField0_ |= 0x00000008;
      onChanged();
      return getUpdateTimeFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public com.google.protobuf.TimestampOrBuilder getUpdateTimeOrBuilder() {
      if (updateTimeBuilder_ != null) {
        return updateTimeBuilder_.getMessageOrBuilder();
      } else {
        return updateTime_ == null
            ? com.google.protobuf.Timestamp.getDefaultInstance()
            : updateTime_;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. The time when the metadata job was updated.
     * </pre>
     *
     * <code>
     * .google.protobuf.Timestamp update_time = 4 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.protobuf.Timestamp,
            com.google.protobuf.Timestamp.Builder,
            com.google.protobuf.TimestampOrBuilder>
        getUpdateTimeFieldBuilder() {
      if (updateTimeBuilder_ == null) {
        updateTimeBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.protobuf.Timestamp,
                com.google.protobuf.Timestamp.Builder,
                com.google.protobuf.TimestampOrBuilder>(
                getUpdateTime(), getParentForChildren(), isClean());
        updateTime_ = null;
      }
      return updateTimeBuilder_;
    }

    private com.google.protobuf.MapField<java.lang.String, java.lang.String> labels_;

    private com.google.protobuf.MapField<java.lang.String, java.lang.String> internalGetLabels() {
      if (labels_ == null) {
        return com.google.protobuf.MapField.emptyMapField(LabelsDefaultEntryHolder.defaultEntry);
      }
      return labels_;
    }

    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
        internalGetMutableLabels() {
      if (labels_ == null) {
        labels_ = com.google.protobuf.MapField.newMapField(LabelsDefaultEntryHolder.defaultEntry);
      }
      if (!labels_.isMutable()) {
        labels_ = labels_.copy();
      }
      bitField0_ |= 0x00000010;
      onChanged();
      return labels_;
    }

    public int getLabelsCount() {
      return internalGetLabels().getMap().size();
    }
    /**
     *
     *
     * <pre>
     * Optional. User-defined labels.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     */
    @java.lang.Override
    public boolean containsLabels(java.lang.String key) {
      if (key == null) {
        throw new NullPointerException("map key");
      }
      return internalGetLabels().getMap().containsKey(key);
    }
    /** Use {@link #getLabelsMap()} instead. */
    @java.lang.Override
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getLabels() {
      return getLabelsMap();
    }
    /**
     *
     *
     * <pre>
     * Optional. User-defined labels.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     */
    @java.lang.Override
    public java.util.Map<java.lang.String, java.lang.String> getLabelsMap() {
      return internalGetLabels().getMap();
    }
    /**
     *
     *
     * <pre>
     * Optional. User-defined labels.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     */
    @java.lang.Override
    public /* nullable */ java.lang.String getLabelsOrDefault(
        java.lang.String key,
        /* nullable */
        java.lang.String defaultValue) {
      if (key == null) {
        throw new NullPointerException("map key");
      }
      java.util.Map<java.lang.String, java.lang.String> map = internalGetLabels().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     *
     *
     * <pre>
     * Optional. User-defined labels.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     */
    @java.lang.Override
    public java.lang.String getLabelsOrThrow(java.lang.String key) {
      if (key == null) {
        throw new NullPointerException("map key");
      }
      java.util.Map<java.lang.String, java.lang.String> map = internalGetLabels().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public Builder clearLabels() {
      bitField0_ = (bitField0_ & ~0x00000010);
      internalGetMutableLabels().getMutableMap().clear();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. User-defined labels.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     */
    public Builder removeLabels(java.lang.String key) {
      if (key == null) {
        throw new NullPointerException("map key");
      }
      internalGetMutableLabels().getMutableMap().remove(key);
      return this;
    }
    /** Use alternate mutation accessors instead. */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getMutableLabels() {
      bitField0_ |= 0x00000010;
      return internalGetMutableLabels().getMutableMap();
    }
    /**
     *
     *
     * <pre>
     * Optional. User-defined labels.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     */
    public Builder putLabels(java.lang.String key, java.lang.String value) {
      if (key == null) {
        throw new NullPointerException("map key");
      }
      if (value == null) {
        throw new NullPointerException("map value");
      }
      internalGetMutableLabels().getMutableMap().put(key, value);
      bitField0_ |= 0x00000010;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. User-defined labels.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
     */
    public Builder putAllLabels(java.util.Map<java.lang.String, java.lang.String> values) {
      internalGetMutableLabels().getMutableMap().putAll(values);
      bitField0_ |= 0x00000010;
      return this;
    }

    private int type_ = 0;
    /**
     *
     *
     * <pre>
     * Required. Metadata job type.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Type type = 6 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The enum numeric value on the wire for type.
     */
    @java.lang.Override
    public int getTypeValue() {
      return type_;
    }
    /**
     *
     *
     * <pre>
     * Required. Metadata job type.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Type type = 6 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @param value The enum numeric value on the wire for type to set.
     * @return This builder for chaining.
     */
    public Builder setTypeValue(int value) {
      type_ = value;
      bitField0_ |= 0x00000020;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Required. Metadata job type.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Type type = 6 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return The type.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.Type getType() {
      com.google.cloud.dataplex.v1.MetadataJob.Type result =
          com.google.cloud.dataplex.v1.MetadataJob.Type.forNumber(type_);
      return result == null ? com.google.cloud.dataplex.v1.MetadataJob.Type.UNRECOGNIZED : result;
    }
    /**
     *
     *
     * <pre>
     * Required. Metadata job type.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Type type = 6 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @param value The type to set.
     * @return This builder for chaining.
     */
    public Builder setType(com.google.cloud.dataplex.v1.MetadataJob.Type value) {
      if (value == null) {
        throw new NullPointerException();
      }
      bitField0_ |= 0x00000020;
      type_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Required. Metadata job type.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Type type = 6 [(.google.api.field_behavior) = REQUIRED];
     * </code>
     *
     * @return This builder for chaining.
     */
    public Builder clearType() {
      bitField0_ = (bitField0_ & ~0x00000020);
      type_ = 0;
      onChanged();
      return this;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.Builder,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpecOrBuilder>
        importSpecBuilder_;
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     *
     * @return Whether the importSpec field is set.
     */
    @java.lang.Override
    public boolean hasImportSpec() {
      return specCase_ == 100;
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     *
     * @return The importSpec.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec getImportSpec() {
      if (importSpecBuilder_ == null) {
        if (specCase_ == 100) {
          return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_;
        }
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance();
      } else {
        if (specCase_ == 100) {
          return importSpecBuilder_.getMessage();
        }
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance();
      }
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     */
    public Builder setImportSpec(com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec value) {
      if (importSpecBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        spec_ = value;
        onChanged();
      } else {
        importSpecBuilder_.setMessage(value);
      }
      specCase_ = 100;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     */
    public Builder setImportSpec(
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.Builder builderForValue) {
      if (importSpecBuilder_ == null) {
        spec_ = builderForValue.build();
        onChanged();
      } else {
        importSpecBuilder_.setMessage(builderForValue.build());
      }
      specCase_ = 100;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     */
    public Builder mergeImportSpec(com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec value) {
      if (importSpecBuilder_ == null) {
        if (specCase_ == 100
            && spec_
                != com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance()) {
          spec_ =
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.newBuilder(
                      (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_)
                  .mergeFrom(value)
                  .buildPartial();
        } else {
          spec_ = value;
        }
        onChanged();
      } else {
        if (specCase_ == 100) {
          importSpecBuilder_.mergeFrom(value);
        } else {
          importSpecBuilder_.setMessage(value);
        }
      }
      specCase_ = 100;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     */
    public Builder clearImportSpec() {
      if (importSpecBuilder_ == null) {
        if (specCase_ == 100) {
          specCase_ = 0;
          spec_ = null;
          onChanged();
        }
      } else {
        if (specCase_ == 100) {
          specCase_ = 0;
          spec_ = null;
        }
        importSpecBuilder_.clear();
      }
      return this;
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     */
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.Builder getImportSpecBuilder() {
      return getImportSpecFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpecOrBuilder
        getImportSpecOrBuilder() {
      if ((specCase_ == 100) && (importSpecBuilder_ != null)) {
        return importSpecBuilder_.getMessageOrBuilder();
      } else {
        if (specCase_ == 100) {
          return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_;
        }
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance();
      }
    }
    /**
     *
     *
     * <pre>
     * Import job specification.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec import_spec = 100;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.Builder,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpecOrBuilder>
        getImportSpecFieldBuilder() {
      if (importSpecBuilder_ == null) {
        if (!(specCase_ == 100)) {
          spec_ = com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.getDefaultInstance();
        }
        importSpecBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec,
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec.Builder,
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpecOrBuilder>(
                (com.google.cloud.dataplex.v1.MetadataJob.ImportJobSpec) spec_,
                getParentForChildren(),
                isClean());
        spec_ = null;
      }
      specCase_ = 100;
      onChanged();
      return importSpecBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.Builder,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobResultOrBuilder>
        importResultBuilder_;
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the importResult field is set.
     */
    @java.lang.Override
    public boolean hasImportResult() {
      return resultCase_ == 200;
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The importResult.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult getImportResult() {
      if (importResultBuilder_ == null) {
        if (resultCase_ == 200) {
          return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_;
        }
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance();
      } else {
        if (resultCase_ == 200) {
          return importResultBuilder_.getMessage();
        }
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance();
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setImportResult(com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult value) {
      if (importResultBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        result_ = value;
        onChanged();
      } else {
        importResultBuilder_.setMessage(value);
      }
      resultCase_ = 200;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setImportResult(
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.Builder builderForValue) {
      if (importResultBuilder_ == null) {
        result_ = builderForValue.build();
        onChanged();
      } else {
        importResultBuilder_.setMessage(builderForValue.build());
      }
      resultCase_ = 200;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder mergeImportResult(
        com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult value) {
      if (importResultBuilder_ == null) {
        if (resultCase_ == 200
            && result_
                != com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance()) {
          result_ =
              com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.newBuilder(
                      (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_)
                  .mergeFrom(value)
                  .buildPartial();
        } else {
          result_ = value;
        }
        onChanged();
      } else {
        if (resultCase_ == 200) {
          importResultBuilder_.mergeFrom(value);
        } else {
          importResultBuilder_.setMessage(value);
        }
      }
      resultCase_ = 200;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder clearImportResult() {
      if (importResultBuilder_ == null) {
        if (resultCase_ == 200) {
          resultCase_ = 0;
          result_ = null;
          onChanged();
        }
      } else {
        if (resultCase_ == 200) {
          resultCase_ = 0;
          result_ = null;
        }
        importResultBuilder_.clear();
      }
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.Builder
        getImportResultBuilder() {
      return getImportResultFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.MetadataJob.ImportJobResultOrBuilder
        getImportResultOrBuilder() {
      if ((resultCase_ == 200) && (importResultBuilder_ != null)) {
        return importResultBuilder_.getMessageOrBuilder();
      } else {
        if (resultCase_ == 200) {
          return (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_;
        }
        return com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance();
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. Import job result.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.ImportJobResult import_result = 200 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.Builder,
            com.google.cloud.dataplex.v1.MetadataJob.ImportJobResultOrBuilder>
        getImportResultFieldBuilder() {
      if (importResultBuilder_ == null) {
        if (!(resultCase_ == 200)) {
          result_ = com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.getDefaultInstance();
        }
        importResultBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult,
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult.Builder,
                com.google.cloud.dataplex.v1.MetadataJob.ImportJobResultOrBuilder>(
                (com.google.cloud.dataplex.v1.MetadataJob.ImportJobResult) result_,
                getParentForChildren(),
                isClean());
        result_ = null;
      }
      resultCase_ = 200;
      onChanged();
      return importResultBuilder_;
    }

    private com.google.cloud.dataplex.v1.MetadataJob.Status status_;
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.MetadataJob.Status,
            com.google.cloud.dataplex.v1.MetadataJob.Status.Builder,
            com.google.cloud.dataplex.v1.MetadataJob.StatusOrBuilder>
        statusBuilder_;
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return Whether the status field is set.
     */
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000100) != 0);
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     *
     * @return The status.
     */
    public com.google.cloud.dataplex.v1.MetadataJob.Status getStatus() {
      if (statusBuilder_ == null) {
        return status_ == null
            ? com.google.cloud.dataplex.v1.MetadataJob.Status.getDefaultInstance()
            : status_;
      } else {
        return statusBuilder_.getMessage();
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setStatus(com.google.cloud.dataplex.v1.MetadataJob.Status value) {
      if (statusBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        status_ = value;
      } else {
        statusBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000100;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder setStatus(
        com.google.cloud.dataplex.v1.MetadataJob.Status.Builder builderForValue) {
      if (statusBuilder_ == null) {
        status_ = builderForValue.build();
      } else {
        statusBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000100;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder mergeStatus(com.google.cloud.dataplex.v1.MetadataJob.Status value) {
      if (statusBuilder_ == null) {
        if (((bitField0_ & 0x00000100) != 0)
            && status_ != null
            && status_ != com.google.cloud.dataplex.v1.MetadataJob.Status.getDefaultInstance()) {
          getStatusBuilder().mergeFrom(value);
        } else {
          status_ = value;
        }
      } else {
        statusBuilder_.mergeFrom(value);
      }
      if (status_ != null) {
        bitField0_ |= 0x00000100;
        onChanged();
      }
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public Builder clearStatus() {
      bitField0_ = (bitField0_ & ~0x00000100);
      status_ = null;
      if (statusBuilder_ != null) {
        statusBuilder_.dispose();
        statusBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public com.google.cloud.dataplex.v1.MetadataJob.Status.Builder getStatusBuilder() {
      bitField0_ |= 0x00000100;
      onChanged();
      return getStatusFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    public com.google.cloud.dataplex.v1.MetadataJob.StatusOrBuilder getStatusOrBuilder() {
      if (statusBuilder_ != null) {
        return statusBuilder_.getMessageOrBuilder();
      } else {
        return status_ == null
            ? com.google.cloud.dataplex.v1.MetadataJob.Status.getDefaultInstance()
            : status_;
      }
    }
    /**
     *
     *
     * <pre>
     * Output only. Metadata job status.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.MetadataJob.Status status = 7 [(.google.api.field_behavior) = OUTPUT_ONLY];
     * </code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.MetadataJob.Status,
            com.google.cloud.dataplex.v1.MetadataJob.Status.Builder,
            com.google.cloud.dataplex.v1.MetadataJob.StatusOrBuilder>
        getStatusFieldBuilder() {
      if (statusBuilder_ == null) {
        statusBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.cloud.dataplex.v1.MetadataJob.Status,
                com.google.cloud.dataplex.v1.MetadataJob.Status.Builder,
                com.google.cloud.dataplex.v1.MetadataJob.StatusOrBuilder>(
                getStatus(), getParentForChildren(), isClean());
        status_ = null;
      }
      return statusBuilder_;
    }

    @java.lang.Override
    public final Builder setUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }

    // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.MetadataJob)
  }

  // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.MetadataJob)
  private static final com.google.cloud.dataplex.v1.MetadataJob DEFAULT_INSTANCE;

  static {
    DEFAULT_INSTANCE = new com.google.cloud.dataplex.v1.MetadataJob();
  }

  public static com.google.cloud.dataplex.v1.MetadataJob getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<MetadataJob> PARSER =
      new com.google.protobuf.AbstractParser<MetadataJob>() {
        @java.lang.Override
        public MetadataJob parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

  public static com.google.protobuf.Parser<MetadataJob> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<MetadataJob> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.cloud.dataplex.v1.MetadataJob getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }
}
