/*
 * Copyright 2025 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/dataplex/v1/data_discovery.proto

// Protobuf Java Version: 3.25.5
package com.google.cloud.dataplex.v1;

/**
 *
 *
 * <pre>
 * Spec for a data discovery scan.
 * </pre>
 *
 * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec}
 */
public final class DataDiscoverySpec extends com.google.protobuf.GeneratedMessageV3
    implements
    // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.DataDiscoverySpec)
    DataDiscoverySpecOrBuilder {
  private static final long serialVersionUID = 0L;
  // Use DataDiscoverySpec.newBuilder() to construct.
  private DataDiscoverySpec(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }

  private DataDiscoverySpec() {}

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
    return new DataDiscoverySpec();
  }

  public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
    return com.google.cloud.dataplex.v1.DataDiscoveryProto
        .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_descriptor;
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.google.cloud.dataplex.v1.DataDiscoveryProto
        .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.google.cloud.dataplex.v1.DataDiscoverySpec.class,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.Builder.class);
  }

  public interface BigQueryPublishingConfigOrBuilder
      extends
      // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     *
     *
     * <pre>
     * Optional. Determines whether to  publish discovered tables as BigLake
     * external tables or non-BigLake external tables.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The enum numeric value on the wire for tableType.
     */
    int getTableTypeValue();
    /**
     *
     *
     * <pre>
     * Optional. Determines whether to  publish discovered tables as BigLake
     * external tables or non-BigLake external tables.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The tableType.
     */
    com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
        getTableType();

    /**
     *
     *
     * <pre>
     * Optional. The BigQuery connection used to create BigLake tables.
     * Must be in the form
     * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
     * </pre>
     *
     * <code>
     * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
     * </code>
     *
     * @return The connection.
     */
    java.lang.String getConnection();
    /**
     *
     *
     * <pre>
     * Optional. The BigQuery connection used to create BigLake tables.
     * Must be in the form
     * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
     * </pre>
     *
     * <code>
     * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
     * </code>
     *
     * @return The bytes for connection.
     */
    com.google.protobuf.ByteString getConnectionBytes();

    /**
     *
     *
     * <pre>
     * Optional. The location of the BigQuery dataset to publish BigLake
     * external or non-BigLake external tables to.
     * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
     * BigQuery dataset can be in the same multi-region bucket or any single
     * region that is included in the same multi-region bucket. The datascan can
     * be created in any single region that is included in the same multi-region
     * bucket
     * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
     * BigQuery dataset can be located in regions that are included in the
     * dual-region bucket, or in a multi-region that includes the dual-region.
     * The datascan can be created in any single region that is included in the
     * same dual-region bucket.
     * 3. If the Cloud Storage bucket is located in a single region, then
     * BigQuery dataset can be in the same single region or any multi-region
     * bucket that includes the same single region. The datascan will be created
     * in the same single region as the bucket.
     * 4. If the BigQuery dataset is in single region, it must be in the same
     * single region as the datascan.
     *
     * For supported values, refer to
     * https://cloud.google.com/bigquery/docs/locations#supported_locations.
     * </pre>
     *
     * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The location.
     */
    java.lang.String getLocation();
    /**
     *
     *
     * <pre>
     * Optional. The location of the BigQuery dataset to publish BigLake
     * external or non-BigLake external tables to.
     * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
     * BigQuery dataset can be in the same multi-region bucket or any single
     * region that is included in the same multi-region bucket. The datascan can
     * be created in any single region that is included in the same multi-region
     * bucket
     * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
     * BigQuery dataset can be located in regions that are included in the
     * dual-region bucket, or in a multi-region that includes the dual-region.
     * The datascan can be created in any single region that is included in the
     * same dual-region bucket.
     * 3. If the Cloud Storage bucket is located in a single region, then
     * BigQuery dataset can be in the same single region or any multi-region
     * bucket that includes the same single region. The datascan will be created
     * in the same single region as the bucket.
     * 4. If the BigQuery dataset is in single region, it must be in the same
     * single region as the datascan.
     *
     * For supported values, refer to
     * https://cloud.google.com/bigquery/docs/locations#supported_locations.
     * </pre>
     *
     * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The bytes for location.
     */
    com.google.protobuf.ByteString getLocationBytes();
  }
  /**
   *
   *
   * <pre>
   * Describes BigQuery publishing configurations.
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig}
   */
  public static final class BigQueryPublishingConfig extends com.google.protobuf.GeneratedMessageV3
      implements
      // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig)
      BigQueryPublishingConfigOrBuilder {
    private static final long serialVersionUID = 0L;
    // Use BigQueryPublishingConfig.newBuilder() to construct.
    private BigQueryPublishingConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }

    private BigQueryPublishingConfig() {
      tableType_ = 0;
      connection_ = "";
      location_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
      return new BigQueryPublishingConfig();
    }

    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.DataDiscoveryProto
          .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_BigQueryPublishingConfig_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataplex.v1.DataDiscoveryProto
          .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_BigQueryPublishingConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.class,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.Builder
                  .class);
    }

    /**
     *
     *
     * <pre>
     * Determines how discovered tables are published.
     * </pre>
     *
     * Protobuf enum {@code
     * google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType}
     */
    public enum TableType implements com.google.protobuf.ProtocolMessageEnum {
      /**
       *
       *
       * <pre>
       * Table type unspecified.
       * </pre>
       *
       * <code>TABLE_TYPE_UNSPECIFIED = 0;</code>
       */
      TABLE_TYPE_UNSPECIFIED(0),
      /**
       *
       *
       * <pre>
       * Default. Discovered tables are published as BigQuery external tables
       * whose data is accessed using the credentials of the user querying the
       * table.
       * </pre>
       *
       * <code>EXTERNAL = 1;</code>
       */
      EXTERNAL(1),
      /**
       *
       *
       * <pre>
       * Discovered tables are published as BigLake external tables whose data
       * is accessed using the credentials of the associated BigQuery
       * connection.
       * </pre>
       *
       * <code>BIGLAKE = 2;</code>
       */
      BIGLAKE(2),
      UNRECOGNIZED(-1),
      ;

      /**
       *
       *
       * <pre>
       * Table type unspecified.
       * </pre>
       *
       * <code>TABLE_TYPE_UNSPECIFIED = 0;</code>
       */
      public static final int TABLE_TYPE_UNSPECIFIED_VALUE = 0;
      /**
       *
       *
       * <pre>
       * Default. Discovered tables are published as BigQuery external tables
       * whose data is accessed using the credentials of the user querying the
       * table.
       * </pre>
       *
       * <code>EXTERNAL = 1;</code>
       */
      public static final int EXTERNAL_VALUE = 1;
      /**
       *
       *
       * <pre>
       * Discovered tables are published as BigLake external tables whose data
       * is accessed using the credentials of the associated BigQuery
       * connection.
       * </pre>
       *
       * <code>BIGLAKE = 2;</code>
       */
      public static final int BIGLAKE_VALUE = 2;

      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static TableType valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static TableType forNumber(int value) {
        switch (value) {
          case 0:
            return TABLE_TYPE_UNSPECIFIED;
          case 1:
            return EXTERNAL;
          case 2:
            return BIGLAKE;
          default:
            return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<TableType> internalGetValueMap() {
        return internalValueMap;
      }

      private static final com.google.protobuf.Internal.EnumLiteMap<TableType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<TableType>() {
            public TableType findValueByNumber(int number) {
              return TableType.forNumber(number);
            }
          };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }

      public final com.google.protobuf.Descriptors.EnumDescriptor getDescriptorForType() {
        return getDescriptor();
      }

      public static final com.google.protobuf.Descriptors.EnumDescriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
            .getDescriptor()
            .getEnumTypes()
            .get(0);
      }

      private static final TableType[] VALUES = values();

      public static TableType valueOf(com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException("EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private TableType(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType)
    }

    public static final int TABLE_TYPE_FIELD_NUMBER = 2;
    private int tableType_ = 0;
    /**
     *
     *
     * <pre>
     * Optional. Determines whether to  publish discovered tables as BigLake
     * external tables or non-BigLake external tables.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The enum numeric value on the wire for tableType.
     */
    @java.lang.Override
    public int getTableTypeValue() {
      return tableType_;
    }
    /**
     *
     *
     * <pre>
     * Optional. Determines whether to  publish discovered tables as BigLake
     * external tables or non-BigLake external tables.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The tableType.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
        getTableType() {
      com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType result =
          com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
              .forNumber(tableType_);
      return result == null
          ? com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
              .UNRECOGNIZED
          : result;
    }

    public static final int CONNECTION_FIELD_NUMBER = 3;

    @SuppressWarnings("serial")
    private volatile java.lang.Object connection_ = "";
    /**
     *
     *
     * <pre>
     * Optional. The BigQuery connection used to create BigLake tables.
     * Must be in the form
     * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
     * </pre>
     *
     * <code>
     * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
     * </code>
     *
     * @return The connection.
     */
    @java.lang.Override
    public java.lang.String getConnection() {
      java.lang.Object ref = connection_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        connection_ = s;
        return s;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. The BigQuery connection used to create BigLake tables.
     * Must be in the form
     * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
     * </pre>
     *
     * <code>
     * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
     * </code>
     *
     * @return The bytes for connection.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getConnectionBytes() {
      java.lang.Object ref = connection_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
        connection_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LOCATION_FIELD_NUMBER = 4;

    @SuppressWarnings("serial")
    private volatile java.lang.Object location_ = "";
    /**
     *
     *
     * <pre>
     * Optional. The location of the BigQuery dataset to publish BigLake
     * external or non-BigLake external tables to.
     * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
     * BigQuery dataset can be in the same multi-region bucket or any single
     * region that is included in the same multi-region bucket. The datascan can
     * be created in any single region that is included in the same multi-region
     * bucket
     * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
     * BigQuery dataset can be located in regions that are included in the
     * dual-region bucket, or in a multi-region that includes the dual-region.
     * The datascan can be created in any single region that is included in the
     * same dual-region bucket.
     * 3. If the Cloud Storage bucket is located in a single region, then
     * BigQuery dataset can be in the same single region or any multi-region
     * bucket that includes the same single region. The datascan will be created
     * in the same single region as the bucket.
     * 4. If the BigQuery dataset is in single region, it must be in the same
     * single region as the datascan.
     *
     * For supported values, refer to
     * https://cloud.google.com/bigquery/docs/locations#supported_locations.
     * </pre>
     *
     * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The location.
     */
    @java.lang.Override
    public java.lang.String getLocation() {
      java.lang.Object ref = location_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        location_ = s;
        return s;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. The location of the BigQuery dataset to publish BigLake
     * external or non-BigLake external tables to.
     * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
     * BigQuery dataset can be in the same multi-region bucket or any single
     * region that is included in the same multi-region bucket. The datascan can
     * be created in any single region that is included in the same multi-region
     * bucket
     * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
     * BigQuery dataset can be located in regions that are included in the
     * dual-region bucket, or in a multi-region that includes the dual-region.
     * The datascan can be created in any single region that is included in the
     * same dual-region bucket.
     * 3. If the Cloud Storage bucket is located in a single region, then
     * BigQuery dataset can be in the same single region or any multi-region
     * bucket that includes the same single region. The datascan will be created
     * in the same single region as the bucket.
     * 4. If the BigQuery dataset is in single region, it must be in the same
     * single region as the datascan.
     *
     * For supported values, refer to
     * https://cloud.google.com/bigquery/docs/locations#supported_locations.
     * </pre>
     *
     * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The bytes for location.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getLocationBytes() {
      java.lang.Object ref = location_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
        location_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;

    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
      if (tableType_
          != com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
              .TABLE_TYPE_UNSPECIFIED
              .getNumber()) {
        output.writeEnum(2, tableType_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(connection_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, connection_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(location_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, location_);
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (tableType_
          != com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
              .TABLE_TYPE_UNSPECIFIED
              .getNumber()) {
        size += com.google.protobuf.CodedOutputStream.computeEnumSize(2, tableType_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(connection_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, connection_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(location_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, location_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
        return true;
      }
      if (!(obj
          instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig)) {
        return super.equals(obj);
      }
      com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig other =
          (com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig) obj;

      if (tableType_ != other.tableType_) return false;
      if (!getConnection().equals(other.getConnection())) return false;
      if (!getLocation().equals(other.getLocation())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + TABLE_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + tableType_;
      hash = (37 * hash) + CONNECTION_FIELD_NUMBER;
      hash = (53 * hash) + getConnection().hashCode();
      hash = (37 * hash) + LOCATION_FIELD_NUMBER;
      hash = (53 * hash) + getLocation().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        byte[] data) throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
        parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
        parseDelimitedFrom(
            java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        com.google.protobuf.CodedInputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() {
      return newBuilder();
    }

    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }

    public static Builder newBuilder(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }

    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     *
     *
     * <pre>
     * Describes BigQuery publishing configurations.
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig}
     */
    public static final class Builder
        extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
        implements
        // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig)
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_BigQueryPublishingConfig_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_BigQueryPublishingConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.class,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.Builder
                    .class);
      }

      // Construct using
      // com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.newBuilder()
      private Builder() {}

      private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
      }

      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        tableType_ = 0;
        connection_ = "";
        location_ = "";
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_BigQueryPublishingConfig_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
          getDefaultInstanceForType() {
        return com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
            .getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig build() {
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig result =
            buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
          buildPartial() {
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig result =
            new com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig(this);
        if (bitField0_ != 0) {
          buildPartial0(result);
        }
        onBuilt();
        return result;
      }

      private void buildPartial0(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.tableType_ = tableType_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.connection_ = connection_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.location_ = location_;
        }
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }

      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.setField(field, value);
      }

      @java.lang.Override
      public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }

      @java.lang.Override
      public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }

      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index,
          java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }

      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }

      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other
            instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig) {
          return mergeFrom(
              (com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig) other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig other) {
        if (other
            == com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
                .getDefaultInstance()) return this;
        if (other.tableType_ != 0) {
          setTableTypeValue(other.getTableTypeValue());
        }
        if (!other.getConnection().isEmpty()) {
          connection_ = other.connection_;
          bitField0_ |= 0x00000002;
          onChanged();
        }
        if (!other.getLocation().isEmpty()) {
          location_ = other.location_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 16:
                {
                  tableType_ = input.readEnum();
                  bitField0_ |= 0x00000001;
                  break;
                } // case 16
              case 26:
                {
                  connection_ = input.readStringRequireUtf8();
                  bitField0_ |= 0x00000002;
                  break;
                } // case 26
              case 34:
                {
                  location_ = input.readStringRequireUtf8();
                  bitField0_ |= 0x00000004;
                  break;
                } // case 34
              default:
                {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private int bitField0_;

      private int tableType_ = 0;
      /**
       *
       *
       * <pre>
       * Optional. Determines whether to  publish discovered tables as BigLake
       * external tables or non-BigLake external tables.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The enum numeric value on the wire for tableType.
       */
      @java.lang.Override
      public int getTableTypeValue() {
        return tableType_;
      }
      /**
       *
       *
       * <pre>
       * Optional. Determines whether to  publish discovered tables as BigLake
       * external tables or non-BigLake external tables.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The enum numeric value on the wire for tableType to set.
       * @return This builder for chaining.
       */
      public Builder setTableTypeValue(int value) {
        tableType_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Determines whether to  publish discovered tables as BigLake
       * external tables or non-BigLake external tables.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The tableType.
       */
      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
          getTableType() {
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType result =
            com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
                .forNumber(tableType_);
        return result == null
            ? com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType
                .UNRECOGNIZED
            : result;
      }
      /**
       *
       *
       * <pre>
       * Optional. Determines whether to  publish discovered tables as BigLake
       * external tables or non-BigLake external tables.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The tableType to set.
       * @return This builder for chaining.
       */
      public Builder setTableType(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        tableType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Determines whether to  publish discovered tables as BigLake
       * external tables or non-BigLake external tables.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.TableType table_type = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearTableType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        tableType_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object connection_ = "";
      /**
       *
       *
       * <pre>
       * Optional. The BigQuery connection used to create BigLake tables.
       * Must be in the form
       * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
       * </pre>
       *
       * <code>
       * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The connection.
       */
      public java.lang.String getConnection() {
        java.lang.Object ref = connection_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          connection_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The BigQuery connection used to create BigLake tables.
       * Must be in the form
       * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
       * </pre>
       *
       * <code>
       * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return The bytes for connection.
       */
      public com.google.protobuf.ByteString getConnectionBytes() {
        java.lang.Object ref = connection_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          connection_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The BigQuery connection used to create BigLake tables.
       * Must be in the form
       * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
       * </pre>
       *
       * <code>
       * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param value The connection to set.
       * @return This builder for chaining.
       */
      public Builder setConnection(java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        connection_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The BigQuery connection used to create BigLake tables.
       * Must be in the form
       * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
       * </pre>
       *
       * <code>
       * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearConnection() {
        connection_ = getDefaultInstance().getConnection();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The BigQuery connection used to create BigLake tables.
       * Must be in the form
       * `projects/{project_id}/locations/{location_id}/connections/{connection_id}`
       * </pre>
       *
       * <code>
       * string connection = 3 [(.google.api.field_behavior) = OPTIONAL, (.google.api.resource_reference) = { ... }
       * </code>
       *
       * @param value The bytes for connection to set.
       * @return This builder for chaining.
       */
      public Builder setConnectionBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
          throw new NullPointerException();
        }
        checkByteStringIsUtf8(value);
        connection_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private java.lang.Object location_ = "";
      /**
       *
       *
       * <pre>
       * Optional. The location of the BigQuery dataset to publish BigLake
       * external or non-BigLake external tables to.
       * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
       * BigQuery dataset can be in the same multi-region bucket or any single
       * region that is included in the same multi-region bucket. The datascan can
       * be created in any single region that is included in the same multi-region
       * bucket
       * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
       * BigQuery dataset can be located in regions that are included in the
       * dual-region bucket, or in a multi-region that includes the dual-region.
       * The datascan can be created in any single region that is included in the
       * same dual-region bucket.
       * 3. If the Cloud Storage bucket is located in a single region, then
       * BigQuery dataset can be in the same single region or any multi-region
       * bucket that includes the same single region. The datascan will be created
       * in the same single region as the bucket.
       * 4. If the BigQuery dataset is in single region, it must be in the same
       * single region as the datascan.
       *
       * For supported values, refer to
       * https://cloud.google.com/bigquery/docs/locations#supported_locations.
       * </pre>
       *
       * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The location.
       */
      public java.lang.String getLocation() {
        java.lang.Object ref = location_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          location_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The location of the BigQuery dataset to publish BigLake
       * external or non-BigLake external tables to.
       * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
       * BigQuery dataset can be in the same multi-region bucket or any single
       * region that is included in the same multi-region bucket. The datascan can
       * be created in any single region that is included in the same multi-region
       * bucket
       * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
       * BigQuery dataset can be located in regions that are included in the
       * dual-region bucket, or in a multi-region that includes the dual-region.
       * The datascan can be created in any single region that is included in the
       * same dual-region bucket.
       * 3. If the Cloud Storage bucket is located in a single region, then
       * BigQuery dataset can be in the same single region or any multi-region
       * bucket that includes the same single region. The datascan will be created
       * in the same single region as the bucket.
       * 4. If the BigQuery dataset is in single region, it must be in the same
       * single region as the datascan.
       *
       * For supported values, refer to
       * https://cloud.google.com/bigquery/docs/locations#supported_locations.
       * </pre>
       *
       * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for location.
       */
      public com.google.protobuf.ByteString getLocationBytes() {
        java.lang.Object ref = location_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          location_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The location of the BigQuery dataset to publish BigLake
       * external or non-BigLake external tables to.
       * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
       * BigQuery dataset can be in the same multi-region bucket or any single
       * region that is included in the same multi-region bucket. The datascan can
       * be created in any single region that is included in the same multi-region
       * bucket
       * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
       * BigQuery dataset can be located in regions that are included in the
       * dual-region bucket, or in a multi-region that includes the dual-region.
       * The datascan can be created in any single region that is included in the
       * same dual-region bucket.
       * 3. If the Cloud Storage bucket is located in a single region, then
       * BigQuery dataset can be in the same single region or any multi-region
       * bucket that includes the same single region. The datascan will be created
       * in the same single region as the bucket.
       * 4. If the BigQuery dataset is in single region, it must be in the same
       * single region as the datascan.
       *
       * For supported values, refer to
       * https://cloud.google.com/bigquery/docs/locations#supported_locations.
       * </pre>
       *
       * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @param value The location to set.
       * @return This builder for chaining.
       */
      public Builder setLocation(java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        location_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The location of the BigQuery dataset to publish BigLake
       * external or non-BigLake external tables to.
       * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
       * BigQuery dataset can be in the same multi-region bucket or any single
       * region that is included in the same multi-region bucket. The datascan can
       * be created in any single region that is included in the same multi-region
       * bucket
       * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
       * BigQuery dataset can be located in regions that are included in the
       * dual-region bucket, or in a multi-region that includes the dual-region.
       * The datascan can be created in any single region that is included in the
       * same dual-region bucket.
       * 3. If the Cloud Storage bucket is located in a single region, then
       * BigQuery dataset can be in the same single region or any multi-region
       * bucket that includes the same single region. The datascan will be created
       * in the same single region as the bucket.
       * 4. If the BigQuery dataset is in single region, it must be in the same
       * single region as the datascan.
       *
       * For supported values, refer to
       * https://cloud.google.com/bigquery/docs/locations#supported_locations.
       * </pre>
       *
       * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return This builder for chaining.
       */
      public Builder clearLocation() {
        location_ = getDefaultInstance().getLocation();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. The location of the BigQuery dataset to publish BigLake
       * external or non-BigLake external tables to.
       * 1. If the Cloud Storage bucket is located in a multi-region bucket, then
       * BigQuery dataset can be in the same multi-region bucket or any single
       * region that is included in the same multi-region bucket. The datascan can
       * be created in any single region that is included in the same multi-region
       * bucket
       * 2. If the Cloud Storage bucket is located in a dual-region bucket, then
       * BigQuery dataset can be located in regions that are included in the
       * dual-region bucket, or in a multi-region that includes the dual-region.
       * The datascan can be created in any single region that is included in the
       * same dual-region bucket.
       * 3. If the Cloud Storage bucket is located in a single region, then
       * BigQuery dataset can be in the same single region or any multi-region
       * bucket that includes the same single region. The datascan will be created
       * in the same single region as the bucket.
       * 4. If the BigQuery dataset is in single region, it must be in the same
       * single region as the datascan.
       *
       * For supported values, refer to
       * https://cloud.google.com/bigquery/docs/locations#supported_locations.
       * </pre>
       *
       * <code>string location = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @param value The bytes for location to set.
       * @return This builder for chaining.
       */
      public Builder setLocationBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
          throw new NullPointerException();
        }
        checkByteStringIsUtf8(value);
        location_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }

      // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig)
    private static final com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
        DEFAULT_INSTANCE;

    static {
      DEFAULT_INSTANCE =
          new com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig();
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
        getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<BigQueryPublishingConfig> PARSER =
        new com.google.protobuf.AbstractParser<BigQueryPublishingConfig>() {
          @java.lang.Override
          public BigQueryPublishingConfig parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
            Builder builder = newBuilder();
            try {
              builder.mergeFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              throw e.setUnfinishedMessage(builder.buildPartial());
            } catch (com.google.protobuf.UninitializedMessageException e) {
              throw e.asInvalidProtocolBufferException()
                  .setUnfinishedMessage(builder.buildPartial());
            } catch (java.io.IOException e) {
              throw new com.google.protobuf.InvalidProtocolBufferException(e)
                  .setUnfinishedMessage(builder.buildPartial());
            }
            return builder.buildPartial();
          }
        };

    public static com.google.protobuf.Parser<BigQueryPublishingConfig> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<BigQueryPublishingConfig> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
        getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }
  }

  public interface StorageConfigOrBuilder
      extends
      // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return A list containing the includePatterns.
     */
    java.util.List<java.lang.String> getIncludePatternsList();
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The count of includePatterns.
     */
    int getIncludePatternsCount();
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the element to return.
     * @return The includePatterns at the given index.
     */
    java.lang.String getIncludePatterns(int index);
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the value to return.
     * @return The bytes of the includePatterns at the given index.
     */
    com.google.protobuf.ByteString getIncludePatternsBytes(int index);

    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return A list containing the excludePatterns.
     */
    java.util.List<java.lang.String> getExcludePatternsList();
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The count of excludePatterns.
     */
    int getExcludePatternsCount();
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the element to return.
     * @return The excludePatterns at the given index.
     */
    java.lang.String getExcludePatterns(int index);
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the value to return.
     * @return The bytes of the excludePatterns at the given index.
     */
    com.google.protobuf.ByteString getExcludePatternsBytes(int index);

    /**
     *
     *
     * <pre>
     * Optional. Configuration for CSV data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return Whether the csvOptions field is set.
     */
    boolean hasCsvOptions();
    /**
     *
     *
     * <pre>
     * Optional. Configuration for CSV data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The csvOptions.
     */
    com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions getCsvOptions();
    /**
     *
     *
     * <pre>
     * Optional. Configuration for CSV data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptionsOrBuilder
        getCsvOptionsOrBuilder();

    /**
     *
     *
     * <pre>
     * Optional. Configuration for JSON data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return Whether the jsonOptions field is set.
     */
    boolean hasJsonOptions();
    /**
     *
     *
     * <pre>
     * Optional. Configuration for JSON data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The jsonOptions.
     */
    com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions getJsonOptions();
    /**
     *
     *
     * <pre>
     * Optional. Configuration for JSON data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptionsOrBuilder
        getJsonOptionsOrBuilder();
  }
  /**
   *
   *
   * <pre>
   * Configurations related to Cloud Storage as the data source.
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig}
   */
  public static final class StorageConfig extends com.google.protobuf.GeneratedMessageV3
      implements
      // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig)
      StorageConfigOrBuilder {
    private static final long serialVersionUID = 0L;
    // Use StorageConfig.newBuilder() to construct.
    private StorageConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }

    private StorageConfig() {
      includePatterns_ = com.google.protobuf.LazyStringArrayList.emptyList();
      excludePatterns_ = com.google.protobuf.LazyStringArrayList.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
      return new StorageConfig();
    }

    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.DataDiscoveryProto
          .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataplex.v1.DataDiscoveryProto
          .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.class,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.Builder.class);
    }

    public interface CsvOptionsOrBuilder
        extends
        // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions)
        com.google.protobuf.MessageOrBuilder {

      /**
       *
       *
       * <pre>
       * Optional. The number of rows to interpret as header rows that should be
       * skipped when reading data rows.
       * </pre>
       *
       * <code>int32 header_rows = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The headerRows.
       */
      int getHeaderRows();

      /**
       *
       *
       * <pre>
       * Optional. The delimiter that is used to separate values. The default is
       * `,` (comma).
       * </pre>
       *
       * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The delimiter.
       */
      java.lang.String getDelimiter();
      /**
       *
       *
       * <pre>
       * Optional. The delimiter that is used to separate values. The default is
       * `,` (comma).
       * </pre>
       *
       * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for delimiter.
       */
      com.google.protobuf.ByteString getDelimiterBytes();

      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The encoding.
       */
      java.lang.String getEncoding();
      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for encoding.
       */
      com.google.protobuf.ByteString getEncodingBytes();

      /**
       *
       *
       * <pre>
       * Optional. Whether to disable the inference of data types for CSV data.
       * If true, all columns are registered as strings.
       * </pre>
       *
       * <code>bool type_inference_disabled = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The typeInferenceDisabled.
       */
      boolean getTypeInferenceDisabled();

      /**
       *
       *
       * <pre>
       * Optional. The character used to quote column values. Accepts `"`
       * (double quotation mark) or `'` (single quotation mark). If unspecified,
       * defaults to `"` (double quotation mark).
       * </pre>
       *
       * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The quote.
       */
      java.lang.String getQuote();
      /**
       *
       *
       * <pre>
       * Optional. The character used to quote column values. Accepts `"`
       * (double quotation mark) or `'` (single quotation mark). If unspecified,
       * defaults to `"` (double quotation mark).
       * </pre>
       *
       * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for quote.
       */
      com.google.protobuf.ByteString getQuoteBytes();
    }
    /**
     *
     *
     * <pre>
     * Describes CSV and similar semi-structured data formats.
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions}
     */
    public static final class CsvOptions extends com.google.protobuf.GeneratedMessageV3
        implements
        // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions)
        CsvOptionsOrBuilder {
      private static final long serialVersionUID = 0L;
      // Use CsvOptions.newBuilder() to construct.
      private CsvOptions(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }

      private CsvOptions() {
        delimiter_ = "";
        encoding_ = "";
        quote_ = "";
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
        return new CsvOptions();
      }

      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_CsvOptions_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_CsvOptions_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.class,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.Builder
                    .class);
      }

      public static final int HEADER_ROWS_FIELD_NUMBER = 1;
      private int headerRows_ = 0;
      /**
       *
       *
       * <pre>
       * Optional. The number of rows to interpret as header rows that should be
       * skipped when reading data rows.
       * </pre>
       *
       * <code>int32 header_rows = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The headerRows.
       */
      @java.lang.Override
      public int getHeaderRows() {
        return headerRows_;
      }

      public static final int DELIMITER_FIELD_NUMBER = 2;

      @SuppressWarnings("serial")
      private volatile java.lang.Object delimiter_ = "";
      /**
       *
       *
       * <pre>
       * Optional. The delimiter that is used to separate values. The default is
       * `,` (comma).
       * </pre>
       *
       * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The delimiter.
       */
      @java.lang.Override
      public java.lang.String getDelimiter() {
        java.lang.Object ref = delimiter_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          delimiter_ = s;
          return s;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The delimiter that is used to separate values. The default is
       * `,` (comma).
       * </pre>
       *
       * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for delimiter.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getDelimiterBytes() {
        java.lang.Object ref = delimiter_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          delimiter_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int ENCODING_FIELD_NUMBER = 3;

      @SuppressWarnings("serial")
      private volatile java.lang.Object encoding_ = "";
      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The encoding.
       */
      @java.lang.Override
      public java.lang.String getEncoding() {
        java.lang.Object ref = encoding_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          encoding_ = s;
          return s;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for encoding.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getEncodingBytes() {
        java.lang.Object ref = encoding_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          encoding_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int TYPE_INFERENCE_DISABLED_FIELD_NUMBER = 4;
      private boolean typeInferenceDisabled_ = false;
      /**
       *
       *
       * <pre>
       * Optional. Whether to disable the inference of data types for CSV data.
       * If true, all columns are registered as strings.
       * </pre>
       *
       * <code>bool type_inference_disabled = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The typeInferenceDisabled.
       */
      @java.lang.Override
      public boolean getTypeInferenceDisabled() {
        return typeInferenceDisabled_;
      }

      public static final int QUOTE_FIELD_NUMBER = 5;

      @SuppressWarnings("serial")
      private volatile java.lang.Object quote_ = "";
      /**
       *
       *
       * <pre>
       * Optional. The character used to quote column values. Accepts `"`
       * (double quotation mark) or `'` (single quotation mark). If unspecified,
       * defaults to `"` (double quotation mark).
       * </pre>
       *
       * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The quote.
       */
      @java.lang.Override
      public java.lang.String getQuote() {
        java.lang.Object ref = quote_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          quote_ = s;
          return s;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The character used to quote column values. Accepts `"`
       * (double quotation mark) or `'` (single quotation mark). If unspecified,
       * defaults to `"` (double quotation mark).
       * </pre>
       *
       * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for quote.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getQuoteBytes() {
        java.lang.Object ref = quote_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          quote_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      private byte memoizedIsInitialized = -1;

      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
        if (headerRows_ != 0) {
          output.writeInt32(1, headerRows_);
        }
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(delimiter_)) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 2, delimiter_);
        }
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(encoding_)) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 3, encoding_);
        }
        if (typeInferenceDisabled_ != false) {
          output.writeBool(4, typeInferenceDisabled_);
        }
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(quote_)) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 5, quote_);
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (headerRows_ != 0) {
          size += com.google.protobuf.CodedOutputStream.computeInt32Size(1, headerRows_);
        }
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(delimiter_)) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, delimiter_);
        }
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(encoding_)) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, encoding_);
        }
        if (typeInferenceDisabled_ != false) {
          size += com.google.protobuf.CodedOutputStream.computeBoolSize(4, typeInferenceDisabled_);
        }
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(quote_)) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, quote_);
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
          return true;
        }
        if (!(obj
            instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions)) {
          return super.equals(obj);
        }
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions other =
            (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions) obj;

        if (getHeaderRows() != other.getHeaderRows()) return false;
        if (!getDelimiter().equals(other.getDelimiter())) return false;
        if (!getEncoding().equals(other.getEncoding())) return false;
        if (getTypeInferenceDisabled() != other.getTypeInferenceDisabled()) return false;
        if (!getQuote().equals(other.getQuote())) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + HEADER_ROWS_FIELD_NUMBER;
        hash = (53 * hash) + getHeaderRows();
        hash = (37 * hash) + DELIMITER_FIELD_NUMBER;
        hash = (53 * hash) + getDelimiter().hashCode();
        hash = (37 * hash) + ENCODING_FIELD_NUMBER;
        hash = (53 * hash) + getEncoding().hashCode();
        hash = (37 * hash) + TYPE_INFERENCE_DISABLED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(getTypeInferenceDisabled());
        hash = (37 * hash) + QUOTE_FIELD_NUMBER;
        hash = (53 * hash) + getQuote().hashCode();
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(java.nio.ByteBuffer data)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(
              java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(com.google.protobuf.ByteString data)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(
              com.google.protobuf.ByteString data,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(java.io.InputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(
              java.io.InputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
            PARSER, input, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseDelimitedFrom(
              java.io.InputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
            PARSER, input, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          parseFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
            PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() {
        return newBuilder();
      }

      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }

      public static Builder newBuilder(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }

      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       *
       *
       * <pre>
       * Describes CSV and similar semi-structured data formats.
       * </pre>
       *
       * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions}
       */
      public static final class Builder
          extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
          implements
          // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions)
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptionsOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
          return com.google.cloud.dataplex.v1.DataDiscoveryProto
              .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_CsvOptions_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return com.google.cloud.dataplex.v1.DataDiscoveryProto
              .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_CsvOptions_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.class,
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.Builder
                      .class);
        }

        // Construct using
        // com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.newBuilder()
        private Builder() {}

        private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
        }

        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          headerRows_ = 0;
          delimiter_ = "";
          encoding_ = "";
          typeInferenceDisabled_ = false;
          quote_ = "";
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
          return com.google.cloud.dataplex.v1.DataDiscoveryProto
              .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_CsvOptions_descriptor;
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
            getDefaultInstanceForType() {
          return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
              .getDefaultInstance();
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions build() {
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions result =
              buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
            buildPartial() {
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions result =
              new com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions(this);
          if (bitField0_ != 0) {
            buildPartial0(result);
          }
          onBuilt();
          return result;
        }

        private void buildPartial0(
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions result) {
          int from_bitField0_ = bitField0_;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.headerRows_ = headerRows_;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.delimiter_ = delimiter_;
          }
          if (((from_bitField0_ & 0x00000004) != 0)) {
            result.encoding_ = encoding_;
          }
          if (((from_bitField0_ & 0x00000008) != 0)) {
            result.typeInferenceDisabled_ = typeInferenceDisabled_;
          }
          if (((from_bitField0_ & 0x00000010) != 0)) {
            result.quote_ = quote_;
          }
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }

        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
          return super.setField(field, value);
        }

        @java.lang.Override
        public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }

        @java.lang.Override
        public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }

        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index,
            java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }

        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }

        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other
              instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions) {
            return mergeFrom(
                (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions) other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions other) {
          if (other
              == com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
                  .getDefaultInstance()) return this;
          if (other.getHeaderRows() != 0) {
            setHeaderRows(other.getHeaderRows());
          }
          if (!other.getDelimiter().isEmpty()) {
            delimiter_ = other.delimiter_;
            bitField0_ |= 0x00000002;
            onChanged();
          }
          if (!other.getEncoding().isEmpty()) {
            encoding_ = other.encoding_;
            bitField0_ |= 0x00000004;
            onChanged();
          }
          if (other.getTypeInferenceDisabled() != false) {
            setTypeInferenceDisabled(other.getTypeInferenceDisabled());
          }
          if (!other.getQuote().isEmpty()) {
            quote_ = other.quote_;
            bitField0_ |= 0x00000010;
            onChanged();
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 8:
                  {
                    headerRows_ = input.readInt32();
                    bitField0_ |= 0x00000001;
                    break;
                  } // case 8
                case 18:
                  {
                    delimiter_ = input.readStringRequireUtf8();
                    bitField0_ |= 0x00000002;
                    break;
                  } // case 18
                case 26:
                  {
                    encoding_ = input.readStringRequireUtf8();
                    bitField0_ |= 0x00000004;
                    break;
                  } // case 26
                case 32:
                  {
                    typeInferenceDisabled_ = input.readBool();
                    bitField0_ |= 0x00000008;
                    break;
                  } // case 32
                case 42:
                  {
                    quote_ = input.readStringRequireUtf8();
                    bitField0_ |= 0x00000010;
                    break;
                  } // case 42
                default:
                  {
                    if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                      done = true; // was an endgroup tag
                    }
                    break;
                  } // default:
              } // switch (tag)
            } // while (!done)
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }

        private int bitField0_;

        private int headerRows_;
        /**
         *
         *
         * <pre>
         * Optional. The number of rows to interpret as header rows that should be
         * skipped when reading data rows.
         * </pre>
         *
         * <code>int32 header_rows = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The headerRows.
         */
        @java.lang.Override
        public int getHeaderRows() {
          return headerRows_;
        }
        /**
         *
         *
         * <pre>
         * Optional. The number of rows to interpret as header rows that should be
         * skipped when reading data rows.
         * </pre>
         *
         * <code>int32 header_rows = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The headerRows to set.
         * @return This builder for chaining.
         */
        public Builder setHeaderRows(int value) {

          headerRows_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The number of rows to interpret as header rows that should be
         * skipped when reading data rows.
         * </pre>
         *
         * <code>int32 header_rows = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return This builder for chaining.
         */
        public Builder clearHeaderRows() {
          bitField0_ = (bitField0_ & ~0x00000001);
          headerRows_ = 0;
          onChanged();
          return this;
        }

        private java.lang.Object delimiter_ = "";
        /**
         *
         *
         * <pre>
         * Optional. The delimiter that is used to separate values. The default is
         * `,` (comma).
         * </pre>
         *
         * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The delimiter.
         */
        public java.lang.String getDelimiter() {
          java.lang.Object ref = delimiter_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            delimiter_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The delimiter that is used to separate values. The default is
         * `,` (comma).
         * </pre>
         *
         * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The bytes for delimiter.
         */
        public com.google.protobuf.ByteString getDelimiterBytes() {
          java.lang.Object ref = delimiter_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
            delimiter_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The delimiter that is used to separate values. The default is
         * `,` (comma).
         * </pre>
         *
         * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The delimiter to set.
         * @return This builder for chaining.
         */
        public Builder setDelimiter(java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          delimiter_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The delimiter that is used to separate values. The default is
         * `,` (comma).
         * </pre>
         *
         * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return This builder for chaining.
         */
        public Builder clearDelimiter() {
          delimiter_ = getDefaultInstance().getDelimiter();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The delimiter that is used to separate values. The default is
         * `,` (comma).
         * </pre>
         *
         * <code>string delimiter = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The bytes for delimiter to set.
         * @return This builder for chaining.
         */
        public Builder setDelimiterBytes(com.google.protobuf.ByteString value) {
          if (value == null) {
            throw new NullPointerException();
          }
          checkByteStringIsUtf8(value);
          delimiter_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }

        private java.lang.Object encoding_ = "";
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The encoding.
         */
        public java.lang.String getEncoding() {
          java.lang.Object ref = encoding_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            encoding_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The bytes for encoding.
         */
        public com.google.protobuf.ByteString getEncodingBytes() {
          java.lang.Object ref = encoding_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
            encoding_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The encoding to set.
         * @return This builder for chaining.
         */
        public Builder setEncoding(java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          encoding_ = value;
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return This builder for chaining.
         */
        public Builder clearEncoding() {
          encoding_ = getDefaultInstance().getEncoding();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 3 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The bytes for encoding to set.
         * @return This builder for chaining.
         */
        public Builder setEncodingBytes(com.google.protobuf.ByteString value) {
          if (value == null) {
            throw new NullPointerException();
          }
          checkByteStringIsUtf8(value);
          encoding_ = value;
          bitField0_ |= 0x00000004;
          onChanged();
          return this;
        }

        private boolean typeInferenceDisabled_;
        /**
         *
         *
         * <pre>
         * Optional. Whether to disable the inference of data types for CSV data.
         * If true, all columns are registered as strings.
         * </pre>
         *
         * <code>bool type_inference_disabled = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The typeInferenceDisabled.
         */
        @java.lang.Override
        public boolean getTypeInferenceDisabled() {
          return typeInferenceDisabled_;
        }
        /**
         *
         *
         * <pre>
         * Optional. Whether to disable the inference of data types for CSV data.
         * If true, all columns are registered as strings.
         * </pre>
         *
         * <code>bool type_inference_disabled = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The typeInferenceDisabled to set.
         * @return This builder for chaining.
         */
        public Builder setTypeInferenceDisabled(boolean value) {

          typeInferenceDisabled_ = value;
          bitField0_ |= 0x00000008;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. Whether to disable the inference of data types for CSV data.
         * If true, all columns are registered as strings.
         * </pre>
         *
         * <code>bool type_inference_disabled = 4 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return This builder for chaining.
         */
        public Builder clearTypeInferenceDisabled() {
          bitField0_ = (bitField0_ & ~0x00000008);
          typeInferenceDisabled_ = false;
          onChanged();
          return this;
        }

        private java.lang.Object quote_ = "";
        /**
         *
         *
         * <pre>
         * Optional. The character used to quote column values. Accepts `"`
         * (double quotation mark) or `'` (single quotation mark). If unspecified,
         * defaults to `"` (double quotation mark).
         * </pre>
         *
         * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The quote.
         */
        public java.lang.String getQuote() {
          java.lang.Object ref = quote_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            quote_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The character used to quote column values. Accepts `"`
         * (double quotation mark) or `'` (single quotation mark). If unspecified,
         * defaults to `"` (double quotation mark).
         * </pre>
         *
         * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The bytes for quote.
         */
        public com.google.protobuf.ByteString getQuoteBytes() {
          java.lang.Object ref = quote_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
            quote_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The character used to quote column values. Accepts `"`
         * (double quotation mark) or `'` (single quotation mark). If unspecified,
         * defaults to `"` (double quotation mark).
         * </pre>
         *
         * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The quote to set.
         * @return This builder for chaining.
         */
        public Builder setQuote(java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          quote_ = value;
          bitField0_ |= 0x00000010;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The character used to quote column values. Accepts `"`
         * (double quotation mark) or `'` (single quotation mark). If unspecified,
         * defaults to `"` (double quotation mark).
         * </pre>
         *
         * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return This builder for chaining.
         */
        public Builder clearQuote() {
          quote_ = getDefaultInstance().getQuote();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The character used to quote column values. Accepts `"`
         * (double quotation mark) or `'` (single quotation mark). If unspecified,
         * defaults to `"` (double quotation mark).
         * </pre>
         *
         * <code>string quote = 5 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The bytes for quote to set.
         * @return This builder for chaining.
         */
        public Builder setQuoteBytes(com.google.protobuf.ByteString value) {
          if (value == null) {
            throw new NullPointerException();
          }
          checkByteStringIsUtf8(value);
          quote_ = value;
          bitField0_ |= 0x00000010;
          onChanged();
          return this;
        }

        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }

        // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions)
      }

      // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions)
      private static final com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          DEFAULT_INSTANCE;

      static {
        DEFAULT_INSTANCE =
            new com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions();
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<CsvOptions> PARSER =
          new com.google.protobuf.AbstractParser<CsvOptions>() {
            @java.lang.Override
            public CsvOptions parsePartialFrom(
                com.google.protobuf.CodedInputStream input,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws com.google.protobuf.InvalidProtocolBufferException {
              Builder builder = newBuilder();
              try {
                builder.mergeFrom(input, extensionRegistry);
              } catch (com.google.protobuf.InvalidProtocolBufferException e) {
                throw e.setUnfinishedMessage(builder.buildPartial());
              } catch (com.google.protobuf.UninitializedMessageException e) {
                throw e.asInvalidProtocolBufferException()
                    .setUnfinishedMessage(builder.buildPartial());
              } catch (java.io.IOException e) {
                throw new com.google.protobuf.InvalidProtocolBufferException(e)
                    .setUnfinishedMessage(builder.buildPartial());
              }
              return builder.buildPartial();
            }
          };

      public static com.google.protobuf.Parser<CsvOptions> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<CsvOptions> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }
    }

    public interface JsonOptionsOrBuilder
        extends
        // @@protoc_insertion_point(interface_extends:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions)
        com.google.protobuf.MessageOrBuilder {

      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The encoding.
       */
      java.lang.String getEncoding();
      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for encoding.
       */
      com.google.protobuf.ByteString getEncodingBytes();

      /**
       *
       *
       * <pre>
       * Optional. Whether to disable the inference of data types for JSON data.
       * If true, all columns are registered as their primitive types
       * (strings, number, or boolean).
       * </pre>
       *
       * <code>bool type_inference_disabled = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The typeInferenceDisabled.
       */
      boolean getTypeInferenceDisabled();
    }
    /**
     *
     *
     * <pre>
     * Describes JSON data format.
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions}
     */
    public static final class JsonOptions extends com.google.protobuf.GeneratedMessageV3
        implements
        // @@protoc_insertion_point(message_implements:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions)
        JsonOptionsOrBuilder {
      private static final long serialVersionUID = 0L;
      // Use JsonOptions.newBuilder() to construct.
      private JsonOptions(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }

      private JsonOptions() {
        encoding_ = "";
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(UnusedPrivateParameter unused) {
        return new JsonOptions();
      }

      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_JsonOptions_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_JsonOptions_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.class,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.Builder
                    .class);
      }

      public static final int ENCODING_FIELD_NUMBER = 1;

      @SuppressWarnings("serial")
      private volatile java.lang.Object encoding_ = "";
      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The encoding.
       */
      @java.lang.Override
      public java.lang.String getEncoding() {
        java.lang.Object ref = encoding_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          encoding_ = s;
          return s;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. The character encoding of the data. The default is UTF-8.
       * </pre>
       *
       * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The bytes for encoding.
       */
      @java.lang.Override
      public com.google.protobuf.ByteString getEncodingBytes() {
        java.lang.Object ref = encoding_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
          encoding_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int TYPE_INFERENCE_DISABLED_FIELD_NUMBER = 2;
      private boolean typeInferenceDisabled_ = false;
      /**
       *
       *
       * <pre>
       * Optional. Whether to disable the inference of data types for JSON data.
       * If true, all columns are registered as their primitive types
       * (strings, number, or boolean).
       * </pre>
       *
       * <code>bool type_inference_disabled = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
       *
       * @return The typeInferenceDisabled.
       */
      @java.lang.Override
      public boolean getTypeInferenceDisabled() {
        return typeInferenceDisabled_;
      }

      private byte memoizedIsInitialized = -1;

      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(encoding_)) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, encoding_);
        }
        if (typeInferenceDisabled_ != false) {
          output.writeBool(2, typeInferenceDisabled_);
        }
        getUnknownFields().writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(encoding_)) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, encoding_);
        }
        if (typeInferenceDisabled_ != false) {
          size += com.google.protobuf.CodedOutputStream.computeBoolSize(2, typeInferenceDisabled_);
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
          return true;
        }
        if (!(obj
            instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions)) {
          return super.equals(obj);
        }
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions other =
            (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions) obj;

        if (!getEncoding().equals(other.getEncoding())) return false;
        if (getTypeInferenceDisabled() != other.getTypeInferenceDisabled()) return false;
        if (!getUnknownFields().equals(other.getUnknownFields())) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + ENCODING_FIELD_NUMBER;
        hash = (53 * hash) + getEncoding().hashCode();
        hash = (37 * hash) + TYPE_INFERENCE_DISABLED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(getTypeInferenceDisabled());
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(java.nio.ByteBuffer data)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(
              java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(com.google.protobuf.ByteString data)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(
              com.google.protobuf.ByteString data,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(byte[] data) throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(java.io.InputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(
              java.io.InputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
            PARSER, input, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseDelimitedFrom(java.io.InputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseDelimitedFrom(
              java.io.InputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
            PARSER, input, extensionRegistry);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(com.google.protobuf.CodedInputStream input) throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          parseFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
            PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() {
        return newBuilder();
      }

      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }

      public static Builder newBuilder(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }

      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       *
       *
       * <pre>
       * Describes JSON data format.
       * </pre>
       *
       * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions}
       */
      public static final class Builder
          extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
          implements
          // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions)
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptionsOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
          return com.google.cloud.dataplex.v1.DataDiscoveryProto
              .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_JsonOptions_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return com.google.cloud.dataplex.v1.DataDiscoveryProto
              .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_JsonOptions_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.class,
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.Builder
                      .class);
        }

        // Construct using
        // com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.newBuilder()
        private Builder() {}

        private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
        }

        @java.lang.Override
        public Builder clear() {
          super.clear();
          bitField0_ = 0;
          encoding_ = "";
          typeInferenceDisabled_ = false;
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
          return com.google.cloud.dataplex.v1.DataDiscoveryProto
              .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_JsonOptions_descriptor;
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
            getDefaultInstanceForType() {
          return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
              .getDefaultInstance();
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions build() {
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions result =
              buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
            buildPartial() {
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions result =
              new com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions(this);
          if (bitField0_ != 0) {
            buildPartial0(result);
          }
          onBuilt();
          return result;
        }

        private void buildPartial0(
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions result) {
          int from_bitField0_ = bitField0_;
          if (((from_bitField0_ & 0x00000001) != 0)) {
            result.encoding_ = encoding_;
          }
          if (((from_bitField0_ & 0x00000002) != 0)) {
            result.typeInferenceDisabled_ = typeInferenceDisabled_;
          }
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }

        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
          return super.setField(field, value);
        }

        @java.lang.Override
        public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }

        @java.lang.Override
        public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }

        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index,
            java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }

        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }

        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other
              instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions) {
            return mergeFrom(
                (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions) other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions other) {
          if (other
              == com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
                  .getDefaultInstance()) return this;
          if (!other.getEncoding().isEmpty()) {
            encoding_ = other.encoding_;
            bitField0_ |= 0x00000001;
            onChanged();
          }
          if (other.getTypeInferenceDisabled() != false) {
            setTypeInferenceDisabled(other.getTypeInferenceDisabled());
          }
          this.mergeUnknownFields(other.getUnknownFields());
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          if (extensionRegistry == null) {
            throw new java.lang.NullPointerException();
          }
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                case 10:
                  {
                    encoding_ = input.readStringRequireUtf8();
                    bitField0_ |= 0x00000001;
                    break;
                  } // case 10
                case 16:
                  {
                    typeInferenceDisabled_ = input.readBool();
                    bitField0_ |= 0x00000002;
                    break;
                  } // case 16
                default:
                  {
                    if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                      done = true; // was an endgroup tag
                    }
                    break;
                  } // default:
              } // switch (tag)
            } // while (!done)
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.unwrapIOException();
          } finally {
            onChanged();
          } // finally
          return this;
        }

        private int bitField0_;

        private java.lang.Object encoding_ = "";
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The encoding.
         */
        public java.lang.String getEncoding() {
          java.lang.Object ref = encoding_;
          if (!(ref instanceof java.lang.String)) {
            com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
            java.lang.String s = bs.toStringUtf8();
            encoding_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The bytes for encoding.
         */
        public com.google.protobuf.ByteString getEncodingBytes() {
          java.lang.Object ref = encoding_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
            encoding_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The encoding to set.
         * @return This builder for chaining.
         */
        public Builder setEncoding(java.lang.String value) {
          if (value == null) {
            throw new NullPointerException();
          }
          encoding_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return This builder for chaining.
         */
        public Builder clearEncoding() {
          encoding_ = getDefaultInstance().getEncoding();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. The character encoding of the data. The default is UTF-8.
         * </pre>
         *
         * <code>string encoding = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The bytes for encoding to set.
         * @return This builder for chaining.
         */
        public Builder setEncodingBytes(com.google.protobuf.ByteString value) {
          if (value == null) {
            throw new NullPointerException();
          }
          checkByteStringIsUtf8(value);
          encoding_ = value;
          bitField0_ |= 0x00000001;
          onChanged();
          return this;
        }

        private boolean typeInferenceDisabled_;
        /**
         *
         *
         * <pre>
         * Optional. Whether to disable the inference of data types for JSON data.
         * If true, all columns are registered as their primitive types
         * (strings, number, or boolean).
         * </pre>
         *
         * <code>bool type_inference_disabled = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return The typeInferenceDisabled.
         */
        @java.lang.Override
        public boolean getTypeInferenceDisabled() {
          return typeInferenceDisabled_;
        }
        /**
         *
         *
         * <pre>
         * Optional. Whether to disable the inference of data types for JSON data.
         * If true, all columns are registered as their primitive types
         * (strings, number, or boolean).
         * </pre>
         *
         * <code>bool type_inference_disabled = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @param value The typeInferenceDisabled to set.
         * @return This builder for chaining.
         */
        public Builder setTypeInferenceDisabled(boolean value) {

          typeInferenceDisabled_ = value;
          bitField0_ |= 0x00000002;
          onChanged();
          return this;
        }
        /**
         *
         *
         * <pre>
         * Optional. Whether to disable the inference of data types for JSON data.
         * If true, all columns are registered as their primitive types
         * (strings, number, or boolean).
         * </pre>
         *
         * <code>bool type_inference_disabled = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
         *
         * @return This builder for chaining.
         */
        public Builder clearTypeInferenceDisabled() {
          bitField0_ = (bitField0_ & ~0x00000002);
          typeInferenceDisabled_ = false;
          onChanged();
          return this;
        }

        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }

        // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions)
      }

      // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions)
      private static final com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          DEFAULT_INSTANCE;

      static {
        DEFAULT_INSTANCE =
            new com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions();
      }

      public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<JsonOptions> PARSER =
          new com.google.protobuf.AbstractParser<JsonOptions>() {
            @java.lang.Override
            public JsonOptions parsePartialFrom(
                com.google.protobuf.CodedInputStream input,
                com.google.protobuf.ExtensionRegistryLite extensionRegistry)
                throws com.google.protobuf.InvalidProtocolBufferException {
              Builder builder = newBuilder();
              try {
                builder.mergeFrom(input, extensionRegistry);
              } catch (com.google.protobuf.InvalidProtocolBufferException e) {
                throw e.setUnfinishedMessage(builder.buildPartial());
              } catch (com.google.protobuf.UninitializedMessageException e) {
                throw e.asInvalidProtocolBufferException()
                    .setUnfinishedMessage(builder.buildPartial());
              } catch (java.io.IOException e) {
                throw new com.google.protobuf.InvalidProtocolBufferException(e)
                    .setUnfinishedMessage(builder.buildPartial());
              }
              return builder.buildPartial();
            }
          };

      public static com.google.protobuf.Parser<JsonOptions> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<JsonOptions> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }
    }

    private int bitField0_;
    public static final int INCLUDE_PATTERNS_FIELD_NUMBER = 1;

    @SuppressWarnings("serial")
    private com.google.protobuf.LazyStringArrayList includePatterns_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return A list containing the includePatterns.
     */
    public com.google.protobuf.ProtocolStringList getIncludePatternsList() {
      return includePatterns_;
    }
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The count of includePatterns.
     */
    public int getIncludePatternsCount() {
      return includePatterns_.size();
    }
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the element to return.
     * @return The includePatterns at the given index.
     */
    public java.lang.String getIncludePatterns(int index) {
      return includePatterns_.get(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to include during discovery when only a subset
     * of the data should be considered. Provide a list of patterns that
     * identify the data to include. For Cloud Storage bucket assets, these
     * patterns are interpreted as glob patterns used to match object names. For
     * BigQuery dataset assets, these patterns are interpreted as patterns to
     * match table names.
     * </pre>
     *
     * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the value to return.
     * @return The bytes of the includePatterns at the given index.
     */
    public com.google.protobuf.ByteString getIncludePatternsBytes(int index) {
      return includePatterns_.getByteString(index);
    }

    public static final int EXCLUDE_PATTERNS_FIELD_NUMBER = 2;

    @SuppressWarnings("serial")
    private com.google.protobuf.LazyStringArrayList excludePatterns_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return A list containing the excludePatterns.
     */
    public com.google.protobuf.ProtocolStringList getExcludePatternsList() {
      return excludePatterns_;
    }
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @return The count of excludePatterns.
     */
    public int getExcludePatternsCount() {
      return excludePatterns_.size();
    }
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the element to return.
     * @return The excludePatterns at the given index.
     */
    public java.lang.String getExcludePatterns(int index) {
      return excludePatterns_.get(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. Defines the data to exclude during discovery. Provide a list of
     * patterns that identify the data to exclude. For Cloud Storage bucket
     * assets, these patterns are interpreted as glob patterns used to match
     * object names. For BigQuery dataset assets, these patterns are interpreted
     * as patterns to match table names.
     * </pre>
     *
     * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];</code>
     *
     * @param index The index of the value to return.
     * @return The bytes of the excludePatterns at the given index.
     */
    public com.google.protobuf.ByteString getExcludePatternsBytes(int index) {
      return excludePatterns_.getByteString(index);
    }

    public static final int CSV_OPTIONS_FIELD_NUMBER = 3;
    private com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csvOptions_;
    /**
     *
     *
     * <pre>
     * Optional. Configuration for CSV data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return Whether the csvOptions field is set.
     */
    @java.lang.Override
    public boolean hasCsvOptions() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for CSV data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The csvOptions.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions getCsvOptions() {
      return csvOptions_ == null
          ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
              .getDefaultInstance()
          : csvOptions_;
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for CSV data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptionsOrBuilder
        getCsvOptionsOrBuilder() {
      return csvOptions_ == null
          ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
              .getDefaultInstance()
          : csvOptions_;
    }

    public static final int JSON_OPTIONS_FIELD_NUMBER = 4;
    private com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions jsonOptions_;
    /**
     *
     *
     * <pre>
     * Optional. Configuration for JSON data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return Whether the jsonOptions field is set.
     */
    @java.lang.Override
    public boolean hasJsonOptions() {
      return ((bitField0_ & 0x00000002) != 0);
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for JSON data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The jsonOptions.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
        getJsonOptions() {
      return jsonOptions_ == null
          ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
              .getDefaultInstance()
          : jsonOptions_;
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for JSON data.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptionsOrBuilder
        getJsonOptionsOrBuilder() {
      return jsonOptions_ == null
          ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
              .getDefaultInstance()
          : jsonOptions_;
    }

    private byte memoizedIsInitialized = -1;

    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
      for (int i = 0; i < includePatterns_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, includePatterns_.getRaw(i));
      }
      for (int i = 0; i < excludePatterns_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, excludePatterns_.getRaw(i));
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        output.writeMessage(3, getCsvOptions());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        output.writeMessage(4, getJsonOptions());
      }
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < includePatterns_.size(); i++) {
          dataSize += computeStringSizeNoTag(includePatterns_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getIncludePatternsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < excludePatterns_.size(); i++) {
          dataSize += computeStringSizeNoTag(excludePatterns_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getExcludePatternsList().size();
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        size += com.google.protobuf.CodedOutputStream.computeMessageSize(3, getCsvOptions());
      }
      if (((bitField0_ & 0x00000002) != 0)) {
        size += com.google.protobuf.CodedOutputStream.computeMessageSize(4, getJsonOptions());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
        return true;
      }
      if (!(obj instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig)) {
        return super.equals(obj);
      }
      com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig other =
          (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) obj;

      if (!getIncludePatternsList().equals(other.getIncludePatternsList())) return false;
      if (!getExcludePatternsList().equals(other.getExcludePatternsList())) return false;
      if (hasCsvOptions() != other.hasCsvOptions()) return false;
      if (hasCsvOptions()) {
        if (!getCsvOptions().equals(other.getCsvOptions())) return false;
      }
      if (hasJsonOptions() != other.hasJsonOptions()) return false;
      if (hasJsonOptions()) {
        if (!getJsonOptions().equals(other.getJsonOptions())) return false;
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getIncludePatternsCount() > 0) {
        hash = (37 * hash) + INCLUDE_PATTERNS_FIELD_NUMBER;
        hash = (53 * hash) + getIncludePatternsList().hashCode();
      }
      if (getExcludePatternsCount() > 0) {
        hash = (37 * hash) + EXCLUDE_PATTERNS_FIELD_NUMBER;
        hash = (53 * hash) + getExcludePatternsList().hashCode();
      }
      if (hasCsvOptions()) {
        hash = (37 * hash) + CSV_OPTIONS_FIELD_NUMBER;
        hash = (53 * hash) + getCsvOptions().hashCode();
      }
      if (hasJsonOptions()) {
        hash = (37 * hash) + JSON_OPTIONS_FIELD_NUMBER;
        hash = (53 * hash) + getJsonOptions().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        java.nio.ByteBuffer data) throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        byte[] data) throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseDelimitedFrom(
        java.io.InputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseDelimitedFrom(
        java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
          PARSER, input, extensionRegistry);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        com.google.protobuf.CodedInputStream input) throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
          PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() {
      return newBuilder();
    }

    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }

    public static Builder newBuilder(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }

    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     *
     *
     * <pre>
     * Configurations related to Cloud Storage as the data source.
     * </pre>
     *
     * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig}
     */
    public static final class Builder
        extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
        implements
        // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig)
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.class,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.Builder.class);
      }

      // Construct using com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }

      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {
          getCsvOptionsFieldBuilder();
          getJsonOptionsFieldBuilder();
        }
      }

      @java.lang.Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        includePatterns_ = com.google.protobuf.LazyStringArrayList.emptyList();
        excludePatterns_ = com.google.protobuf.LazyStringArrayList.emptyList();
        csvOptions_ = null;
        if (csvOptionsBuilder_ != null) {
          csvOptionsBuilder_.dispose();
          csvOptionsBuilder_ = null;
        }
        jsonOptions_ = null;
        if (jsonOptionsBuilder_ != null) {
          jsonOptionsBuilder_.dispose();
          jsonOptionsBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
        return com.google.cloud.dataplex.v1.DataDiscoveryProto
            .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_StorageConfig_descriptor;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig
          getDefaultInstanceForType() {
        return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance();
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig build() {
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig buildPartial() {
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig result =
            new com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig(this);
        if (bitField0_ != 0) {
          buildPartial0(result);
        }
        onBuilt();
        return result;
      }

      private void buildPartial0(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          includePatterns_.makeImmutable();
          result.includePatterns_ = includePatterns_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          excludePatterns_.makeImmutable();
          result.excludePatterns_ = excludePatterns_;
        }
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.csvOptions_ =
              csvOptionsBuilder_ == null ? csvOptions_ : csvOptionsBuilder_.build();
          to_bitField0_ |= 0x00000001;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.jsonOptions_ =
              jsonOptionsBuilder_ == null ? jsonOptions_ : jsonOptionsBuilder_.build();
          to_bitField0_ |= 0x00000002;
        }
        result.bitField0_ |= to_bitField0_;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }

      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.setField(field, value);
      }

      @java.lang.Override
      public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }

      @java.lang.Override
      public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }

      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index,
          java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }

      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }

      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) {
          return mergeFrom((com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig other) {
        if (other
            == com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance())
          return this;
        if (!other.includePatterns_.isEmpty()) {
          if (includePatterns_.isEmpty()) {
            includePatterns_ = other.includePatterns_;
            bitField0_ |= 0x00000001;
          } else {
            ensureIncludePatternsIsMutable();
            includePatterns_.addAll(other.includePatterns_);
          }
          onChanged();
        }
        if (!other.excludePatterns_.isEmpty()) {
          if (excludePatterns_.isEmpty()) {
            excludePatterns_ = other.excludePatterns_;
            bitField0_ |= 0x00000002;
          } else {
            ensureExcludePatternsIsMutable();
            excludePatterns_.addAll(other.excludePatterns_);
          }
          onChanged();
        }
        if (other.hasCsvOptions()) {
          mergeCsvOptions(other.getCsvOptions());
        }
        if (other.hasJsonOptions()) {
          mergeJsonOptions(other.getJsonOptions());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10:
                {
                  java.lang.String s = input.readStringRequireUtf8();
                  ensureIncludePatternsIsMutable();
                  includePatterns_.add(s);
                  break;
                } // case 10
              case 18:
                {
                  java.lang.String s = input.readStringRequireUtf8();
                  ensureExcludePatternsIsMutable();
                  excludePatterns_.add(s);
                  break;
                } // case 18
              case 26:
                {
                  input.readMessage(getCsvOptionsFieldBuilder().getBuilder(), extensionRegistry);
                  bitField0_ |= 0x00000004;
                  break;
                } // case 26
              case 34:
                {
                  input.readMessage(getJsonOptionsFieldBuilder().getBuilder(), extensionRegistry);
                  bitField0_ |= 0x00000008;
                  break;
                } // case 34
              default:
                {
                  if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                    done = true; // was an endgroup tag
                  }
                  break;
                } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }

      private int bitField0_;

      private com.google.protobuf.LazyStringArrayList includePatterns_ =
          com.google.protobuf.LazyStringArrayList.emptyList();

      private void ensureIncludePatternsIsMutable() {
        if (!includePatterns_.isModifiable()) {
          includePatterns_ = new com.google.protobuf.LazyStringArrayList(includePatterns_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return A list containing the includePatterns.
       */
      public com.google.protobuf.ProtocolStringList getIncludePatternsList() {
        includePatterns_.makeImmutable();
        return includePatterns_;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The count of includePatterns.
       */
      public int getIncludePatternsCount() {
        return includePatterns_.size();
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param index The index of the element to return.
       * @return The includePatterns at the given index.
       */
      public java.lang.String getIncludePatterns(int index) {
        return includePatterns_.get(index);
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the includePatterns at the given index.
       */
      public com.google.protobuf.ByteString getIncludePatternsBytes(int index) {
        return includePatterns_.getByteString(index);
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param index The index to set the value at.
       * @param value The includePatterns to set.
       * @return This builder for chaining.
       */
      public Builder setIncludePatterns(int index, java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureIncludePatternsIsMutable();
        includePatterns_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The includePatterns to add.
       * @return This builder for chaining.
       */
      public Builder addIncludePatterns(java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureIncludePatternsIsMutable();
        includePatterns_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param values The includePatterns to add.
       * @return This builder for chaining.
       */
      public Builder addAllIncludePatterns(java.lang.Iterable<java.lang.String> values) {
        ensureIncludePatternsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(values, includePatterns_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearIncludePatterns() {
        includePatterns_ = com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        ;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to include during discovery when only a subset
       * of the data should be considered. Provide a list of patterns that
       * identify the data to include. For Cloud Storage bucket assets, these
       * patterns are interpreted as glob patterns used to match object names. For
       * BigQuery dataset assets, these patterns are interpreted as patterns to
       * match table names.
       * </pre>
       *
       * <code>repeated string include_patterns = 1 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The bytes of the includePatterns to add.
       * @return This builder for chaining.
       */
      public Builder addIncludePatternsBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
          throw new NullPointerException();
        }
        checkByteStringIsUtf8(value);
        ensureIncludePatternsIsMutable();
        includePatterns_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringArrayList excludePatterns_ =
          com.google.protobuf.LazyStringArrayList.emptyList();

      private void ensureExcludePatternsIsMutable() {
        if (!excludePatterns_.isModifiable()) {
          excludePatterns_ = new com.google.protobuf.LazyStringArrayList(excludePatterns_);
        }
        bitField0_ |= 0x00000002;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return A list containing the excludePatterns.
       */
      public com.google.protobuf.ProtocolStringList getExcludePatternsList() {
        excludePatterns_.makeImmutable();
        return excludePatterns_;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The count of excludePatterns.
       */
      public int getExcludePatternsCount() {
        return excludePatterns_.size();
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param index The index of the element to return.
       * @return The excludePatterns at the given index.
       */
      public java.lang.String getExcludePatterns(int index) {
        return excludePatterns_.get(index);
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param index The index of the value to return.
       * @return The bytes of the excludePatterns at the given index.
       */
      public com.google.protobuf.ByteString getExcludePatternsBytes(int index) {
        return excludePatterns_.getByteString(index);
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param index The index to set the value at.
       * @param value The excludePatterns to set.
       * @return This builder for chaining.
       */
      public Builder setExcludePatterns(int index, java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureExcludePatternsIsMutable();
        excludePatterns_.set(index, value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The excludePatterns to add.
       * @return This builder for chaining.
       */
      public Builder addExcludePatterns(java.lang.String value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureExcludePatternsIsMutable();
        excludePatterns_.add(value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param values The excludePatterns to add.
       * @return This builder for chaining.
       */
      public Builder addAllExcludePatterns(java.lang.Iterable<java.lang.String> values) {
        ensureExcludePatternsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(values, excludePatterns_);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return This builder for chaining.
       */
      public Builder clearExcludePatterns() {
        excludePatterns_ = com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        ;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Defines the data to exclude during discovery. Provide a list of
       * patterns that identify the data to exclude. For Cloud Storage bucket
       * assets, these patterns are interpreted as glob patterns used to match
       * object names. For BigQuery dataset assets, these patterns are interpreted
       * as patterns to match table names.
       * </pre>
       *
       * <code>repeated string exclude_patterns = 2 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @param value The bytes of the excludePatterns to add.
       * @return This builder for chaining.
       */
      public Builder addExcludePatternsBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
          throw new NullPointerException();
        }
        checkByteStringIsUtf8(value);
        ensureExcludePatternsIsMutable();
        excludePatterns_.add(value);
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }

      private com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csvOptions_;
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.Builder,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptionsOrBuilder>
          csvOptionsBuilder_;
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return Whether the csvOptions field is set.
       */
      public boolean hasCsvOptions() {
        return ((bitField0_ & 0x00000004) != 0);
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The csvOptions.
       */
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
          getCsvOptions() {
        if (csvOptionsBuilder_ == null) {
          return csvOptions_ == null
              ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
                  .getDefaultInstance()
              : csvOptions_;
        } else {
          return csvOptionsBuilder_.getMessage();
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder setCsvOptions(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions value) {
        if (csvOptionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          csvOptions_ = value;
        } else {
          csvOptionsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder setCsvOptions(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.Builder
              builderForValue) {
        if (csvOptionsBuilder_ == null) {
          csvOptions_ = builderForValue.build();
        } else {
          csvOptionsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder mergeCsvOptions(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions value) {
        if (csvOptionsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)
              && csvOptions_ != null
              && csvOptions_
                  != com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
                      .getDefaultInstance()) {
            getCsvOptionsBuilder().mergeFrom(value);
          } else {
            csvOptions_ = value;
          }
        } else {
          csvOptionsBuilder_.mergeFrom(value);
        }
        if (csvOptions_ != null) {
          bitField0_ |= 0x00000004;
          onChanged();
        }
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder clearCsvOptions() {
        bitField0_ = (bitField0_ & ~0x00000004);
        csvOptions_ = null;
        if (csvOptionsBuilder_ != null) {
          csvOptionsBuilder_.dispose();
          csvOptionsBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.Builder
          getCsvOptionsBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getCsvOptionsFieldBuilder().getBuilder();
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptionsOrBuilder
          getCsvOptionsOrBuilder() {
        if (csvOptionsBuilder_ != null) {
          return csvOptionsBuilder_.getMessageOrBuilder();
        } else {
          return csvOptions_ == null
              ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions
                  .getDefaultInstance()
              : csvOptions_;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for CSV data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions csv_options = 3 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.Builder,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptionsOrBuilder>
          getCsvOptionsFieldBuilder() {
        if (csvOptionsBuilder_ == null) {
          csvOptionsBuilder_ =
              new com.google.protobuf.SingleFieldBuilderV3<
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions,
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptions.Builder,
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.CsvOptionsOrBuilder>(
                  getCsvOptions(), getParentForChildren(), isClean());
          csvOptions_ = null;
        }
        return csvOptionsBuilder_;
      }

      private com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions jsonOptions_;
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.Builder,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptionsOrBuilder>
          jsonOptionsBuilder_;
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return Whether the jsonOptions field is set.
       */
      public boolean hasJsonOptions() {
        return ((bitField0_ & 0x00000008) != 0);
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       *
       * @return The jsonOptions.
       */
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
          getJsonOptions() {
        if (jsonOptionsBuilder_ == null) {
          return jsonOptions_ == null
              ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
                  .getDefaultInstance()
              : jsonOptions_;
        } else {
          return jsonOptionsBuilder_.getMessage();
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder setJsonOptions(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions value) {
        if (jsonOptionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          jsonOptions_ = value;
        } else {
          jsonOptionsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder setJsonOptions(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.Builder
              builderForValue) {
        if (jsonOptionsBuilder_ == null) {
          jsonOptions_ = builderForValue.build();
        } else {
          jsonOptionsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder mergeJsonOptions(
          com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions value) {
        if (jsonOptionsBuilder_ == null) {
          if (((bitField0_ & 0x00000008) != 0)
              && jsonOptions_ != null
              && jsonOptions_
                  != com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
                      .getDefaultInstance()) {
            getJsonOptionsBuilder().mergeFrom(value);
          } else {
            jsonOptions_ = value;
          }
        } else {
          jsonOptionsBuilder_.mergeFrom(value);
        }
        if (jsonOptions_ != null) {
          bitField0_ |= 0x00000008;
          onChanged();
        }
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public Builder clearJsonOptions() {
        bitField0_ = (bitField0_ & ~0x00000008);
        jsonOptions_ = null;
        if (jsonOptionsBuilder_ != null) {
          jsonOptionsBuilder_.dispose();
          jsonOptionsBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.Builder
          getJsonOptionsBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getJsonOptionsFieldBuilder().getBuilder();
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptionsOrBuilder
          getJsonOptionsOrBuilder() {
        if (jsonOptionsBuilder_ != null) {
          return jsonOptionsBuilder_.getMessageOrBuilder();
        } else {
          return jsonOptions_ == null
              ? com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions
                  .getDefaultInstance()
              : jsonOptions_;
        }
      }
      /**
       *
       *
       * <pre>
       * Optional. Configuration for JSON data.
       * </pre>
       *
       * <code>
       * .google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions json_options = 4 [(.google.api.field_behavior) = OPTIONAL];
       * </code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.Builder,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptionsOrBuilder>
          getJsonOptionsFieldBuilder() {
        if (jsonOptionsBuilder_ == null) {
          jsonOptionsBuilder_ =
              new com.google.protobuf.SingleFieldBuilderV3<
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions,
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.JsonOptions.Builder,
                  com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig
                      .JsonOptionsOrBuilder>(getJsonOptions(), getParentForChildren(), isClean());
          jsonOptions_ = null;
        }
        return jsonOptionsBuilder_;
      }

      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }

      // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig)
    }

    // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig)
    private static final com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig
        DEFAULT_INSTANCE;

    static {
      DEFAULT_INSTANCE = new com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig();
    }

    public static com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig
        getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StorageConfig> PARSER =
        new com.google.protobuf.AbstractParser<StorageConfig>() {
          @java.lang.Override
          public StorageConfig parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
            Builder builder = newBuilder();
            try {
              builder.mergeFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              throw e.setUnfinishedMessage(builder.buildPartial());
            } catch (com.google.protobuf.UninitializedMessageException e) {
              throw e.asInvalidProtocolBufferException()
                  .setUnfinishedMessage(builder.buildPartial());
            } catch (java.io.IOException e) {
              throw new com.google.protobuf.InvalidProtocolBufferException(e)
                  .setUnfinishedMessage(builder.buildPartial());
            }
            return builder.buildPartial();
          }
        };

    public static com.google.protobuf.Parser<StorageConfig> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StorageConfig> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig
        getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }
  }

  private int bitField0_;
  private int resourceConfigCase_ = 0;

  @SuppressWarnings("serial")
  private java.lang.Object resourceConfig_;

  public enum ResourceConfigCase
      implements
          com.google.protobuf.Internal.EnumLite,
          com.google.protobuf.AbstractMessage.InternalOneOfEnum {
    STORAGE_CONFIG(100),
    RESOURCECONFIG_NOT_SET(0);
    private final int value;

    private ResourceConfigCase(int value) {
      this.value = value;
    }
    /**
     * @param value The number of the enum to look for.
     * @return The enum associated with the given number.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ResourceConfigCase valueOf(int value) {
      return forNumber(value);
    }

    public static ResourceConfigCase forNumber(int value) {
      switch (value) {
        case 100:
          return STORAGE_CONFIG;
        case 0:
          return RESOURCECONFIG_NOT_SET;
        default:
          return null;
      }
    }

    public int getNumber() {
      return this.value;
    }
  };

  public ResourceConfigCase getResourceConfigCase() {
    return ResourceConfigCase.forNumber(resourceConfigCase_);
  }

  public static final int BIGQUERY_PUBLISHING_CONFIG_FIELD_NUMBER = 1;
  private com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
      bigqueryPublishingConfig_;
  /**
   *
   *
   * <pre>
   * Optional. Configuration for metadata publishing.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
   * </code>
   *
   * @return Whether the bigqueryPublishingConfig field is set.
   */
  @java.lang.Override
  public boolean hasBigqueryPublishingConfig() {
    return ((bitField0_ & 0x00000001) != 0);
  }
  /**
   *
   *
   * <pre>
   * Optional. Configuration for metadata publishing.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
   * </code>
   *
   * @return The bigqueryPublishingConfig.
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
      getBigqueryPublishingConfig() {
    return bigqueryPublishingConfig_ == null
        ? com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
            .getDefaultInstance()
        : bigqueryPublishingConfig_;
  }
  /**
   *
   *
   * <pre>
   * Optional. Configuration for metadata publishing.
   * </pre>
   *
   * <code>
   * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
   * </code>
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfigOrBuilder
      getBigqueryPublishingConfigOrBuilder() {
    return bigqueryPublishingConfig_ == null
        ? com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
            .getDefaultInstance()
        : bigqueryPublishingConfig_;
  }

  public static final int STORAGE_CONFIG_FIELD_NUMBER = 100;
  /**
   *
   *
   * <pre>
   * Cloud Storage related configurations.
   * </pre>
   *
   * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
   *
   * @return Whether the storageConfig field is set.
   */
  @java.lang.Override
  public boolean hasStorageConfig() {
    return resourceConfigCase_ == 100;
  }
  /**
   *
   *
   * <pre>
   * Cloud Storage related configurations.
   * </pre>
   *
   * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
   *
   * @return The storageConfig.
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig getStorageConfig() {
    if (resourceConfigCase_ == 100) {
      return (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) resourceConfig_;
    }
    return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance();
  }
  /**
   *
   *
   * <pre>
   * Cloud Storage related configurations.
   * </pre>
   *
   * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
   */
  @java.lang.Override
  public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfigOrBuilder
      getStorageConfigOrBuilder() {
    if (resourceConfigCase_ == 100) {
      return (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) resourceConfig_;
    }
    return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance();
  }

  private byte memoizedIsInitialized = -1;

  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
    if (((bitField0_ & 0x00000001) != 0)) {
      output.writeMessage(1, getBigqueryPublishingConfig());
    }
    if (resourceConfigCase_ == 100) {
      output.writeMessage(
          100, (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) resourceConfig_);
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (((bitField0_ & 0x00000001) != 0)) {
      size +=
          com.google.protobuf.CodedOutputStream.computeMessageSize(
              1, getBigqueryPublishingConfig());
    }
    if (resourceConfigCase_ == 100) {
      size +=
          com.google.protobuf.CodedOutputStream.computeMessageSize(
              100, (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) resourceConfig_);
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
      return true;
    }
    if (!(obj instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec)) {
      return super.equals(obj);
    }
    com.google.cloud.dataplex.v1.DataDiscoverySpec other =
        (com.google.cloud.dataplex.v1.DataDiscoverySpec) obj;

    if (hasBigqueryPublishingConfig() != other.hasBigqueryPublishingConfig()) return false;
    if (hasBigqueryPublishingConfig()) {
      if (!getBigqueryPublishingConfig().equals(other.getBigqueryPublishingConfig())) return false;
    }
    if (!getResourceConfigCase().equals(other.getResourceConfigCase())) return false;
    switch (resourceConfigCase_) {
      case 100:
        if (!getStorageConfig().equals(other.getStorageConfig())) return false;
        break;
      case 0:
      default:
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    if (hasBigqueryPublishingConfig()) {
      hash = (37 * hash) + BIGQUERY_PUBLISHING_CONFIG_FIELD_NUMBER;
      hash = (53 * hash) + getBigqueryPublishingConfig().hashCode();
    }
    switch (resourceConfigCase_) {
      case 100:
        hash = (37 * hash) + STORAGE_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getStorageConfig().hashCode();
        break;
      case 0:
      default:
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(
      java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(
      byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(
      java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
        PARSER, input, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseDelimitedFrom(
      java.io.InputStream input) throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseDelimitedFrom(
      java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
        PARSER, input, extensionRegistry);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(
      com.google.protobuf.CodedInputStream input) throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
        PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() {
    return newBuilder();
  }

  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }

  public static Builder newBuilder(com.google.cloud.dataplex.v1.DataDiscoverySpec prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }

  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   *
   *
   * <pre>
   * Spec for a data discovery scan.
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataplex.v1.DataDiscoverySpec}
   */
  public static final class Builder extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
      implements
      // @@protoc_insertion_point(builder_implements:google.cloud.dataplex.v1.DataDiscoverySpec)
      com.google.cloud.dataplex.v1.DataDiscoverySpecOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataplex.v1.DataDiscoveryProto
          .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataplex.v1.DataDiscoveryProto
          .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataplex.v1.DataDiscoverySpec.class,
              com.google.cloud.dataplex.v1.DataDiscoverySpec.Builder.class);
    }

    // Construct using com.google.cloud.dataplex.v1.DataDiscoverySpec.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }

    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {
        getBigqueryPublishingConfigFieldBuilder();
      }
    }

    @java.lang.Override
    public Builder clear() {
      super.clear();
      bitField0_ = 0;
      bigqueryPublishingConfig_ = null;
      if (bigqueryPublishingConfigBuilder_ != null) {
        bigqueryPublishingConfigBuilder_.dispose();
        bigqueryPublishingConfigBuilder_ = null;
      }
      if (storageConfigBuilder_ != null) {
        storageConfigBuilder_.clear();
      }
      resourceConfigCase_ = 0;
      resourceConfig_ = null;
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
      return com.google.cloud.dataplex.v1.DataDiscoveryProto
          .internal_static_google_cloud_dataplex_v1_DataDiscoverySpec_descriptor;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec getDefaultInstanceForType() {
      return com.google.cloud.dataplex.v1.DataDiscoverySpec.getDefaultInstance();
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec build() {
      com.google.cloud.dataplex.v1.DataDiscoverySpec result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec buildPartial() {
      com.google.cloud.dataplex.v1.DataDiscoverySpec result =
          new com.google.cloud.dataplex.v1.DataDiscoverySpec(this);
      if (bitField0_ != 0) {
        buildPartial0(result);
      }
      buildPartialOneofs(result);
      onBuilt();
      return result;
    }

    private void buildPartial0(com.google.cloud.dataplex.v1.DataDiscoverySpec result) {
      int from_bitField0_ = bitField0_;
      int to_bitField0_ = 0;
      if (((from_bitField0_ & 0x00000001) != 0)) {
        result.bigqueryPublishingConfig_ =
            bigqueryPublishingConfigBuilder_ == null
                ? bigqueryPublishingConfig_
                : bigqueryPublishingConfigBuilder_.build();
        to_bitField0_ |= 0x00000001;
      }
      result.bitField0_ |= to_bitField0_;
    }

    private void buildPartialOneofs(com.google.cloud.dataplex.v1.DataDiscoverySpec result) {
      result.resourceConfigCase_ = resourceConfigCase_;
      result.resourceConfig_ = this.resourceConfig_;
      if (resourceConfigCase_ == 100 && storageConfigBuilder_ != null) {
        result.resourceConfig_ = storageConfigBuilder_.build();
      }
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }

    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
      return super.setField(field, value);
    }

    @java.lang.Override
    public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }

    @java.lang.Override
    public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }

    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field, int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }

    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }

    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.google.cloud.dataplex.v1.DataDiscoverySpec) {
        return mergeFrom((com.google.cloud.dataplex.v1.DataDiscoverySpec) other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.google.cloud.dataplex.v1.DataDiscoverySpec other) {
      if (other == com.google.cloud.dataplex.v1.DataDiscoverySpec.getDefaultInstance()) return this;
      if (other.hasBigqueryPublishingConfig()) {
        mergeBigqueryPublishingConfig(other.getBigqueryPublishingConfig());
      }
      switch (other.getResourceConfigCase()) {
        case STORAGE_CONFIG:
          {
            mergeStorageConfig(other.getStorageConfig());
            break;
          }
        case RESOURCECONFIG_NOT_SET:
          {
            break;
          }
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10:
              {
                input.readMessage(
                    getBigqueryPublishingConfigFieldBuilder().getBuilder(), extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
            case 802:
              {
                input.readMessage(getStorageConfigFieldBuilder().getBuilder(), extensionRegistry);
                resourceConfigCase_ = 100;
                break;
              } // case 802
            default:
              {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }

    private int resourceConfigCase_ = 0;
    private java.lang.Object resourceConfig_;

    public ResourceConfigCase getResourceConfigCase() {
      return ResourceConfigCase.forNumber(resourceConfigCase_);
    }

    public Builder clearResourceConfig() {
      resourceConfigCase_ = 0;
      resourceConfig_ = null;
      onChanged();
      return this;
    }

    private int bitField0_;

    private com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
        bigqueryPublishingConfig_;
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.Builder,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfigOrBuilder>
        bigqueryPublishingConfigBuilder_;
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return Whether the bigqueryPublishingConfig field is set.
     */
    public boolean hasBigqueryPublishingConfig() {
      return ((bitField0_ & 0x00000001) != 0);
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     *
     * @return The bigqueryPublishingConfig.
     */
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
        getBigqueryPublishingConfig() {
      if (bigqueryPublishingConfigBuilder_ == null) {
        return bigqueryPublishingConfig_ == null
            ? com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
                .getDefaultInstance()
            : bigqueryPublishingConfig_;
      } else {
        return bigqueryPublishingConfigBuilder_.getMessage();
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    public Builder setBigqueryPublishingConfig(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig value) {
      if (bigqueryPublishingConfigBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        bigqueryPublishingConfig_ = value;
      } else {
        bigqueryPublishingConfigBuilder_.setMessage(value);
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    public Builder setBigqueryPublishingConfig(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.Builder
            builderForValue) {
      if (bigqueryPublishingConfigBuilder_ == null) {
        bigqueryPublishingConfig_ = builderForValue.build();
      } else {
        bigqueryPublishingConfigBuilder_.setMessage(builderForValue.build());
      }
      bitField0_ |= 0x00000001;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    public Builder mergeBigqueryPublishingConfig(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig value) {
      if (bigqueryPublishingConfigBuilder_ == null) {
        if (((bitField0_ & 0x00000001) != 0)
            && bigqueryPublishingConfig_ != null
            && bigqueryPublishingConfig_
                != com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
                    .getDefaultInstance()) {
          getBigqueryPublishingConfigBuilder().mergeFrom(value);
        } else {
          bigqueryPublishingConfig_ = value;
        }
      } else {
        bigqueryPublishingConfigBuilder_.mergeFrom(value);
      }
      if (bigqueryPublishingConfig_ != null) {
        bitField0_ |= 0x00000001;
        onChanged();
      }
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    public Builder clearBigqueryPublishingConfig() {
      bitField0_ = (bitField0_ & ~0x00000001);
      bigqueryPublishingConfig_ = null;
      if (bigqueryPublishingConfigBuilder_ != null) {
        bigqueryPublishingConfigBuilder_.dispose();
        bigqueryPublishingConfigBuilder_ = null;
      }
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.Builder
        getBigqueryPublishingConfigBuilder() {
      bitField0_ |= 0x00000001;
      onChanged();
      return getBigqueryPublishingConfigFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfigOrBuilder
        getBigqueryPublishingConfigOrBuilder() {
      if (bigqueryPublishingConfigBuilder_ != null) {
        return bigqueryPublishingConfigBuilder_.getMessageOrBuilder();
      } else {
        return bigqueryPublishingConfig_ == null
            ? com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig
                .getDefaultInstance()
            : bigqueryPublishingConfig_;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. Configuration for metadata publishing.
     * </pre>
     *
     * <code>
     * .google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig bigquery_publishing_config = 1 [(.google.api.field_behavior) = OPTIONAL];
     * </code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.Builder,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfigOrBuilder>
        getBigqueryPublishingConfigFieldBuilder() {
      if (bigqueryPublishingConfigBuilder_ == null) {
        bigqueryPublishingConfigBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfig.Builder,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.BigQueryPublishingConfigOrBuilder>(
                getBigqueryPublishingConfig(), getParentForChildren(), isClean());
        bigqueryPublishingConfig_ = null;
      }
      return bigqueryPublishingConfigBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.Builder,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfigOrBuilder>
        storageConfigBuilder_;
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     *
     * @return Whether the storageConfig field is set.
     */
    @java.lang.Override
    public boolean hasStorageConfig() {
      return resourceConfigCase_ == 100;
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     *
     * @return The storageConfig.
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig getStorageConfig() {
      if (storageConfigBuilder_ == null) {
        if (resourceConfigCase_ == 100) {
          return (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) resourceConfig_;
        }
        return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance();
      } else {
        if (resourceConfigCase_ == 100) {
          return storageConfigBuilder_.getMessage();
        }
        return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance();
      }
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     */
    public Builder setStorageConfig(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig value) {
      if (storageConfigBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        resourceConfig_ = value;
        onChanged();
      } else {
        storageConfigBuilder_.setMessage(value);
      }
      resourceConfigCase_ = 100;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     */
    public Builder setStorageConfig(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.Builder builderForValue) {
      if (storageConfigBuilder_ == null) {
        resourceConfig_ = builderForValue.build();
        onChanged();
      } else {
        storageConfigBuilder_.setMessage(builderForValue.build());
      }
      resourceConfigCase_ = 100;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     */
    public Builder mergeStorageConfig(
        com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig value) {
      if (storageConfigBuilder_ == null) {
        if (resourceConfigCase_ == 100
            && resourceConfig_
                != com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig
                    .getDefaultInstance()) {
          resourceConfig_ =
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.newBuilder(
                      (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig)
                          resourceConfig_)
                  .mergeFrom(value)
                  .buildPartial();
        } else {
          resourceConfig_ = value;
        }
        onChanged();
      } else {
        if (resourceConfigCase_ == 100) {
          storageConfigBuilder_.mergeFrom(value);
        } else {
          storageConfigBuilder_.setMessage(value);
        }
      }
      resourceConfigCase_ = 100;
      return this;
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     */
    public Builder clearStorageConfig() {
      if (storageConfigBuilder_ == null) {
        if (resourceConfigCase_ == 100) {
          resourceConfigCase_ = 0;
          resourceConfig_ = null;
          onChanged();
        }
      } else {
        if (resourceConfigCase_ == 100) {
          resourceConfigCase_ = 0;
          resourceConfig_ = null;
        }
        storageConfigBuilder_.clear();
      }
      return this;
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     */
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.Builder
        getStorageConfigBuilder() {
      return getStorageConfigFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     */
    @java.lang.Override
    public com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfigOrBuilder
        getStorageConfigOrBuilder() {
      if ((resourceConfigCase_ == 100) && (storageConfigBuilder_ != null)) {
        return storageConfigBuilder_.getMessageOrBuilder();
      } else {
        if (resourceConfigCase_ == 100) {
          return (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) resourceConfig_;
        }
        return com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance();
      }
    }
    /**
     *
     *
     * <pre>
     * Cloud Storage related configurations.
     * </pre>
     *
     * <code>.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig storage_config = 100;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.Builder,
            com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfigOrBuilder>
        getStorageConfigFieldBuilder() {
      if (storageConfigBuilder_ == null) {
        if (!(resourceConfigCase_ == 100)) {
          resourceConfig_ =
              com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.getDefaultInstance();
        }
        storageConfigBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig.Builder,
                com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfigOrBuilder>(
                (com.google.cloud.dataplex.v1.DataDiscoverySpec.StorageConfig) resourceConfig_,
                getParentForChildren(),
                isClean());
        resourceConfig_ = null;
      }
      resourceConfigCase_ = 100;
      onChanged();
      return storageConfigBuilder_;
    }

    @java.lang.Override
    public final Builder setUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }

    // @@protoc_insertion_point(builder_scope:google.cloud.dataplex.v1.DataDiscoverySpec)
  }

  // @@protoc_insertion_point(class_scope:google.cloud.dataplex.v1.DataDiscoverySpec)
  private static final com.google.cloud.dataplex.v1.DataDiscoverySpec DEFAULT_INSTANCE;

  static {
    DEFAULT_INSTANCE = new com.google.cloud.dataplex.v1.DataDiscoverySpec();
  }

  public static com.google.cloud.dataplex.v1.DataDiscoverySpec getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<DataDiscoverySpec> PARSER =
      new com.google.protobuf.AbstractParser<DataDiscoverySpec>() {
        @java.lang.Override
        public DataDiscoverySpec parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          Builder builder = newBuilder();
          try {
            builder.mergeFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(builder.buildPartial());
          } catch (com.google.protobuf.UninitializedMessageException e) {
            throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
          } catch (java.io.IOException e) {
            throw new com.google.protobuf.InvalidProtocolBufferException(e)
                .setUnfinishedMessage(builder.buildPartial());
          }
          return builder.buildPartial();
        }
      };

  public static com.google.protobuf.Parser<DataDiscoverySpec> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<DataDiscoverySpec> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.cloud.dataplex.v1.DataDiscoverySpec getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }
}
