// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/privacy/dlp/v2beta1/dlp.proto

package com.google.privacy.dlp.v2beta1;

/**
 * <pre>
 * Cloud repository for storing output.
 * </pre>
 *
 * Protobuf type {@code google.privacy.dlp.v2beta1.OutputStorageConfig}
 */
public  final class OutputStorageConfig extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:google.privacy.dlp.v2beta1.OutputStorageConfig)
    OutputStorageConfigOrBuilder {
private static final long serialVersionUID = 0L;
  // Use OutputStorageConfig.newBuilder() to construct.
  private OutputStorageConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private OutputStorageConfig() {
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return this.unknownFields;
  }
  private OutputStorageConfig(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    this();
    if (extensionRegistry == null) {
      throw new java.lang.NullPointerException();
    }
    int mutable_bitField0_ = 0;
    com.google.protobuf.UnknownFieldSet.Builder unknownFields =
        com.google.protobuf.UnknownFieldSet.newBuilder();
    try {
      boolean done = false;
      while (!done) {
        int tag = input.readTag();
        switch (tag) {
          case 0:
            done = true;
            break;
          default: {
            if (!parseUnknownFieldProto3(
                input, unknownFields, extensionRegistry, tag)) {
              done = true;
            }
            break;
          }
          case 10: {
            com.google.privacy.dlp.v2beta1.BigQueryTable.Builder subBuilder = null;
            if (typeCase_ == 1) {
              subBuilder = ((com.google.privacy.dlp.v2beta1.BigQueryTable) type_).toBuilder();
            }
            type_ =
                input.readMessage(com.google.privacy.dlp.v2beta1.BigQueryTable.parser(), extensionRegistry);
            if (subBuilder != null) {
              subBuilder.mergeFrom((com.google.privacy.dlp.v2beta1.BigQueryTable) type_);
              type_ = subBuilder.buildPartial();
            }
            typeCase_ = 1;
            break;
          }
          case 18: {
            com.google.privacy.dlp.v2beta1.CloudStoragePath.Builder subBuilder = null;
            if (typeCase_ == 2) {
              subBuilder = ((com.google.privacy.dlp.v2beta1.CloudStoragePath) type_).toBuilder();
            }
            type_ =
                input.readMessage(com.google.privacy.dlp.v2beta1.CloudStoragePath.parser(), extensionRegistry);
            if (subBuilder != null) {
              subBuilder.mergeFrom((com.google.privacy.dlp.v2beta1.CloudStoragePath) type_);
              type_ = subBuilder.buildPartial();
            }
            typeCase_ = 2;
            break;
          }
        }
      }
    } catch (com.google.protobuf.InvalidProtocolBufferException e) {
      throw e.setUnfinishedMessage(this);
    } catch (java.io.IOException e) {
      throw new com.google.protobuf.InvalidProtocolBufferException(
          e).setUnfinishedMessage(this);
    } finally {
      this.unknownFields = unknownFields.build();
      makeExtensionsImmutable();
    }
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return com.google.privacy.dlp.v2beta1.DlpProto.internal_static_google_privacy_dlp_v2beta1_OutputStorageConfig_descriptor;
  }

  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.google.privacy.dlp.v2beta1.DlpProto.internal_static_google_privacy_dlp_v2beta1_OutputStorageConfig_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.google.privacy.dlp.v2beta1.OutputStorageConfig.class, com.google.privacy.dlp.v2beta1.OutputStorageConfig.Builder.class);
  }

  private int typeCase_ = 0;
  private java.lang.Object type_;
  public enum TypeCase
      implements com.google.protobuf.Internal.EnumLite {
    TABLE(1),
    STORAGE_PATH(2),
    TYPE_NOT_SET(0);
    private final int value;
    private TypeCase(int value) {
      this.value = value;
    }
    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static TypeCase valueOf(int value) {
      return forNumber(value);
    }

    public static TypeCase forNumber(int value) {
      switch (value) {
        case 1: return TABLE;
        case 2: return STORAGE_PATH;
        case 0: return TYPE_NOT_SET;
        default: return null;
      }
    }
    public int getNumber() {
      return this.value;
    }
  };

  public TypeCase
  getTypeCase() {
    return TypeCase.forNumber(
        typeCase_);
  }

  public static final int TABLE_FIELD_NUMBER = 1;
  /**
   * <pre>
   * Store findings in a new table in the dataset.
   * </pre>
   *
   * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
   */
  public boolean hasTable() {
    return typeCase_ == 1;
  }
  /**
   * <pre>
   * Store findings in a new table in the dataset.
   * </pre>
   *
   * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
   */
  public com.google.privacy.dlp.v2beta1.BigQueryTable getTable() {
    if (typeCase_ == 1) {
       return (com.google.privacy.dlp.v2beta1.BigQueryTable) type_;
    }
    return com.google.privacy.dlp.v2beta1.BigQueryTable.getDefaultInstance();
  }
  /**
   * <pre>
   * Store findings in a new table in the dataset.
   * </pre>
   *
   * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
   */
  public com.google.privacy.dlp.v2beta1.BigQueryTableOrBuilder getTableOrBuilder() {
    if (typeCase_ == 1) {
       return (com.google.privacy.dlp.v2beta1.BigQueryTable) type_;
    }
    return com.google.privacy.dlp.v2beta1.BigQueryTable.getDefaultInstance();
  }

  public static final int STORAGE_PATH_FIELD_NUMBER = 2;
  /**
   * <pre>
   * The path to a Google Cloud Storage location to store output.
   * The bucket must already exist and
   * the Google APIs service account for DLP must have write permission to
   * write to the given bucket.
   * Results are split over multiple csv files with each file name matching
   * the pattern "[operation_id]_[count].csv", for example
   * `3094877188788974909_1.csv`. The `operation_id` matches the
   * identifier for the Operation, and the `count` is a counter used for
   * tracking the number of files written.
   * The CSV file(s) contain the following columns regardless of storage type
   * scanned:
   * - id
   * - info_type
   * - likelihood
   * - byte size of finding
   * - quote
   * - timestamp
   * For Cloud Storage the next columns are:
   * - file_path
   * - start_offset
   * For Cloud Datastore the next columns are:
   * - project_id
   * - namespace_id
   * - path
   * - column_name
   * - offset
   * For BigQuery the next columns are:
   * - row_number
   * - project_id
   * - dataset_id
   * - table_id
   * </pre>
   *
   * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
   */
  public boolean hasStoragePath() {
    return typeCase_ == 2;
  }
  /**
   * <pre>
   * The path to a Google Cloud Storage location to store output.
   * The bucket must already exist and
   * the Google APIs service account for DLP must have write permission to
   * write to the given bucket.
   * Results are split over multiple csv files with each file name matching
   * the pattern "[operation_id]_[count].csv", for example
   * `3094877188788974909_1.csv`. The `operation_id` matches the
   * identifier for the Operation, and the `count` is a counter used for
   * tracking the number of files written.
   * The CSV file(s) contain the following columns regardless of storage type
   * scanned:
   * - id
   * - info_type
   * - likelihood
   * - byte size of finding
   * - quote
   * - timestamp
   * For Cloud Storage the next columns are:
   * - file_path
   * - start_offset
   * For Cloud Datastore the next columns are:
   * - project_id
   * - namespace_id
   * - path
   * - column_name
   * - offset
   * For BigQuery the next columns are:
   * - row_number
   * - project_id
   * - dataset_id
   * - table_id
   * </pre>
   *
   * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
   */
  public com.google.privacy.dlp.v2beta1.CloudStoragePath getStoragePath() {
    if (typeCase_ == 2) {
       return (com.google.privacy.dlp.v2beta1.CloudStoragePath) type_;
    }
    return com.google.privacy.dlp.v2beta1.CloudStoragePath.getDefaultInstance();
  }
  /**
   * <pre>
   * The path to a Google Cloud Storage location to store output.
   * The bucket must already exist and
   * the Google APIs service account for DLP must have write permission to
   * write to the given bucket.
   * Results are split over multiple csv files with each file name matching
   * the pattern "[operation_id]_[count].csv", for example
   * `3094877188788974909_1.csv`. The `operation_id` matches the
   * identifier for the Operation, and the `count` is a counter used for
   * tracking the number of files written.
   * The CSV file(s) contain the following columns regardless of storage type
   * scanned:
   * - id
   * - info_type
   * - likelihood
   * - byte size of finding
   * - quote
   * - timestamp
   * For Cloud Storage the next columns are:
   * - file_path
   * - start_offset
   * For Cloud Datastore the next columns are:
   * - project_id
   * - namespace_id
   * - path
   * - column_name
   * - offset
   * For BigQuery the next columns are:
   * - row_number
   * - project_id
   * - dataset_id
   * - table_id
   * </pre>
   *
   * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
   */
  public com.google.privacy.dlp.v2beta1.CloudStoragePathOrBuilder getStoragePathOrBuilder() {
    if (typeCase_ == 2) {
       return (com.google.privacy.dlp.v2beta1.CloudStoragePath) type_;
    }
    return com.google.privacy.dlp.v2beta1.CloudStoragePath.getDefaultInstance();
  }

  private byte memoizedIsInitialized = -1;
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (typeCase_ == 1) {
      output.writeMessage(1, (com.google.privacy.dlp.v2beta1.BigQueryTable) type_);
    }
    if (typeCase_ == 2) {
      output.writeMessage(2, (com.google.privacy.dlp.v2beta1.CloudStoragePath) type_);
    }
    unknownFields.writeTo(output);
  }

  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (typeCase_ == 1) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(1, (com.google.privacy.dlp.v2beta1.BigQueryTable) type_);
    }
    if (typeCase_ == 2) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(2, (com.google.privacy.dlp.v2beta1.CloudStoragePath) type_);
    }
    size += unknownFields.getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof com.google.privacy.dlp.v2beta1.OutputStorageConfig)) {
      return super.equals(obj);
    }
    com.google.privacy.dlp.v2beta1.OutputStorageConfig other = (com.google.privacy.dlp.v2beta1.OutputStorageConfig) obj;

    boolean result = true;
    result = result && getTypeCase().equals(
        other.getTypeCase());
    if (!result) return false;
    switch (typeCase_) {
      case 1:
        result = result && getTable()
            .equals(other.getTable());
        break;
      case 2:
        result = result && getStoragePath()
            .equals(other.getStoragePath());
        break;
      case 0:
      default:
    }
    result = result && unknownFields.equals(other.unknownFields);
    return result;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    switch (typeCase_) {
      case 1:
        hash = (37 * hash) + TABLE_FIELD_NUMBER;
        hash = (53 * hash) + getTable().hashCode();
        break;
      case 2:
        hash = (37 * hash) + STORAGE_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getStoragePath().hashCode();
        break;
      case 0:
      default:
    }
    hash = (29 * hash) + unknownFields.hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.privacy.dlp.v2beta1.OutputStorageConfig prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Cloud repository for storing output.
   * </pre>
   *
   * Protobuf type {@code google.privacy.dlp.v2beta1.OutputStorageConfig}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:google.privacy.dlp.v2beta1.OutputStorageConfig)
      com.google.privacy.dlp.v2beta1.OutputStorageConfigOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.privacy.dlp.v2beta1.DlpProto.internal_static_google_privacy_dlp_v2beta1_OutputStorageConfig_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.privacy.dlp.v2beta1.DlpProto.internal_static_google_privacy_dlp_v2beta1_OutputStorageConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.privacy.dlp.v2beta1.OutputStorageConfig.class, com.google.privacy.dlp.v2beta1.OutputStorageConfig.Builder.class);
    }

    // Construct using com.google.privacy.dlp.v2beta1.OutputStorageConfig.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3
              .alwaysUseFieldBuilders) {
      }
    }
    public Builder clear() {
      super.clear();
      typeCase_ = 0;
      type_ = null;
      return this;
    }

    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return com.google.privacy.dlp.v2beta1.DlpProto.internal_static_google_privacy_dlp_v2beta1_OutputStorageConfig_descriptor;
    }

    public com.google.privacy.dlp.v2beta1.OutputStorageConfig getDefaultInstanceForType() {
      return com.google.privacy.dlp.v2beta1.OutputStorageConfig.getDefaultInstance();
    }

    public com.google.privacy.dlp.v2beta1.OutputStorageConfig build() {
      com.google.privacy.dlp.v2beta1.OutputStorageConfig result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    public com.google.privacy.dlp.v2beta1.OutputStorageConfig buildPartial() {
      com.google.privacy.dlp.v2beta1.OutputStorageConfig result = new com.google.privacy.dlp.v2beta1.OutputStorageConfig(this);
      if (typeCase_ == 1) {
        if (tableBuilder_ == null) {
          result.type_ = type_;
        } else {
          result.type_ = tableBuilder_.build();
        }
      }
      if (typeCase_ == 2) {
        if (storagePathBuilder_ == null) {
          result.type_ = type_;
        } else {
          result.type_ = storagePathBuilder_.build();
        }
      }
      result.typeCase_ = typeCase_;
      onBuilt();
      return result;
    }

    public Builder clone() {
      return (Builder) super.clone();
    }
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return (Builder) super.setField(field, value);
    }
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return (Builder) super.clearField(field);
    }
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return (Builder) super.clearOneof(oneof);
    }
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, java.lang.Object value) {
      return (Builder) super.setRepeatedField(field, index, value);
    }
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return (Builder) super.addRepeatedField(field, value);
    }
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.google.privacy.dlp.v2beta1.OutputStorageConfig) {
        return mergeFrom((com.google.privacy.dlp.v2beta1.OutputStorageConfig)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.google.privacy.dlp.v2beta1.OutputStorageConfig other) {
      if (other == com.google.privacy.dlp.v2beta1.OutputStorageConfig.getDefaultInstance()) return this;
      switch (other.getTypeCase()) {
        case TABLE: {
          mergeTable(other.getTable());
          break;
        }
        case STORAGE_PATH: {
          mergeStoragePath(other.getStoragePath());
          break;
        }
        case TYPE_NOT_SET: {
          break;
        }
      }
      this.mergeUnknownFields(other.unknownFields);
      onChanged();
      return this;
    }

    public final boolean isInitialized() {
      return true;
    }

    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      com.google.privacy.dlp.v2beta1.OutputStorageConfig parsedMessage = null;
      try {
        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        parsedMessage = (com.google.privacy.dlp.v2beta1.OutputStorageConfig) e.getUnfinishedMessage();
        throw e.unwrapIOException();
      } finally {
        if (parsedMessage != null) {
          mergeFrom(parsedMessage);
        }
      }
      return this;
    }
    private int typeCase_ = 0;
    private java.lang.Object type_;
    public TypeCase
        getTypeCase() {
      return TypeCase.forNumber(
          typeCase_);
    }

    public Builder clearType() {
      typeCase_ = 0;
      type_ = null;
      onChanged();
      return this;
    }


    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.privacy.dlp.v2beta1.BigQueryTable, com.google.privacy.dlp.v2beta1.BigQueryTable.Builder, com.google.privacy.dlp.v2beta1.BigQueryTableOrBuilder> tableBuilder_;
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public boolean hasTable() {
      return typeCase_ == 1;
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public com.google.privacy.dlp.v2beta1.BigQueryTable getTable() {
      if (tableBuilder_ == null) {
        if (typeCase_ == 1) {
          return (com.google.privacy.dlp.v2beta1.BigQueryTable) type_;
        }
        return com.google.privacy.dlp.v2beta1.BigQueryTable.getDefaultInstance();
      } else {
        if (typeCase_ == 1) {
          return tableBuilder_.getMessage();
        }
        return com.google.privacy.dlp.v2beta1.BigQueryTable.getDefaultInstance();
      }
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public Builder setTable(com.google.privacy.dlp.v2beta1.BigQueryTable value) {
      if (tableBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        type_ = value;
        onChanged();
      } else {
        tableBuilder_.setMessage(value);
      }
      typeCase_ = 1;
      return this;
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public Builder setTable(
        com.google.privacy.dlp.v2beta1.BigQueryTable.Builder builderForValue) {
      if (tableBuilder_ == null) {
        type_ = builderForValue.build();
        onChanged();
      } else {
        tableBuilder_.setMessage(builderForValue.build());
      }
      typeCase_ = 1;
      return this;
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public Builder mergeTable(com.google.privacy.dlp.v2beta1.BigQueryTable value) {
      if (tableBuilder_ == null) {
        if (typeCase_ == 1 &&
            type_ != com.google.privacy.dlp.v2beta1.BigQueryTable.getDefaultInstance()) {
          type_ = com.google.privacy.dlp.v2beta1.BigQueryTable.newBuilder((com.google.privacy.dlp.v2beta1.BigQueryTable) type_)
              .mergeFrom(value).buildPartial();
        } else {
          type_ = value;
        }
        onChanged();
      } else {
        if (typeCase_ == 1) {
          tableBuilder_.mergeFrom(value);
        }
        tableBuilder_.setMessage(value);
      }
      typeCase_ = 1;
      return this;
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public Builder clearTable() {
      if (tableBuilder_ == null) {
        if (typeCase_ == 1) {
          typeCase_ = 0;
          type_ = null;
          onChanged();
        }
      } else {
        if (typeCase_ == 1) {
          typeCase_ = 0;
          type_ = null;
        }
        tableBuilder_.clear();
      }
      return this;
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public com.google.privacy.dlp.v2beta1.BigQueryTable.Builder getTableBuilder() {
      return getTableFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    public com.google.privacy.dlp.v2beta1.BigQueryTableOrBuilder getTableOrBuilder() {
      if ((typeCase_ == 1) && (tableBuilder_ != null)) {
        return tableBuilder_.getMessageOrBuilder();
      } else {
        if (typeCase_ == 1) {
          return (com.google.privacy.dlp.v2beta1.BigQueryTable) type_;
        }
        return com.google.privacy.dlp.v2beta1.BigQueryTable.getDefaultInstance();
      }
    }
    /**
     * <pre>
     * Store findings in a new table in the dataset.
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.BigQueryTable table = 1;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.privacy.dlp.v2beta1.BigQueryTable, com.google.privacy.dlp.v2beta1.BigQueryTable.Builder, com.google.privacy.dlp.v2beta1.BigQueryTableOrBuilder> 
        getTableFieldBuilder() {
      if (tableBuilder_ == null) {
        if (!(typeCase_ == 1)) {
          type_ = com.google.privacy.dlp.v2beta1.BigQueryTable.getDefaultInstance();
        }
        tableBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            com.google.privacy.dlp.v2beta1.BigQueryTable, com.google.privacy.dlp.v2beta1.BigQueryTable.Builder, com.google.privacy.dlp.v2beta1.BigQueryTableOrBuilder>(
                (com.google.privacy.dlp.v2beta1.BigQueryTable) type_,
                getParentForChildren(),
                isClean());
        type_ = null;
      }
      typeCase_ = 1;
      onChanged();;
      return tableBuilder_;
    }

    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.privacy.dlp.v2beta1.CloudStoragePath, com.google.privacy.dlp.v2beta1.CloudStoragePath.Builder, com.google.privacy.dlp.v2beta1.CloudStoragePathOrBuilder> storagePathBuilder_;
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public boolean hasStoragePath() {
      return typeCase_ == 2;
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public com.google.privacy.dlp.v2beta1.CloudStoragePath getStoragePath() {
      if (storagePathBuilder_ == null) {
        if (typeCase_ == 2) {
          return (com.google.privacy.dlp.v2beta1.CloudStoragePath) type_;
        }
        return com.google.privacy.dlp.v2beta1.CloudStoragePath.getDefaultInstance();
      } else {
        if (typeCase_ == 2) {
          return storagePathBuilder_.getMessage();
        }
        return com.google.privacy.dlp.v2beta1.CloudStoragePath.getDefaultInstance();
      }
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public Builder setStoragePath(com.google.privacy.dlp.v2beta1.CloudStoragePath value) {
      if (storagePathBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        type_ = value;
        onChanged();
      } else {
        storagePathBuilder_.setMessage(value);
      }
      typeCase_ = 2;
      return this;
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public Builder setStoragePath(
        com.google.privacy.dlp.v2beta1.CloudStoragePath.Builder builderForValue) {
      if (storagePathBuilder_ == null) {
        type_ = builderForValue.build();
        onChanged();
      } else {
        storagePathBuilder_.setMessage(builderForValue.build());
      }
      typeCase_ = 2;
      return this;
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public Builder mergeStoragePath(com.google.privacy.dlp.v2beta1.CloudStoragePath value) {
      if (storagePathBuilder_ == null) {
        if (typeCase_ == 2 &&
            type_ != com.google.privacy.dlp.v2beta1.CloudStoragePath.getDefaultInstance()) {
          type_ = com.google.privacy.dlp.v2beta1.CloudStoragePath.newBuilder((com.google.privacy.dlp.v2beta1.CloudStoragePath) type_)
              .mergeFrom(value).buildPartial();
        } else {
          type_ = value;
        }
        onChanged();
      } else {
        if (typeCase_ == 2) {
          storagePathBuilder_.mergeFrom(value);
        }
        storagePathBuilder_.setMessage(value);
      }
      typeCase_ = 2;
      return this;
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public Builder clearStoragePath() {
      if (storagePathBuilder_ == null) {
        if (typeCase_ == 2) {
          typeCase_ = 0;
          type_ = null;
          onChanged();
        }
      } else {
        if (typeCase_ == 2) {
          typeCase_ = 0;
          type_ = null;
        }
        storagePathBuilder_.clear();
      }
      return this;
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public com.google.privacy.dlp.v2beta1.CloudStoragePath.Builder getStoragePathBuilder() {
      return getStoragePathFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    public com.google.privacy.dlp.v2beta1.CloudStoragePathOrBuilder getStoragePathOrBuilder() {
      if ((typeCase_ == 2) && (storagePathBuilder_ != null)) {
        return storagePathBuilder_.getMessageOrBuilder();
      } else {
        if (typeCase_ == 2) {
          return (com.google.privacy.dlp.v2beta1.CloudStoragePath) type_;
        }
        return com.google.privacy.dlp.v2beta1.CloudStoragePath.getDefaultInstance();
      }
    }
    /**
     * <pre>
     * The path to a Google Cloud Storage location to store output.
     * The bucket must already exist and
     * the Google APIs service account for DLP must have write permission to
     * write to the given bucket.
     * Results are split over multiple csv files with each file name matching
     * the pattern "[operation_id]_[count].csv", for example
     * `3094877188788974909_1.csv`. The `operation_id` matches the
     * identifier for the Operation, and the `count` is a counter used for
     * tracking the number of files written.
     * The CSV file(s) contain the following columns regardless of storage type
     * scanned:
     * - id
     * - info_type
     * - likelihood
     * - byte size of finding
     * - quote
     * - timestamp
     * For Cloud Storage the next columns are:
     * - file_path
     * - start_offset
     * For Cloud Datastore the next columns are:
     * - project_id
     * - namespace_id
     * - path
     * - column_name
     * - offset
     * For BigQuery the next columns are:
     * - row_number
     * - project_id
     * - dataset_id
     * - table_id
     * </pre>
     *
     * <code>.google.privacy.dlp.v2beta1.CloudStoragePath storage_path = 2;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        com.google.privacy.dlp.v2beta1.CloudStoragePath, com.google.privacy.dlp.v2beta1.CloudStoragePath.Builder, com.google.privacy.dlp.v2beta1.CloudStoragePathOrBuilder> 
        getStoragePathFieldBuilder() {
      if (storagePathBuilder_ == null) {
        if (!(typeCase_ == 2)) {
          type_ = com.google.privacy.dlp.v2beta1.CloudStoragePath.getDefaultInstance();
        }
        storagePathBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            com.google.privacy.dlp.v2beta1.CloudStoragePath, com.google.privacy.dlp.v2beta1.CloudStoragePath.Builder, com.google.privacy.dlp.v2beta1.CloudStoragePathOrBuilder>(
                (com.google.privacy.dlp.v2beta1.CloudStoragePath) type_,
                getParentForChildren(),
                isClean());
        type_ = null;
      }
      typeCase_ = 2;
      onChanged();;
      return storagePathBuilder_;
    }
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFieldsProto3(unknownFields);
    }

    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:google.privacy.dlp.v2beta1.OutputStorageConfig)
  }

  // @@protoc_insertion_point(class_scope:google.privacy.dlp.v2beta1.OutputStorageConfig)
  private static final com.google.privacy.dlp.v2beta1.OutputStorageConfig DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new com.google.privacy.dlp.v2beta1.OutputStorageConfig();
  }

  public static com.google.privacy.dlp.v2beta1.OutputStorageConfig getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<OutputStorageConfig>
      PARSER = new com.google.protobuf.AbstractParser<OutputStorageConfig>() {
    public OutputStorageConfig parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return new OutputStorageConfig(input, extensionRegistry);
    }
  };

  public static com.google.protobuf.Parser<OutputStorageConfig> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<OutputStorageConfig> getParserForType() {
    return PARSER;
  }

  public com.google.privacy.dlp.v2beta1.OutputStorageConfig getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

