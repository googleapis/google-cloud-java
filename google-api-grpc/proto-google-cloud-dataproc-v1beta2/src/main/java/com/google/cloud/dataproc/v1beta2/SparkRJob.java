// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/dataproc/v1beta2/jobs.proto

package com.google.cloud.dataproc.v1beta2;

/**
 *
 *
 * <pre>
 * A Cloud Dataproc job for running
 * [Apache SparkR](https://spark.apache.org/docs/latest/sparkr.html)
 * applications on YARN.
 * </pre>
 *
 * Protobuf type {@code google.cloud.dataproc.v1beta2.SparkRJob}
 */
public final class SparkRJob extends com.google.protobuf.GeneratedMessageV3
    implements
    // @@protoc_insertion_point(message_implements:google.cloud.dataproc.v1beta2.SparkRJob)
    SparkRJobOrBuilder {
  private static final long serialVersionUID = 0L;
  // Use SparkRJob.newBuilder() to construct.
  private SparkRJob(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }

  private SparkRJob() {
    mainRFileUri_ = "";
    args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet getUnknownFields() {
    return this.unknownFields;
  }

  private SparkRJob(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    this();
    if (extensionRegistry == null) {
      throw new java.lang.NullPointerException();
    }
    int mutable_bitField0_ = 0;
    com.google.protobuf.UnknownFieldSet.Builder unknownFields =
        com.google.protobuf.UnknownFieldSet.newBuilder();
    try {
      boolean done = false;
      while (!done) {
        int tag = input.readTag();
        switch (tag) {
          case 0:
            done = true;
            break;
          case 10:
            {
              java.lang.String s = input.readStringRequireUtf8();

              mainRFileUri_ = s;
              break;
            }
          case 18:
            {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                args_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              args_.add(s);
              break;
            }
          case 26:
            {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                fileUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000004;
              }
              fileUris_.add(s);
              break;
            }
          case 34:
            {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000008) != 0)) {
                archiveUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              archiveUris_.add(s);
              break;
            }
          case 42:
            {
              if (!((mutable_bitField0_ & 0x00000010) != 0)) {
                properties_ =
                    com.google.protobuf.MapField.newMapField(
                        PropertiesDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000010;
              }
              com.google.protobuf.MapEntry<java.lang.String, java.lang.String> properties__ =
                  input.readMessage(
                      PropertiesDefaultEntryHolder.defaultEntry.getParserForType(),
                      extensionRegistry);
              properties_.getMutableMap().put(properties__.getKey(), properties__.getValue());
              break;
            }
          case 50:
            {
              com.google.cloud.dataproc.v1beta2.LoggingConfig.Builder subBuilder = null;
              if (loggingConfig_ != null) {
                subBuilder = loggingConfig_.toBuilder();
              }
              loggingConfig_ =
                  input.readMessage(
                      com.google.cloud.dataproc.v1beta2.LoggingConfig.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(loggingConfig_);
                loggingConfig_ = subBuilder.buildPartial();
              }

              break;
            }
          default:
            {
              if (!parseUnknownField(input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
        }
      }
    } catch (com.google.protobuf.InvalidProtocolBufferException e) {
      throw e.setUnfinishedMessage(this);
    } catch (java.io.IOException e) {
      throw new com.google.protobuf.InvalidProtocolBufferException(e).setUnfinishedMessage(this);
    } finally {
      if (((mutable_bitField0_ & 0x00000002) != 0)) {
        args_ = args_.getUnmodifiableView();
      }
      if (((mutable_bitField0_ & 0x00000004) != 0)) {
        fileUris_ = fileUris_.getUnmodifiableView();
      }
      if (((mutable_bitField0_ & 0x00000008) != 0)) {
        archiveUris_ = archiveUris_.getUnmodifiableView();
      }
      this.unknownFields = unknownFields.build();
      makeExtensionsImmutable();
    }
  }

  public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
    return com.google.cloud.dataproc.v1beta2.JobsProto
        .internal_static_google_cloud_dataproc_v1beta2_SparkRJob_descriptor;
  }

  @SuppressWarnings({"rawtypes"})
  @java.lang.Override
  protected com.google.protobuf.MapField internalGetMapField(int number) {
    switch (number) {
      case 5:
        return internalGetProperties();
      default:
        throw new RuntimeException("Invalid map field number: " + number);
    }
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.google.cloud.dataproc.v1beta2.JobsProto
        .internal_static_google_cloud_dataproc_v1beta2_SparkRJob_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.google.cloud.dataproc.v1beta2.SparkRJob.class,
            com.google.cloud.dataproc.v1beta2.SparkRJob.Builder.class);
  }

  private int bitField0_;
  public static final int MAIN_R_FILE_URI_FIELD_NUMBER = 1;
  private volatile java.lang.Object mainRFileUri_;
  /**
   *
   *
   * <pre>
   * Required. The HCFS URI of the main R file to use as the driver.
   * Must be a .R file.
   * </pre>
   *
   * <code>string main_r_file_uri = 1 [(.google.api.field_behavior) = REQUIRED];</code>
   */
  public java.lang.String getMainRFileUri() {
    java.lang.Object ref = mainRFileUri_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      mainRFileUri_ = s;
      return s;
    }
  }
  /**
   *
   *
   * <pre>
   * Required. The HCFS URI of the main R file to use as the driver.
   * Must be a .R file.
   * </pre>
   *
   * <code>string main_r_file_uri = 1 [(.google.api.field_behavior) = REQUIRED];</code>
   */
  public com.google.protobuf.ByteString getMainRFileUriBytes() {
    java.lang.Object ref = mainRFileUri_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b =
          com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
      mainRFileUri_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int ARGS_FIELD_NUMBER = 2;
  private com.google.protobuf.LazyStringList args_;
  /**
   *
   *
   * <pre>
   * Optional. The arguments to pass to the driver.  Do not include arguments,
   * such as `--conf`, that can be set as job properties, since a collision may
   * occur that causes an incorrect job submission.
   * </pre>
   *
   * <code>repeated string args = 2;</code>
   */
  public com.google.protobuf.ProtocolStringList getArgsList() {
    return args_;
  }
  /**
   *
   *
   * <pre>
   * Optional. The arguments to pass to the driver.  Do not include arguments,
   * such as `--conf`, that can be set as job properties, since a collision may
   * occur that causes an incorrect job submission.
   * </pre>
   *
   * <code>repeated string args = 2;</code>
   */
  public int getArgsCount() {
    return args_.size();
  }
  /**
   *
   *
   * <pre>
   * Optional. The arguments to pass to the driver.  Do not include arguments,
   * such as `--conf`, that can be set as job properties, since a collision may
   * occur that causes an incorrect job submission.
   * </pre>
   *
   * <code>repeated string args = 2;</code>
   */
  public java.lang.String getArgs(int index) {
    return args_.get(index);
  }
  /**
   *
   *
   * <pre>
   * Optional. The arguments to pass to the driver.  Do not include arguments,
   * such as `--conf`, that can be set as job properties, since a collision may
   * occur that causes an incorrect job submission.
   * </pre>
   *
   * <code>repeated string args = 2;</code>
   */
  public com.google.protobuf.ByteString getArgsBytes(int index) {
    return args_.getByteString(index);
  }

  public static final int FILE_URIS_FIELD_NUMBER = 3;
  private com.google.protobuf.LazyStringList fileUris_;
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of files to be copied to the working directory of
   * R drivers and distributed tasks. Useful for naively parallel tasks.
   * </pre>
   *
   * <code>repeated string file_uris = 3;</code>
   */
  public com.google.protobuf.ProtocolStringList getFileUrisList() {
    return fileUris_;
  }
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of files to be copied to the working directory of
   * R drivers and distributed tasks. Useful for naively parallel tasks.
   * </pre>
   *
   * <code>repeated string file_uris = 3;</code>
   */
  public int getFileUrisCount() {
    return fileUris_.size();
  }
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of files to be copied to the working directory of
   * R drivers and distributed tasks. Useful for naively parallel tasks.
   * </pre>
   *
   * <code>repeated string file_uris = 3;</code>
   */
  public java.lang.String getFileUris(int index) {
    return fileUris_.get(index);
  }
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of files to be copied to the working directory of
   * R drivers and distributed tasks. Useful for naively parallel tasks.
   * </pre>
   *
   * <code>repeated string file_uris = 3;</code>
   */
  public com.google.protobuf.ByteString getFileUrisBytes(int index) {
    return fileUris_.getByteString(index);
  }

  public static final int ARCHIVE_URIS_FIELD_NUMBER = 4;
  private com.google.protobuf.LazyStringList archiveUris_;
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of archives to be extracted in the working directory of
   * Spark drivers and tasks. Supported file types:
   * .jar, .tar, .tar.gz, .tgz, and .zip.
   * </pre>
   *
   * <code>repeated string archive_uris = 4;</code>
   */
  public com.google.protobuf.ProtocolStringList getArchiveUrisList() {
    return archiveUris_;
  }
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of archives to be extracted in the working directory of
   * Spark drivers and tasks. Supported file types:
   * .jar, .tar, .tar.gz, .tgz, and .zip.
   * </pre>
   *
   * <code>repeated string archive_uris = 4;</code>
   */
  public int getArchiveUrisCount() {
    return archiveUris_.size();
  }
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of archives to be extracted in the working directory of
   * Spark drivers and tasks. Supported file types:
   * .jar, .tar, .tar.gz, .tgz, and .zip.
   * </pre>
   *
   * <code>repeated string archive_uris = 4;</code>
   */
  public java.lang.String getArchiveUris(int index) {
    return archiveUris_.get(index);
  }
  /**
   *
   *
   * <pre>
   * Optional. HCFS URIs of archives to be extracted in the working directory of
   * Spark drivers and tasks. Supported file types:
   * .jar, .tar, .tar.gz, .tgz, and .zip.
   * </pre>
   *
   * <code>repeated string archive_uris = 4;</code>
   */
  public com.google.protobuf.ByteString getArchiveUrisBytes(int index) {
    return archiveUris_.getByteString(index);
  }

  public static final int PROPERTIES_FIELD_NUMBER = 5;

  private static final class PropertiesDefaultEntryHolder {
    static final com.google.protobuf.MapEntry<java.lang.String, java.lang.String> defaultEntry =
        com.google.protobuf.MapEntry.<java.lang.String, java.lang.String>newDefaultInstance(
            com.google.cloud.dataproc.v1beta2.JobsProto
                .internal_static_google_cloud_dataproc_v1beta2_SparkRJob_PropertiesEntry_descriptor,
            com.google.protobuf.WireFormat.FieldType.STRING,
            "",
            com.google.protobuf.WireFormat.FieldType.STRING,
            "");
  }

  private com.google.protobuf.MapField<java.lang.String, java.lang.String> properties_;

  private com.google.protobuf.MapField<java.lang.String, java.lang.String> internalGetProperties() {
    if (properties_ == null) {
      return com.google.protobuf.MapField.emptyMapField(PropertiesDefaultEntryHolder.defaultEntry);
    }
    return properties_;
  }

  public int getPropertiesCount() {
    return internalGetProperties().getMap().size();
  }
  /**
   *
   *
   * <pre>
   * Optional. A mapping of property names to values, used to configure SparkR.
   * Properties that conflict with values set by the Cloud Dataproc API may be
   * overwritten. Can include properties set in
   * /etc/spark/conf/spark-defaults.conf and classes in user code.
   * </pre>
   *
   * <code>map&lt;string, string&gt; properties = 5;</code>
   */
  public boolean containsProperties(java.lang.String key) {
    if (key == null) {
      throw new java.lang.NullPointerException();
    }
    return internalGetProperties().getMap().containsKey(key);
  }
  /** Use {@link #getPropertiesMap()} instead. */
  @java.lang.Deprecated
  public java.util.Map<java.lang.String, java.lang.String> getProperties() {
    return getPropertiesMap();
  }
  /**
   *
   *
   * <pre>
   * Optional. A mapping of property names to values, used to configure SparkR.
   * Properties that conflict with values set by the Cloud Dataproc API may be
   * overwritten. Can include properties set in
   * /etc/spark/conf/spark-defaults.conf and classes in user code.
   * </pre>
   *
   * <code>map&lt;string, string&gt; properties = 5;</code>
   */
  public java.util.Map<java.lang.String, java.lang.String> getPropertiesMap() {
    return internalGetProperties().getMap();
  }
  /**
   *
   *
   * <pre>
   * Optional. A mapping of property names to values, used to configure SparkR.
   * Properties that conflict with values set by the Cloud Dataproc API may be
   * overwritten. Can include properties set in
   * /etc/spark/conf/spark-defaults.conf and classes in user code.
   * </pre>
   *
   * <code>map&lt;string, string&gt; properties = 5;</code>
   */
  public java.lang.String getPropertiesOrDefault(
      java.lang.String key, java.lang.String defaultValue) {
    if (key == null) {
      throw new java.lang.NullPointerException();
    }
    java.util.Map<java.lang.String, java.lang.String> map = internalGetProperties().getMap();
    return map.containsKey(key) ? map.get(key) : defaultValue;
  }
  /**
   *
   *
   * <pre>
   * Optional. A mapping of property names to values, used to configure SparkR.
   * Properties that conflict with values set by the Cloud Dataproc API may be
   * overwritten. Can include properties set in
   * /etc/spark/conf/spark-defaults.conf and classes in user code.
   * </pre>
   *
   * <code>map&lt;string, string&gt; properties = 5;</code>
   */
  public java.lang.String getPropertiesOrThrow(java.lang.String key) {
    if (key == null) {
      throw new java.lang.NullPointerException();
    }
    java.util.Map<java.lang.String, java.lang.String> map = internalGetProperties().getMap();
    if (!map.containsKey(key)) {
      throw new java.lang.IllegalArgumentException();
    }
    return map.get(key);
  }

  public static final int LOGGING_CONFIG_FIELD_NUMBER = 6;
  private com.google.cloud.dataproc.v1beta2.LoggingConfig loggingConfig_;
  /**
   *
   *
   * <pre>
   * Optional. The runtime log config for job execution.
   * </pre>
   *
   * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
   */
  public boolean hasLoggingConfig() {
    return loggingConfig_ != null;
  }
  /**
   *
   *
   * <pre>
   * Optional. The runtime log config for job execution.
   * </pre>
   *
   * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
   */
  public com.google.cloud.dataproc.v1beta2.LoggingConfig getLoggingConfig() {
    return loggingConfig_ == null
        ? com.google.cloud.dataproc.v1beta2.LoggingConfig.getDefaultInstance()
        : loggingConfig_;
  }
  /**
   *
   *
   * <pre>
   * Optional. The runtime log config for job execution.
   * </pre>
   *
   * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
   */
  public com.google.cloud.dataproc.v1beta2.LoggingConfigOrBuilder getLoggingConfigOrBuilder() {
    return getLoggingConfig();
  }

  private byte memoizedIsInitialized = -1;

  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output) throws java.io.IOException {
    if (!getMainRFileUriBytes().isEmpty()) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 1, mainRFileUri_);
    }
    for (int i = 0; i < args_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 2, args_.getRaw(i));
    }
    for (int i = 0; i < fileUris_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 3, fileUris_.getRaw(i));
    }
    for (int i = 0; i < archiveUris_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 4, archiveUris_.getRaw(i));
    }
    com.google.protobuf.GeneratedMessageV3.serializeStringMapTo(
        output, internalGetProperties(), PropertiesDefaultEntryHolder.defaultEntry, 5);
    if (loggingConfig_ != null) {
      output.writeMessage(6, getLoggingConfig());
    }
    unknownFields.writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (!getMainRFileUriBytes().isEmpty()) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, mainRFileUri_);
    }
    {
      int dataSize = 0;
      for (int i = 0; i < args_.size(); i++) {
        dataSize += computeStringSizeNoTag(args_.getRaw(i));
      }
      size += dataSize;
      size += 1 * getArgsList().size();
    }
    {
      int dataSize = 0;
      for (int i = 0; i < fileUris_.size(); i++) {
        dataSize += computeStringSizeNoTag(fileUris_.getRaw(i));
      }
      size += dataSize;
      size += 1 * getFileUrisList().size();
    }
    {
      int dataSize = 0;
      for (int i = 0; i < archiveUris_.size(); i++) {
        dataSize += computeStringSizeNoTag(archiveUris_.getRaw(i));
      }
      size += dataSize;
      size += 1 * getArchiveUrisList().size();
    }
    for (java.util.Map.Entry<java.lang.String, java.lang.String> entry :
        internalGetProperties().getMap().entrySet()) {
      com.google.protobuf.MapEntry<java.lang.String, java.lang.String> properties__ =
          PropertiesDefaultEntryHolder.defaultEntry
              .newBuilderForType()
              .setKey(entry.getKey())
              .setValue(entry.getValue())
              .build();
      size += com.google.protobuf.CodedOutputStream.computeMessageSize(5, properties__);
    }
    if (loggingConfig_ != null) {
      size += com.google.protobuf.CodedOutputStream.computeMessageSize(6, getLoggingConfig());
    }
    size += unknownFields.getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
      return true;
    }
    if (!(obj instanceof com.google.cloud.dataproc.v1beta2.SparkRJob)) {
      return super.equals(obj);
    }
    com.google.cloud.dataproc.v1beta2.SparkRJob other =
        (com.google.cloud.dataproc.v1beta2.SparkRJob) obj;

    if (!getMainRFileUri().equals(other.getMainRFileUri())) return false;
    if (!getArgsList().equals(other.getArgsList())) return false;
    if (!getFileUrisList().equals(other.getFileUrisList())) return false;
    if (!getArchiveUrisList().equals(other.getArchiveUrisList())) return false;
    if (!internalGetProperties().equals(other.internalGetProperties())) return false;
    if (hasLoggingConfig() != other.hasLoggingConfig()) return false;
    if (hasLoggingConfig()) {
      if (!getLoggingConfig().equals(other.getLoggingConfig())) return false;
    }
    if (!unknownFields.equals(other.unknownFields)) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + MAIN_R_FILE_URI_FIELD_NUMBER;
    hash = (53 * hash) + getMainRFileUri().hashCode();
    if (getArgsCount() > 0) {
      hash = (37 * hash) + ARGS_FIELD_NUMBER;
      hash = (53 * hash) + getArgsList().hashCode();
    }
    if (getFileUrisCount() > 0) {
      hash = (37 * hash) + FILE_URIS_FIELD_NUMBER;
      hash = (53 * hash) + getFileUrisList().hashCode();
    }
    if (getArchiveUrisCount() > 0) {
      hash = (37 * hash) + ARCHIVE_URIS_FIELD_NUMBER;
      hash = (53 * hash) + getArchiveUrisList().hashCode();
    }
    if (!internalGetProperties().getMap().isEmpty()) {
      hash = (37 * hash) + PROPERTIES_FIELD_NUMBER;
      hash = (53 * hash) + internalGetProperties().hashCode();
    }
    if (hasLoggingConfig()) {
      hash = (37 * hash) + LOGGING_CONFIG_FIELD_NUMBER;
      hash = (53 * hash) + getLoggingConfig().hashCode();
    }
    hash = (29 * hash) + unknownFields.hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(
      java.nio.ByteBuffer data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(
      byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(
      java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
        PARSER, input, extensionRegistry);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseDelimitedFrom(
      java.io.InputStream input) throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseDelimitedFrom(
      java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseDelimitedWithIOException(
        PARSER, input, extensionRegistry);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(
      com.google.protobuf.CodedInputStream input) throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(PARSER, input);
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3.parseWithIOException(
        PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() {
    return newBuilder();
  }

  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }

  public static Builder newBuilder(com.google.cloud.dataproc.v1beta2.SparkRJob prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }

  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   *
   *
   * <pre>
   * A Cloud Dataproc job for running
   * [Apache SparkR](https://spark.apache.org/docs/latest/sparkr.html)
   * applications on YARN.
   * </pre>
   *
   * Protobuf type {@code google.cloud.dataproc.v1beta2.SparkRJob}
   */
  public static final class Builder extends com.google.protobuf.GeneratedMessageV3.Builder<Builder>
      implements
      // @@protoc_insertion_point(builder_implements:google.cloud.dataproc.v1beta2.SparkRJob)
      com.google.cloud.dataproc.v1beta2.SparkRJobOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor getDescriptor() {
      return com.google.cloud.dataproc.v1beta2.JobsProto
          .internal_static_google_cloud_dataproc_v1beta2_SparkRJob_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMapField(int number) {
      switch (number) {
        case 5:
          return internalGetProperties();
        default:
          throw new RuntimeException("Invalid map field number: " + number);
      }
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMutableMapField(int number) {
      switch (number) {
        case 5:
          return internalGetMutableProperties();
        default:
          throw new RuntimeException("Invalid map field number: " + number);
      }
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.dataproc.v1beta2.JobsProto
          .internal_static_google_cloud_dataproc_v1beta2_SparkRJob_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.dataproc.v1beta2.SparkRJob.class,
              com.google.cloud.dataproc.v1beta2.SparkRJob.Builder.class);
    }

    // Construct using com.google.cloud.dataproc.v1beta2.SparkRJob.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }

    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders) {}
    }

    @java.lang.Override
    public Builder clear() {
      super.clear();
      mainRFileUri_ = "";

      args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000002);
      fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000004);
      archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000008);
      internalGetMutableProperties().clear();
      if (loggingConfigBuilder_ == null) {
        loggingConfig_ = null;
      } else {
        loggingConfig_ = null;
        loggingConfigBuilder_ = null;
      }
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor getDescriptorForType() {
      return com.google.cloud.dataproc.v1beta2.JobsProto
          .internal_static_google_cloud_dataproc_v1beta2_SparkRJob_descriptor;
    }

    @java.lang.Override
    public com.google.cloud.dataproc.v1beta2.SparkRJob getDefaultInstanceForType() {
      return com.google.cloud.dataproc.v1beta2.SparkRJob.getDefaultInstance();
    }

    @java.lang.Override
    public com.google.cloud.dataproc.v1beta2.SparkRJob build() {
      com.google.cloud.dataproc.v1beta2.SparkRJob result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public com.google.cloud.dataproc.v1beta2.SparkRJob buildPartial() {
      com.google.cloud.dataproc.v1beta2.SparkRJob result =
          new com.google.cloud.dataproc.v1beta2.SparkRJob(this);
      int from_bitField0_ = bitField0_;
      int to_bitField0_ = 0;
      result.mainRFileUri_ = mainRFileUri_;
      if (((bitField0_ & 0x00000002) != 0)) {
        args_ = args_.getUnmodifiableView();
        bitField0_ = (bitField0_ & ~0x00000002);
      }
      result.args_ = args_;
      if (((bitField0_ & 0x00000004) != 0)) {
        fileUris_ = fileUris_.getUnmodifiableView();
        bitField0_ = (bitField0_ & ~0x00000004);
      }
      result.fileUris_ = fileUris_;
      if (((bitField0_ & 0x00000008) != 0)) {
        archiveUris_ = archiveUris_.getUnmodifiableView();
        bitField0_ = (bitField0_ & ~0x00000008);
      }
      result.archiveUris_ = archiveUris_;
      result.properties_ = internalGetProperties();
      result.properties_.makeImmutable();
      if (loggingConfigBuilder_ == null) {
        result.loggingConfig_ = loggingConfig_;
      } else {
        result.loggingConfig_ = loggingConfigBuilder_.build();
      }
      result.bitField0_ = to_bitField0_;
      onBuilt();
      return result;
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }

    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
      return super.setField(field, value);
    }

    @java.lang.Override
    public Builder clearField(com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }

    @java.lang.Override
    public Builder clearOneof(com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }

    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field, int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }

    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field, java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }

    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.google.cloud.dataproc.v1beta2.SparkRJob) {
        return mergeFrom((com.google.cloud.dataproc.v1beta2.SparkRJob) other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.google.cloud.dataproc.v1beta2.SparkRJob other) {
      if (other == com.google.cloud.dataproc.v1beta2.SparkRJob.getDefaultInstance()) return this;
      if (!other.getMainRFileUri().isEmpty()) {
        mainRFileUri_ = other.mainRFileUri_;
        onChanged();
      }
      if (!other.args_.isEmpty()) {
        if (args_.isEmpty()) {
          args_ = other.args_;
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          ensureArgsIsMutable();
          args_.addAll(other.args_);
        }
        onChanged();
      }
      if (!other.fileUris_.isEmpty()) {
        if (fileUris_.isEmpty()) {
          fileUris_ = other.fileUris_;
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          ensureFileUrisIsMutable();
          fileUris_.addAll(other.fileUris_);
        }
        onChanged();
      }
      if (!other.archiveUris_.isEmpty()) {
        if (archiveUris_.isEmpty()) {
          archiveUris_ = other.archiveUris_;
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          ensureArchiveUrisIsMutable();
          archiveUris_.addAll(other.archiveUris_);
        }
        onChanged();
      }
      internalGetMutableProperties().mergeFrom(other.internalGetProperties());
      if (other.hasLoggingConfig()) {
        mergeLoggingConfig(other.getLoggingConfig());
      }
      this.mergeUnknownFields(other.unknownFields);
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      com.google.cloud.dataproc.v1beta2.SparkRJob parsedMessage = null;
      try {
        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        parsedMessage = (com.google.cloud.dataproc.v1beta2.SparkRJob) e.getUnfinishedMessage();
        throw e.unwrapIOException();
      } finally {
        if (parsedMessage != null) {
          mergeFrom(parsedMessage);
        }
      }
      return this;
    }

    private int bitField0_;

    private java.lang.Object mainRFileUri_ = "";
    /**
     *
     *
     * <pre>
     * Required. The HCFS URI of the main R file to use as the driver.
     * Must be a .R file.
     * </pre>
     *
     * <code>string main_r_file_uri = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public java.lang.String getMainRFileUri() {
      java.lang.Object ref = mainRFileUri_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        mainRFileUri_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     *
     *
     * <pre>
     * Required. The HCFS URI of the main R file to use as the driver.
     * Must be a .R file.
     * </pre>
     *
     * <code>string main_r_file_uri = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public com.google.protobuf.ByteString getMainRFileUriBytes() {
      java.lang.Object ref = mainRFileUri_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8((java.lang.String) ref);
        mainRFileUri_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     *
     *
     * <pre>
     * Required. The HCFS URI of the main R file to use as the driver.
     * Must be a .R file.
     * </pre>
     *
     * <code>string main_r_file_uri = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder setMainRFileUri(java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }

      mainRFileUri_ = value;
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Required. The HCFS URI of the main R file to use as the driver.
     * Must be a .R file.
     * </pre>
     *
     * <code>string main_r_file_uri = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder clearMainRFileUri() {

      mainRFileUri_ = getDefaultInstance().getMainRFileUri();
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Required. The HCFS URI of the main R file to use as the driver.
     * Must be a .R file.
     * </pre>
     *
     * <code>string main_r_file_uri = 1 [(.google.api.field_behavior) = REQUIRED];</code>
     */
    public Builder setMainRFileUriBytes(com.google.protobuf.ByteString value) {
      if (value == null) {
        throw new NullPointerException();
      }
      checkByteStringIsUtf8(value);

      mainRFileUri_ = value;
      onChanged();
      return this;
    }

    private com.google.protobuf.LazyStringList args_ =
        com.google.protobuf.LazyStringArrayList.EMPTY;

    private void ensureArgsIsMutable() {
      if (!((bitField0_ & 0x00000002) != 0)) {
        args_ = new com.google.protobuf.LazyStringArrayList(args_);
        bitField0_ |= 0x00000002;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public com.google.protobuf.ProtocolStringList getArgsList() {
      return args_.getUnmodifiableView();
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public int getArgsCount() {
      return args_.size();
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public java.lang.String getArgs(int index) {
      return args_.get(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public com.google.protobuf.ByteString getArgsBytes(int index) {
      return args_.getByteString(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public Builder setArgs(int index, java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      ensureArgsIsMutable();
      args_.set(index, value);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public Builder addArgs(java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      ensureArgsIsMutable();
      args_.add(value);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public Builder addAllArgs(java.lang.Iterable<java.lang.String> values) {
      ensureArgsIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(values, args_);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public Builder clearArgs() {
      args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000002);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The arguments to pass to the driver.  Do not include arguments,
     * such as `--conf`, that can be set as job properties, since a collision may
     * occur that causes an incorrect job submission.
     * </pre>
     *
     * <code>repeated string args = 2;</code>
     */
    public Builder addArgsBytes(com.google.protobuf.ByteString value) {
      if (value == null) {
        throw new NullPointerException();
      }
      checkByteStringIsUtf8(value);
      ensureArgsIsMutable();
      args_.add(value);
      onChanged();
      return this;
    }

    private com.google.protobuf.LazyStringList fileUris_ =
        com.google.protobuf.LazyStringArrayList.EMPTY;

    private void ensureFileUrisIsMutable() {
      if (!((bitField0_ & 0x00000004) != 0)) {
        fileUris_ = new com.google.protobuf.LazyStringArrayList(fileUris_);
        bitField0_ |= 0x00000004;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public com.google.protobuf.ProtocolStringList getFileUrisList() {
      return fileUris_.getUnmodifiableView();
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public int getFileUrisCount() {
      return fileUris_.size();
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public java.lang.String getFileUris(int index) {
      return fileUris_.get(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public com.google.protobuf.ByteString getFileUrisBytes(int index) {
      return fileUris_.getByteString(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public Builder setFileUris(int index, java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      ensureFileUrisIsMutable();
      fileUris_.set(index, value);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public Builder addFileUris(java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      ensureFileUrisIsMutable();
      fileUris_.add(value);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public Builder addAllFileUris(java.lang.Iterable<java.lang.String> values) {
      ensureFileUrisIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(values, fileUris_);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public Builder clearFileUris() {
      fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000004);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of files to be copied to the working directory of
     * R drivers and distributed tasks. Useful for naively parallel tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     */
    public Builder addFileUrisBytes(com.google.protobuf.ByteString value) {
      if (value == null) {
        throw new NullPointerException();
      }
      checkByteStringIsUtf8(value);
      ensureFileUrisIsMutable();
      fileUris_.add(value);
      onChanged();
      return this;
    }

    private com.google.protobuf.LazyStringList archiveUris_ =
        com.google.protobuf.LazyStringArrayList.EMPTY;

    private void ensureArchiveUrisIsMutable() {
      if (!((bitField0_ & 0x00000008) != 0)) {
        archiveUris_ = new com.google.protobuf.LazyStringArrayList(archiveUris_);
        bitField0_ |= 0x00000008;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public com.google.protobuf.ProtocolStringList getArchiveUrisList() {
      return archiveUris_.getUnmodifiableView();
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public int getArchiveUrisCount() {
      return archiveUris_.size();
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public java.lang.String getArchiveUris(int index) {
      return archiveUris_.get(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public com.google.protobuf.ByteString getArchiveUrisBytes(int index) {
      return archiveUris_.getByteString(index);
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public Builder setArchiveUris(int index, java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      ensureArchiveUrisIsMutable();
      archiveUris_.set(index, value);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public Builder addArchiveUris(java.lang.String value) {
      if (value == null) {
        throw new NullPointerException();
      }
      ensureArchiveUrisIsMutable();
      archiveUris_.add(value);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public Builder addAllArchiveUris(java.lang.Iterable<java.lang.String> values) {
      ensureArchiveUrisIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(values, archiveUris_);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public Builder clearArchiveUris() {
      archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000008);
      onChanged();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. HCFS URIs of archives to be extracted in the working directory of
     * Spark drivers and tasks. Supported file types:
     * .jar, .tar, .tar.gz, .tgz, and .zip.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     */
    public Builder addArchiveUrisBytes(com.google.protobuf.ByteString value) {
      if (value == null) {
        throw new NullPointerException();
      }
      checkByteStringIsUtf8(value);
      ensureArchiveUrisIsMutable();
      archiveUris_.add(value);
      onChanged();
      return this;
    }

    private com.google.protobuf.MapField<java.lang.String, java.lang.String> properties_;

    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
        internalGetProperties() {
      if (properties_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            PropertiesDefaultEntryHolder.defaultEntry);
      }
      return properties_;
    }

    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
        internalGetMutableProperties() {
      onChanged();
      ;
      if (properties_ == null) {
        properties_ =
            com.google.protobuf.MapField.newMapField(PropertiesDefaultEntryHolder.defaultEntry);
      }
      if (!properties_.isMutable()) {
        properties_ = properties_.copy();
      }
      return properties_;
    }

    public int getPropertiesCount() {
      return internalGetProperties().getMap().size();
    }
    /**
     *
     *
     * <pre>
     * Optional. A mapping of property names to values, used to configure SparkR.
     * Properties that conflict with values set by the Cloud Dataproc API may be
     * overwritten. Can include properties set in
     * /etc/spark/conf/spark-defaults.conf and classes in user code.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    public boolean containsProperties(java.lang.String key) {
      if (key == null) {
        throw new java.lang.NullPointerException();
      }
      return internalGetProperties().getMap().containsKey(key);
    }
    /** Use {@link #getPropertiesMap()} instead. */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getProperties() {
      return getPropertiesMap();
    }
    /**
     *
     *
     * <pre>
     * Optional. A mapping of property names to values, used to configure SparkR.
     * Properties that conflict with values set by the Cloud Dataproc API may be
     * overwritten. Can include properties set in
     * /etc/spark/conf/spark-defaults.conf and classes in user code.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    public java.util.Map<java.lang.String, java.lang.String> getPropertiesMap() {
      return internalGetProperties().getMap();
    }
    /**
     *
     *
     * <pre>
     * Optional. A mapping of property names to values, used to configure SparkR.
     * Properties that conflict with values set by the Cloud Dataproc API may be
     * overwritten. Can include properties set in
     * /etc/spark/conf/spark-defaults.conf and classes in user code.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    public java.lang.String getPropertiesOrDefault(
        java.lang.String key, java.lang.String defaultValue) {
      if (key == null) {
        throw new java.lang.NullPointerException();
      }
      java.util.Map<java.lang.String, java.lang.String> map = internalGetProperties().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     *
     *
     * <pre>
     * Optional. A mapping of property names to values, used to configure SparkR.
     * Properties that conflict with values set by the Cloud Dataproc API may be
     * overwritten. Can include properties set in
     * /etc/spark/conf/spark-defaults.conf and classes in user code.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    public java.lang.String getPropertiesOrThrow(java.lang.String key) {
      if (key == null) {
        throw new java.lang.NullPointerException();
      }
      java.util.Map<java.lang.String, java.lang.String> map = internalGetProperties().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public Builder clearProperties() {
      internalGetMutableProperties().getMutableMap().clear();
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. A mapping of property names to values, used to configure SparkR.
     * Properties that conflict with values set by the Cloud Dataproc API may be
     * overwritten. Can include properties set in
     * /etc/spark/conf/spark-defaults.conf and classes in user code.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    public Builder removeProperties(java.lang.String key) {
      if (key == null) {
        throw new java.lang.NullPointerException();
      }
      internalGetMutableProperties().getMutableMap().remove(key);
      return this;
    }
    /** Use alternate mutation accessors instead. */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getMutableProperties() {
      return internalGetMutableProperties().getMutableMap();
    }
    /**
     *
     *
     * <pre>
     * Optional. A mapping of property names to values, used to configure SparkR.
     * Properties that conflict with values set by the Cloud Dataproc API may be
     * overwritten. Can include properties set in
     * /etc/spark/conf/spark-defaults.conf and classes in user code.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    public Builder putProperties(java.lang.String key, java.lang.String value) {
      if (key == null) {
        throw new java.lang.NullPointerException();
      }
      if (value == null) {
        throw new java.lang.NullPointerException();
      }
      internalGetMutableProperties().getMutableMap().put(key, value);
      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. A mapping of property names to values, used to configure SparkR.
     * Properties that conflict with values set by the Cloud Dataproc API may be
     * overwritten. Can include properties set in
     * /etc/spark/conf/spark-defaults.conf and classes in user code.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    public Builder putAllProperties(java.util.Map<java.lang.String, java.lang.String> values) {
      internalGetMutableProperties().getMutableMap().putAll(values);
      return this;
    }

    private com.google.cloud.dataproc.v1beta2.LoggingConfig loggingConfig_;
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataproc.v1beta2.LoggingConfig,
            com.google.cloud.dataproc.v1beta2.LoggingConfig.Builder,
            com.google.cloud.dataproc.v1beta2.LoggingConfigOrBuilder>
        loggingConfigBuilder_;
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public boolean hasLoggingConfig() {
      return loggingConfigBuilder_ != null || loggingConfig_ != null;
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public com.google.cloud.dataproc.v1beta2.LoggingConfig getLoggingConfig() {
      if (loggingConfigBuilder_ == null) {
        return loggingConfig_ == null
            ? com.google.cloud.dataproc.v1beta2.LoggingConfig.getDefaultInstance()
            : loggingConfig_;
      } else {
        return loggingConfigBuilder_.getMessage();
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public Builder setLoggingConfig(com.google.cloud.dataproc.v1beta2.LoggingConfig value) {
      if (loggingConfigBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        loggingConfig_ = value;
        onChanged();
      } else {
        loggingConfigBuilder_.setMessage(value);
      }

      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public Builder setLoggingConfig(
        com.google.cloud.dataproc.v1beta2.LoggingConfig.Builder builderForValue) {
      if (loggingConfigBuilder_ == null) {
        loggingConfig_ = builderForValue.build();
        onChanged();
      } else {
        loggingConfigBuilder_.setMessage(builderForValue.build());
      }

      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public Builder mergeLoggingConfig(com.google.cloud.dataproc.v1beta2.LoggingConfig value) {
      if (loggingConfigBuilder_ == null) {
        if (loggingConfig_ != null) {
          loggingConfig_ =
              com.google.cloud.dataproc.v1beta2.LoggingConfig.newBuilder(loggingConfig_)
                  .mergeFrom(value)
                  .buildPartial();
        } else {
          loggingConfig_ = value;
        }
        onChanged();
      } else {
        loggingConfigBuilder_.mergeFrom(value);
      }

      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public Builder clearLoggingConfig() {
      if (loggingConfigBuilder_ == null) {
        loggingConfig_ = null;
        onChanged();
      } else {
        loggingConfig_ = null;
        loggingConfigBuilder_ = null;
      }

      return this;
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public com.google.cloud.dataproc.v1beta2.LoggingConfig.Builder getLoggingConfigBuilder() {

      onChanged();
      return getLoggingConfigFieldBuilder().getBuilder();
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    public com.google.cloud.dataproc.v1beta2.LoggingConfigOrBuilder getLoggingConfigOrBuilder() {
      if (loggingConfigBuilder_ != null) {
        return loggingConfigBuilder_.getMessageOrBuilder();
      } else {
        return loggingConfig_ == null
            ? com.google.cloud.dataproc.v1beta2.LoggingConfig.getDefaultInstance()
            : loggingConfig_;
      }
    }
    /**
     *
     *
     * <pre>
     * Optional. The runtime log config for job execution.
     * </pre>
     *
     * <code>.google.cloud.dataproc.v1beta2.LoggingConfig logging_config = 6;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
            com.google.cloud.dataproc.v1beta2.LoggingConfig,
            com.google.cloud.dataproc.v1beta2.LoggingConfig.Builder,
            com.google.cloud.dataproc.v1beta2.LoggingConfigOrBuilder>
        getLoggingConfigFieldBuilder() {
      if (loggingConfigBuilder_ == null) {
        loggingConfigBuilder_ =
            new com.google.protobuf.SingleFieldBuilderV3<
                com.google.cloud.dataproc.v1beta2.LoggingConfig,
                com.google.cloud.dataproc.v1beta2.LoggingConfig.Builder,
                com.google.cloud.dataproc.v1beta2.LoggingConfigOrBuilder>(
                getLoggingConfig(), getParentForChildren(), isClean());
        loggingConfig_ = null;
      }
      return loggingConfigBuilder_;
    }

    @java.lang.Override
    public final Builder setUnknownFields(final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }

    // @@protoc_insertion_point(builder_scope:google.cloud.dataproc.v1beta2.SparkRJob)
  }

  // @@protoc_insertion_point(class_scope:google.cloud.dataproc.v1beta2.SparkRJob)
  private static final com.google.cloud.dataproc.v1beta2.SparkRJob DEFAULT_INSTANCE;

  static {
    DEFAULT_INSTANCE = new com.google.cloud.dataproc.v1beta2.SparkRJob();
  }

  public static com.google.cloud.dataproc.v1beta2.SparkRJob getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<SparkRJob> PARSER =
      new com.google.protobuf.AbstractParser<SparkRJob>() {
        @java.lang.Override
        public SparkRJob parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new SparkRJob(input, extensionRegistry);
        }
      };

  public static com.google.protobuf.Parser<SparkRJob> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<SparkRJob> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.cloud.dataproc.v1beta2.SparkRJob getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }
}
